{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Chapkit","text":"<p>Async SQLAlchemy database library for Python 3.13+ with FastAPI integration and ML workflow support.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from chapkit import BaseConfig\nfrom chapkit.api import ServiceBuilder, ServiceInfo\n\nclass MyConfig(BaseConfig):\n    host: str\n    port: int\n\napp = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"My Service\"))\n    .with_health()\n    .with_config(MyConfig)\n    .build()\n)\n</code></pre> <p>Run with: <code>fastapi dev your_file.py</code></p>"},{"location":"#installation","title":"Installation","text":"<pre><code>uv add chapkit\n</code></pre>"},{"location":"#links","title":"Links","text":"<ul> <li>Repository</li> <li>Issues</li> <li>API Reference</li> </ul>"},{"location":"#license","title":"License","text":"<p>AGPL-3.0-or-later</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete API documentation for all chapkit modules, classes, and functions.</p>"},{"location":"api-reference/#core-layer","title":"Core Layer","text":"<p>Framework-agnostic infrastructure components.</p>"},{"location":"api-reference/#database","title":"Database","text":""},{"location":"api-reference/#chapkit.core.database","title":"<code>database</code>","text":"<p>Async SQLAlchemy database connection manager.</p>"},{"location":"api-reference/#chapkit.core.database.Database","title":"<code>Database</code>","text":"<p>Generic async SQLAlchemy database connection manager.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>class Database:\n    \"\"\"Generic async SQLAlchemy database connection manager.\"\"\"\n\n    def __init__(\n        self,\n        url: str,\n        *,\n        echo: bool = False,\n        alembic_dir: Path | None = None,\n        auto_migrate: bool = True,\n        pool_size: int = 5,\n        max_overflow: int = 10,\n        pool_recycle: int = 3600,\n        pool_pre_ping: bool = True,\n    ) -&gt; None:\n        \"\"\"Initialize database with connection URL and pool configuration.\"\"\"\n        self.url = url\n        self.alembic_dir = alembic_dir\n        self.auto_migrate = auto_migrate\n\n        # Build engine kwargs - skip pool params for in-memory SQLite databases\n        engine_kwargs: dict = {\"echo\": echo, \"future\": True}\n        if \":memory:\" not in url:\n            # Only add pool params for non-in-memory databases\n            engine_kwargs.update(\n                {\n                    \"pool_size\": pool_size,\n                    \"max_overflow\": max_overflow,\n                    \"pool_recycle\": pool_recycle,\n                    \"pool_pre_ping\": pool_pre_ping,\n                }\n            )\n\n        self.engine: AsyncEngine = create_async_engine(url, **engine_kwargs)\n        self._session_factory: async_sessionmaker[AsyncSession] = async_sessionmaker(\n            bind=self.engine, class_=AsyncSession, expire_on_commit=False\n        )\n\n    async def init(self) -&gt; None:\n        \"\"\"Initialize database tables using Alembic migrations or direct creation.\"\"\"\n        import asyncio\n\n        # Import Base here to avoid circular import at module level\n        from chapkit.core.models import Base\n\n        # For databases without migrations, use direct table creation\n        if not self.auto_migrate:\n            async with self.engine.begin() as conn:\n                await conn.run_sync(Base.metadata.create_all)\n        else:\n            # Use Alembic migrations\n            alembic_cfg = Config()\n\n            # Use custom alembic directory if provided, otherwise use bundled migrations\n            if self.alembic_dir is not None:\n                alembic_cfg.set_main_option(\"script_location\", str(self.alembic_dir))\n            else:\n                alembic_cfg.set_main_option(\n                    \"script_location\", str(Path(__file__).parent.parent.parent.parent / \"alembic\")\n                )\n\n            alembic_cfg.set_main_option(\"sqlalchemy.url\", self.url)\n\n            # Run upgrade in executor to avoid event loop conflicts\n            loop = asyncio.get_running_loop()\n            await loop.run_in_executor(None, command.upgrade, alembic_cfg, \"head\")\n\n    @asynccontextmanager\n    async def session(self) -&gt; AsyncIterator[AsyncSession]:\n        \"\"\"Create a database session context manager.\"\"\"\n        async with self._session_factory() as s:\n            yield s\n\n    async def dispose(self) -&gt; None:\n        \"\"\"Dispose of database engine and connection pool.\"\"\"\n        await self.engine.dispose()\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.Database.__init__","title":"<code>__init__(url, *, echo=False, alembic_dir=None, auto_migrate=True, pool_size=5, max_overflow=10, pool_recycle=3600, pool_pre_ping=True)</code>","text":"<p>Initialize database with connection URL and pool configuration.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>def __init__(\n    self,\n    url: str,\n    *,\n    echo: bool = False,\n    alembic_dir: Path | None = None,\n    auto_migrate: bool = True,\n    pool_size: int = 5,\n    max_overflow: int = 10,\n    pool_recycle: int = 3600,\n    pool_pre_ping: bool = True,\n) -&gt; None:\n    \"\"\"Initialize database with connection URL and pool configuration.\"\"\"\n    self.url = url\n    self.alembic_dir = alembic_dir\n    self.auto_migrate = auto_migrate\n\n    # Build engine kwargs - skip pool params for in-memory SQLite databases\n    engine_kwargs: dict = {\"echo\": echo, \"future\": True}\n    if \":memory:\" not in url:\n        # Only add pool params for non-in-memory databases\n        engine_kwargs.update(\n            {\n                \"pool_size\": pool_size,\n                \"max_overflow\": max_overflow,\n                \"pool_recycle\": pool_recycle,\n                \"pool_pre_ping\": pool_pre_ping,\n            }\n        )\n\n    self.engine: AsyncEngine = create_async_engine(url, **engine_kwargs)\n    self._session_factory: async_sessionmaker[AsyncSession] = async_sessionmaker(\n        bind=self.engine, class_=AsyncSession, expire_on_commit=False\n    )\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.Database.init","title":"<code>init()</code>  <code>async</code>","text":"<p>Initialize database tables using Alembic migrations or direct creation.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>async def init(self) -&gt; None:\n    \"\"\"Initialize database tables using Alembic migrations or direct creation.\"\"\"\n    import asyncio\n\n    # Import Base here to avoid circular import at module level\n    from chapkit.core.models import Base\n\n    # For databases without migrations, use direct table creation\n    if not self.auto_migrate:\n        async with self.engine.begin() as conn:\n            await conn.run_sync(Base.metadata.create_all)\n    else:\n        # Use Alembic migrations\n        alembic_cfg = Config()\n\n        # Use custom alembic directory if provided, otherwise use bundled migrations\n        if self.alembic_dir is not None:\n            alembic_cfg.set_main_option(\"script_location\", str(self.alembic_dir))\n        else:\n            alembic_cfg.set_main_option(\n                \"script_location\", str(Path(__file__).parent.parent.parent.parent / \"alembic\")\n            )\n\n        alembic_cfg.set_main_option(\"sqlalchemy.url\", self.url)\n\n        # Run upgrade in executor to avoid event loop conflicts\n        loop = asyncio.get_running_loop()\n        await loop.run_in_executor(None, command.upgrade, alembic_cfg, \"head\")\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.Database.session","title":"<code>session()</code>  <code>async</code>","text":"<p>Create a database session context manager.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>@asynccontextmanager\nasync def session(self) -&gt; AsyncIterator[AsyncSession]:\n    \"\"\"Create a database session context manager.\"\"\"\n    async with self._session_factory() as s:\n        yield s\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.Database.dispose","title":"<code>dispose()</code>  <code>async</code>","text":"<p>Dispose of database engine and connection pool.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>async def dispose(self) -&gt; None:\n    \"\"\"Dispose of database engine and connection pool.\"\"\"\n    await self.engine.dispose()\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.SqliteDatabase","title":"<code>SqliteDatabase</code>","text":"<p>               Bases: <code>Database</code></p> <p>SQLite-specific database implementation with optimizations.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>class SqliteDatabase(Database):\n    \"\"\"SQLite-specific database implementation with optimizations.\"\"\"\n\n    def __init__(\n        self,\n        url: str,\n        *,\n        echo: bool = False,\n        alembic_dir: Path | None = None,\n        auto_migrate: bool = True,\n        pool_size: int = 5,\n        max_overflow: int = 10,\n        pool_recycle: int = 3600,\n        pool_pre_ping: bool = True,\n    ) -&gt; None:\n        \"\"\"Initialize SQLite database with connection URL and pool configuration.\"\"\"\n        self.url = url\n        self.alembic_dir = alembic_dir\n        self.auto_migrate = auto_migrate\n\n        # Build engine kwargs - pool params only for non-in-memory databases\n        engine_kwargs: dict = {\"echo\": echo, \"future\": True}\n        if not self._is_in_memory_url(url):\n            # File-based databases can use pool configuration\n            engine_kwargs.update(\n                {\n                    \"pool_size\": pool_size,\n                    \"max_overflow\": max_overflow,\n                    \"pool_recycle\": pool_recycle,\n                    \"pool_pre_ping\": pool_pre_ping,\n                }\n            )\n\n        self.engine: AsyncEngine = create_async_engine(url, **engine_kwargs)\n        _install_sqlite_connect_pragmas(self.engine)\n        self._session_factory: async_sessionmaker[AsyncSession] = async_sessionmaker(\n            bind=self.engine, class_=AsyncSession, expire_on_commit=False\n        )\n\n    @staticmethod\n    def _is_in_memory_url(url: str) -&gt; bool:\n        \"\"\"Check if URL represents an in-memory database.\"\"\"\n        return \":memory:\" in url\n\n    def is_in_memory(self) -&gt; bool:\n        \"\"\"Check if this is an in-memory database.\"\"\"\n        return self._is_in_memory_url(self.url)\n\n    async def init(self) -&gt; None:\n        \"\"\"Initialize database tables and configure SQLite using Alembic migrations.\"\"\"\n        # Import Base here to avoid circular import at module level\n        from chapkit.core.models import Base\n\n        # Set WAL mode first (if not in-memory)\n        if not self.is_in_memory():\n            async with self.engine.begin() as conn:\n                await conn.exec_driver_sql(\"PRAGMA journal_mode=WAL;\")\n\n        # For in-memory databases or when migrations are disabled, use direct table creation\n        if self.is_in_memory() or not self.auto_migrate:\n            async with self.engine.begin() as conn:\n                await conn.run_sync(Base.metadata.create_all)\n        else:\n            # For file-based databases, use Alembic migrations\n            await super().init()\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.SqliteDatabase.__init__","title":"<code>__init__(url, *, echo=False, alembic_dir=None, auto_migrate=True, pool_size=5, max_overflow=10, pool_recycle=3600, pool_pre_ping=True)</code>","text":"<p>Initialize SQLite database with connection URL and pool configuration.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>def __init__(\n    self,\n    url: str,\n    *,\n    echo: bool = False,\n    alembic_dir: Path | None = None,\n    auto_migrate: bool = True,\n    pool_size: int = 5,\n    max_overflow: int = 10,\n    pool_recycle: int = 3600,\n    pool_pre_ping: bool = True,\n) -&gt; None:\n    \"\"\"Initialize SQLite database with connection URL and pool configuration.\"\"\"\n    self.url = url\n    self.alembic_dir = alembic_dir\n    self.auto_migrate = auto_migrate\n\n    # Build engine kwargs - pool params only for non-in-memory databases\n    engine_kwargs: dict = {\"echo\": echo, \"future\": True}\n    if not self._is_in_memory_url(url):\n        # File-based databases can use pool configuration\n        engine_kwargs.update(\n            {\n                \"pool_size\": pool_size,\n                \"max_overflow\": max_overflow,\n                \"pool_recycle\": pool_recycle,\n                \"pool_pre_ping\": pool_pre_ping,\n            }\n        )\n\n    self.engine: AsyncEngine = create_async_engine(url, **engine_kwargs)\n    _install_sqlite_connect_pragmas(self.engine)\n    self._session_factory: async_sessionmaker[AsyncSession] = async_sessionmaker(\n        bind=self.engine, class_=AsyncSession, expire_on_commit=False\n    )\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.SqliteDatabase.is_in_memory","title":"<code>is_in_memory()</code>","text":"<p>Check if this is an in-memory database.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>def is_in_memory(self) -&gt; bool:\n    \"\"\"Check if this is an in-memory database.\"\"\"\n    return self._is_in_memory_url(self.url)\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.SqliteDatabase.init","title":"<code>init()</code>  <code>async</code>","text":"<p>Initialize database tables and configure SQLite using Alembic migrations.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>async def init(self) -&gt; None:\n    \"\"\"Initialize database tables and configure SQLite using Alembic migrations.\"\"\"\n    # Import Base here to avoid circular import at module level\n    from chapkit.core.models import Base\n\n    # Set WAL mode first (if not in-memory)\n    if not self.is_in_memory():\n        async with self.engine.begin() as conn:\n            await conn.exec_driver_sql(\"PRAGMA journal_mode=WAL;\")\n\n    # For in-memory databases or when migrations are disabled, use direct table creation\n    if self.is_in_memory() or not self.auto_migrate:\n        async with self.engine.begin() as conn:\n            await conn.run_sync(Base.metadata.create_all)\n    else:\n        # For file-based databases, use Alembic migrations\n        await super().init()\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.SqliteDatabaseBuilder","title":"<code>SqliteDatabaseBuilder</code>","text":"<p>Builder for SQLite database configuration with fluent API.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>class SqliteDatabaseBuilder:\n    \"\"\"Builder for SQLite database configuration with fluent API.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize builder with default values.\"\"\"\n        self._url: str = \"\"\n        self._echo: bool = False\n        self._alembic_dir: Path | None = None\n        self._auto_migrate: bool = True\n        self._pool_size: int = 5\n        self._max_overflow: int = 10\n        self._pool_recycle: int = 3600\n        self._pool_pre_ping: bool = True\n\n    @classmethod\n    def in_memory(cls) -&gt; Self:\n        \"\"\"Create an in-memory SQLite database configuration.\"\"\"\n        builder = cls()\n        builder._url = \"sqlite+aiosqlite:///:memory:\"\n        return builder\n\n    @classmethod\n    def from_file(cls, path: str | Path) -&gt; Self:\n        \"\"\"Create a file-based SQLite database configuration.\"\"\"\n        builder = cls()\n        if isinstance(path, Path):\n            path = str(path)\n        builder._url = f\"sqlite+aiosqlite:///{path}\"\n        return builder\n\n    def with_echo(self, enabled: bool = True) -&gt; Self:\n        \"\"\"Enable SQL query logging.\"\"\"\n        self._echo = enabled\n        return self\n\n    def with_migrations(self, enabled: bool = True, alembic_dir: Path | None = None) -&gt; Self:\n        \"\"\"Configure migration behavior.\"\"\"\n        self._auto_migrate = enabled\n        self._alembic_dir = alembic_dir\n        return self\n\n    def with_pool(\n        self,\n        size: int = 5,\n        max_overflow: int = 10,\n        recycle: int = 3600,\n        pre_ping: bool = True,\n    ) -&gt; Self:\n        \"\"\"Configure connection pool settings.\"\"\"\n        self._pool_size = size\n        self._max_overflow = max_overflow\n        self._pool_recycle = recycle\n        self._pool_pre_ping = pre_ping\n        return self\n\n    def build(self) -&gt; SqliteDatabase:\n        \"\"\"Build and return configured SqliteDatabase instance.\"\"\"\n        if not self._url:\n            raise ValueError(\"Database URL not configured. Use .in_memory() or .from_file()\")\n\n        return SqliteDatabase(\n            url=self._url,\n            echo=self._echo,\n            alembic_dir=self._alembic_dir,\n            auto_migrate=self._auto_migrate,\n            pool_size=self._pool_size,\n            max_overflow=self._max_overflow,\n            pool_recycle=self._pool_recycle,\n            pool_pre_ping=self._pool_pre_ping,\n        )\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.SqliteDatabaseBuilder.__init__","title":"<code>__init__()</code>","text":"<p>Initialize builder with default values.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize builder with default values.\"\"\"\n    self._url: str = \"\"\n    self._echo: bool = False\n    self._alembic_dir: Path | None = None\n    self._auto_migrate: bool = True\n    self._pool_size: int = 5\n    self._max_overflow: int = 10\n    self._pool_recycle: int = 3600\n    self._pool_pre_ping: bool = True\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.SqliteDatabaseBuilder.in_memory","title":"<code>in_memory()</code>  <code>classmethod</code>","text":"<p>Create an in-memory SQLite database configuration.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>@classmethod\ndef in_memory(cls) -&gt; Self:\n    \"\"\"Create an in-memory SQLite database configuration.\"\"\"\n    builder = cls()\n    builder._url = \"sqlite+aiosqlite:///:memory:\"\n    return builder\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.SqliteDatabaseBuilder.from_file","title":"<code>from_file(path)</code>  <code>classmethod</code>","text":"<p>Create a file-based SQLite database configuration.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>@classmethod\ndef from_file(cls, path: str | Path) -&gt; Self:\n    \"\"\"Create a file-based SQLite database configuration.\"\"\"\n    builder = cls()\n    if isinstance(path, Path):\n        path = str(path)\n    builder._url = f\"sqlite+aiosqlite:///{path}\"\n    return builder\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.SqliteDatabaseBuilder.with_echo","title":"<code>with_echo(enabled=True)</code>","text":"<p>Enable SQL query logging.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>def with_echo(self, enabled: bool = True) -&gt; Self:\n    \"\"\"Enable SQL query logging.\"\"\"\n    self._echo = enabled\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.SqliteDatabaseBuilder.with_migrations","title":"<code>with_migrations(enabled=True, alembic_dir=None)</code>","text":"<p>Configure migration behavior.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>def with_migrations(self, enabled: bool = True, alembic_dir: Path | None = None) -&gt; Self:\n    \"\"\"Configure migration behavior.\"\"\"\n    self._auto_migrate = enabled\n    self._alembic_dir = alembic_dir\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.SqliteDatabaseBuilder.with_pool","title":"<code>with_pool(size=5, max_overflow=10, recycle=3600, pre_ping=True)</code>","text":"<p>Configure connection pool settings.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>def with_pool(\n    self,\n    size: int = 5,\n    max_overflow: int = 10,\n    recycle: int = 3600,\n    pre_ping: bool = True,\n) -&gt; Self:\n    \"\"\"Configure connection pool settings.\"\"\"\n    self._pool_size = size\n    self._max_overflow = max_overflow\n    self._pool_recycle = recycle\n    self._pool_pre_ping = pre_ping\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.database.SqliteDatabaseBuilder.build","title":"<code>build()</code>","text":"<p>Build and return configured SqliteDatabase instance.</p> Source code in <code>src/chapkit/core/database.py</code> <pre><code>def build(self) -&gt; SqliteDatabase:\n    \"\"\"Build and return configured SqliteDatabase instance.\"\"\"\n    if not self._url:\n        raise ValueError(\"Database URL not configured. Use .in_memory() or .from_file()\")\n\n    return SqliteDatabase(\n        url=self._url,\n        echo=self._echo,\n        alembic_dir=self._alembic_dir,\n        auto_migrate=self._auto_migrate,\n        pool_size=self._pool_size,\n        max_overflow=self._max_overflow,\n        pool_recycle=self._pool_recycle,\n        pool_pre_ping=self._pool_pre_ping,\n    )\n</code></pre>"},{"location":"api-reference/#models","title":"Models","text":""},{"location":"api-reference/#chapkit.core.models","title":"<code>models</code>","text":"<p>Base ORM classes for SQLAlchemy models.</p>"},{"location":"api-reference/#chapkit.core.models.Base","title":"<code>Base</code>","text":"<p>               Bases: <code>AsyncAttrs</code>, <code>DeclarativeBase</code></p> <p>Root declarative base with async support.</p> Source code in <code>src/chapkit/core/models.py</code> <pre><code>class Base(AsyncAttrs, DeclarativeBase):\n    \"\"\"Root declarative base with async support.\"\"\"\n</code></pre>"},{"location":"api-reference/#chapkit.core.models.Entity","title":"<code>Entity</code>","text":"<p>               Bases: <code>Base</code></p> <p>Optional base with common columns for your models.</p> Source code in <code>src/chapkit/core/models.py</code> <pre><code>class Entity(Base):\n    \"\"\"Optional base with common columns for your models.\"\"\"\n\n    __abstract__ = True\n\n    id: Mapped[ULID] = mapped_column(ULIDType, primary_key=True, default=ULID)\n    created_at: Mapped[datetime.datetime] = mapped_column(server_default=func.now())\n    updated_at: Mapped[datetime.datetime] = mapped_column(server_default=func.now(), onupdate=func.now())\n</code></pre>"},{"location":"api-reference/#repository","title":"Repository","text":""},{"location":"api-reference/#chapkit.core.repository","title":"<code>repository</code>","text":"<p>Base repository classes for data access layer.</p>"},{"location":"api-reference/#chapkit.core.repository.Repository","title":"<code>Repository</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract repository interface for data access operations.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>class Repository[T, IdT = ULID](ABC):\n    \"\"\"Abstract repository interface for data access operations.\"\"\"\n\n    @abstractmethod\n    async def save(self, entity: T) -&gt; T:\n        \"\"\"Save an entity to the database.\"\"\"\n        ...\n\n    @abstractmethod\n    async def save_all(self, entities: Iterable[T]) -&gt; Sequence[T]:\n        \"\"\"Save multiple entities to the database.\"\"\"\n        ...\n\n    @abstractmethod\n    async def commit(self) -&gt; None:\n        \"\"\"Commit the current database transaction.\"\"\"\n        ...\n\n    @abstractmethod\n    async def refresh_many(self, entities: Iterable[T]) -&gt; None:\n        \"\"\"Refresh multiple entities from the database.\"\"\"\n        ...\n\n    @abstractmethod\n    async def delete(self, entity: T) -&gt; None:\n        \"\"\"Delete an entity from the database.\"\"\"\n        ...\n\n    @abstractmethod\n    async def delete_by_id(self, id: IdT) -&gt; None:\n        \"\"\"Delete an entity by its ID.\"\"\"\n        ...\n\n    @abstractmethod\n    async def delete_all(self) -&gt; None:\n        \"\"\"Delete all entities from the database.\"\"\"\n        ...\n\n    @abstractmethod\n    async def delete_all_by_id(self, ids: Sequence[IdT]) -&gt; None:\n        \"\"\"Delete multiple entities by their IDs.\"\"\"\n        ...\n\n    @abstractmethod\n    async def count(self) -&gt; int:\n        \"\"\"Count the number of entities.\"\"\"\n        ...\n\n    @abstractmethod\n    async def exists_by_id(self, id: IdT) -&gt; bool:\n        \"\"\"Check if an entity exists by its ID.\"\"\"\n        ...\n\n    @abstractmethod\n    async def find_all(self) -&gt; Sequence[T]:\n        \"\"\"Find all entities.\"\"\"\n        ...\n\n    @abstractmethod\n    async def find_all_paginated(self, offset: int, limit: int) -&gt; Sequence[T]:\n        \"\"\"Find entities with pagination.\"\"\"\n        ...\n\n    @abstractmethod\n    async def find_all_by_id(self, ids: Sequence[IdT]) -&gt; Sequence[T]:\n        \"\"\"Find entities by their IDs.\"\"\"\n        ...\n\n    @abstractmethod\n    async def find_by_id(self, id: IdT) -&gt; T | None:\n        \"\"\"Find an entity by its ID.\"\"\"\n        ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.save","title":"<code>save(entity)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Save an entity to the database.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def save(self, entity: T) -&gt; T:\n    \"\"\"Save an entity to the database.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.save_all","title":"<code>save_all(entities)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Save multiple entities to the database.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def save_all(self, entities: Iterable[T]) -&gt; Sequence[T]:\n    \"\"\"Save multiple entities to the database.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.commit","title":"<code>commit()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Commit the current database transaction.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def commit(self) -&gt; None:\n    \"\"\"Commit the current database transaction.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.refresh_many","title":"<code>refresh_many(entities)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Refresh multiple entities from the database.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def refresh_many(self, entities: Iterable[T]) -&gt; None:\n    \"\"\"Refresh multiple entities from the database.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.delete","title":"<code>delete(entity)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Delete an entity from the database.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def delete(self, entity: T) -&gt; None:\n    \"\"\"Delete an entity from the database.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.delete_by_id","title":"<code>delete_by_id(id)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Delete an entity by its ID.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def delete_by_id(self, id: IdT) -&gt; None:\n    \"\"\"Delete an entity by its ID.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.delete_all","title":"<code>delete_all()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Delete all entities from the database.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def delete_all(self) -&gt; None:\n    \"\"\"Delete all entities from the database.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.delete_all_by_id","title":"<code>delete_all_by_id(ids)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Delete multiple entities by their IDs.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def delete_all_by_id(self, ids: Sequence[IdT]) -&gt; None:\n    \"\"\"Delete multiple entities by their IDs.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.count","title":"<code>count()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Count the number of entities.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def count(self) -&gt; int:\n    \"\"\"Count the number of entities.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.exists_by_id","title":"<code>exists_by_id(id)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Check if an entity exists by its ID.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def exists_by_id(self, id: IdT) -&gt; bool:\n    \"\"\"Check if an entity exists by its ID.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.find_all","title":"<code>find_all()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Find all entities.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def find_all(self) -&gt; Sequence[T]:\n    \"\"\"Find all entities.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.find_all_paginated","title":"<code>find_all_paginated(offset, limit)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Find entities with pagination.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def find_all_paginated(self, offset: int, limit: int) -&gt; Sequence[T]:\n    \"\"\"Find entities with pagination.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.find_all_by_id","title":"<code>find_all_by_id(ids)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Find entities by their IDs.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def find_all_by_id(self, ids: Sequence[IdT]) -&gt; Sequence[T]:\n    \"\"\"Find entities by their IDs.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.Repository.find_by_id","title":"<code>find_by_id(id)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Find an entity by its ID.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>@abstractmethod\nasync def find_by_id(self, id: IdT) -&gt; T | None:\n    \"\"\"Find an entity by its ID.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository","title":"<code>BaseRepository</code>","text":"<p>               Bases: <code>Repository[T, IdT]</code></p> <p>Base repository implementation with common CRUD operations.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>class BaseRepository[T, IdT = ULID](Repository[T, IdT]):\n    \"\"\"Base repository implementation with common CRUD operations.\"\"\"\n\n    def __init__(self, session: AsyncSession, model: type[T]) -&gt; None:\n        \"\"\"Initialize repository with database session and model type.\"\"\"\n        self.s = session\n        self.model = model\n\n    # ---------- Create ----------\n    async def save(self, entity: T) -&gt; T:\n        \"\"\"Save an entity to the database.\"\"\"\n        self.s.add(entity)\n        return entity\n\n    async def save_all(self, entities: Iterable[T]) -&gt; Sequence[T]:\n        \"\"\"Save multiple entities to the database.\"\"\"\n        entity_list = list(entities)\n        self.s.add_all(entity_list)\n        return entity_list\n\n    async def commit(self) -&gt; None:\n        \"\"\"Commit the current database transaction.\"\"\"\n        await self.s.commit()\n\n    async def refresh_many(self, entities: Iterable[T]) -&gt; None:\n        \"\"\"Refresh multiple entities from the database.\"\"\"\n        for e in entities:\n            await self.s.refresh(e)\n\n    # ---------- Delete ----------\n    async def delete(self, entity: T) -&gt; None:\n        \"\"\"Delete an entity from the database.\"\"\"\n        await self.s.delete(entity)\n\n    async def delete_by_id(self, id: IdT) -&gt; None:\n        \"\"\"Delete an entity by its ID.\"\"\"\n        id_col = getattr(self.model, \"id\")\n        await self.s.execute(delete(self.model).where(id_col == id))\n\n    async def delete_all(self) -&gt; None:\n        \"\"\"Delete all entities from the database.\"\"\"\n        await self.s.execute(delete(self.model))\n\n    async def delete_all_by_id(self, ids: Sequence[IdT]) -&gt; None:\n        \"\"\"Delete multiple entities by their IDs.\"\"\"\n        if not ids:\n            return\n        # Access the \"id\" column generically\n        id_col = getattr(self.model, \"id\")\n        await self.s.execute(delete(self.model).where(id_col.in_(ids)))\n\n    # ---------- Read / Count ----------\n    async def count(self) -&gt; int:\n        \"\"\"Count the number of entities.\"\"\"\n        return await self.s.scalar(select(func.count()).select_from(self.model)) or 0\n\n    async def exists_by_id(self, id: IdT) -&gt; bool:\n        \"\"\"Check if an entity exists by its ID.\"\"\"\n        # Access the \"id\" column generically\n        id_col = getattr(self.model, \"id\")\n        q = select(select(id_col).where(id_col == id).exists())\n        return await self.s.scalar(q) or False\n\n    async def find_all(self) -&gt; Sequence[T]:\n        \"\"\"Find all entities.\"\"\"\n        result = await self.s.scalars(select(self.model))\n        return result.all()\n\n    async def find_all_paginated(self, offset: int, limit: int) -&gt; Sequence[T]:\n        \"\"\"Find entities with pagination.\"\"\"\n        result = await self.s.scalars(select(self.model).offset(offset).limit(limit))\n        return result.all()\n\n    async def find_all_by_id(self, ids: Sequence[IdT]) -&gt; Sequence[T]:\n        \"\"\"Find entities by their IDs.\"\"\"\n        if not ids:\n            return []\n        id_col = getattr(self.model, \"id\")\n        result = await self.s.scalars(select(self.model).where(id_col.in_(ids)))\n        return result.all()\n\n    async def find_by_id(self, id: IdT) -&gt; T | None:\n        \"\"\"Find an entity by its ID.\"\"\"\n        return await self.s.get(self.model, id)\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.__init__","title":"<code>__init__(session, model)</code>","text":"<p>Initialize repository with database session and model type.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>def __init__(self, session: AsyncSession, model: type[T]) -&gt; None:\n    \"\"\"Initialize repository with database session and model type.\"\"\"\n    self.s = session\n    self.model = model\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.save","title":"<code>save(entity)</code>  <code>async</code>","text":"<p>Save an entity to the database.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def save(self, entity: T) -&gt; T:\n    \"\"\"Save an entity to the database.\"\"\"\n    self.s.add(entity)\n    return entity\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.save_all","title":"<code>save_all(entities)</code>  <code>async</code>","text":"<p>Save multiple entities to the database.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def save_all(self, entities: Iterable[T]) -&gt; Sequence[T]:\n    \"\"\"Save multiple entities to the database.\"\"\"\n    entity_list = list(entities)\n    self.s.add_all(entity_list)\n    return entity_list\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.commit","title":"<code>commit()</code>  <code>async</code>","text":"<p>Commit the current database transaction.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def commit(self) -&gt; None:\n    \"\"\"Commit the current database transaction.\"\"\"\n    await self.s.commit()\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.refresh_many","title":"<code>refresh_many(entities)</code>  <code>async</code>","text":"<p>Refresh multiple entities from the database.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def refresh_many(self, entities: Iterable[T]) -&gt; None:\n    \"\"\"Refresh multiple entities from the database.\"\"\"\n    for e in entities:\n        await self.s.refresh(e)\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.delete","title":"<code>delete(entity)</code>  <code>async</code>","text":"<p>Delete an entity from the database.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def delete(self, entity: T) -&gt; None:\n    \"\"\"Delete an entity from the database.\"\"\"\n    await self.s.delete(entity)\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.delete_by_id","title":"<code>delete_by_id(id)</code>  <code>async</code>","text":"<p>Delete an entity by its ID.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def delete_by_id(self, id: IdT) -&gt; None:\n    \"\"\"Delete an entity by its ID.\"\"\"\n    id_col = getattr(self.model, \"id\")\n    await self.s.execute(delete(self.model).where(id_col == id))\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.delete_all","title":"<code>delete_all()</code>  <code>async</code>","text":"<p>Delete all entities from the database.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def delete_all(self) -&gt; None:\n    \"\"\"Delete all entities from the database.\"\"\"\n    await self.s.execute(delete(self.model))\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.delete_all_by_id","title":"<code>delete_all_by_id(ids)</code>  <code>async</code>","text":"<p>Delete multiple entities by their IDs.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def delete_all_by_id(self, ids: Sequence[IdT]) -&gt; None:\n    \"\"\"Delete multiple entities by their IDs.\"\"\"\n    if not ids:\n        return\n    # Access the \"id\" column generically\n    id_col = getattr(self.model, \"id\")\n    await self.s.execute(delete(self.model).where(id_col.in_(ids)))\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.count","title":"<code>count()</code>  <code>async</code>","text":"<p>Count the number of entities.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def count(self) -&gt; int:\n    \"\"\"Count the number of entities.\"\"\"\n    return await self.s.scalar(select(func.count()).select_from(self.model)) or 0\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.exists_by_id","title":"<code>exists_by_id(id)</code>  <code>async</code>","text":"<p>Check if an entity exists by its ID.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def exists_by_id(self, id: IdT) -&gt; bool:\n    \"\"\"Check if an entity exists by its ID.\"\"\"\n    # Access the \"id\" column generically\n    id_col = getattr(self.model, \"id\")\n    q = select(select(id_col).where(id_col == id).exists())\n    return await self.s.scalar(q) or False\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.find_all","title":"<code>find_all()</code>  <code>async</code>","text":"<p>Find all entities.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def find_all(self) -&gt; Sequence[T]:\n    \"\"\"Find all entities.\"\"\"\n    result = await self.s.scalars(select(self.model))\n    return result.all()\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.find_all_paginated","title":"<code>find_all_paginated(offset, limit)</code>  <code>async</code>","text":"<p>Find entities with pagination.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def find_all_paginated(self, offset: int, limit: int) -&gt; Sequence[T]:\n    \"\"\"Find entities with pagination.\"\"\"\n    result = await self.s.scalars(select(self.model).offset(offset).limit(limit))\n    return result.all()\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.find_all_by_id","title":"<code>find_all_by_id(ids)</code>  <code>async</code>","text":"<p>Find entities by their IDs.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def find_all_by_id(self, ids: Sequence[IdT]) -&gt; Sequence[T]:\n    \"\"\"Find entities by their IDs.\"\"\"\n    if not ids:\n        return []\n    id_col = getattr(self.model, \"id\")\n    result = await self.s.scalars(select(self.model).where(id_col.in_(ids)))\n    return result.all()\n</code></pre>"},{"location":"api-reference/#chapkit.core.repository.BaseRepository.find_by_id","title":"<code>find_by_id(id)</code>  <code>async</code>","text":"<p>Find an entity by its ID.</p> Source code in <code>src/chapkit/core/repository.py</code> <pre><code>async def find_by_id(self, id: IdT) -&gt; T | None:\n    \"\"\"Find an entity by its ID.\"\"\"\n    return await self.s.get(self.model, id)\n</code></pre>"},{"location":"api-reference/#manager","title":"Manager","text":""},{"location":"api-reference/#chapkit.core.manager","title":"<code>manager</code>","text":"<p>Base classes for service layer managers with lifecycle hooks.</p>"},{"location":"api-reference/#chapkit.core.manager.LifecycleHooks","title":"<code>LifecycleHooks</code>","text":"<p>Lifecycle hooks for entity operations.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>class LifecycleHooks[ModelT, InSchemaT: BaseModel]:\n    \"\"\"Lifecycle hooks for entity operations.\"\"\"\n\n    def _should_assign_field(self, field: str, value: object) -&gt; bool:\n        \"\"\"Determine if a field should be assigned during update.\"\"\"\n        return True\n\n    async def pre_save(self, entity: ModelT, data: InSchemaT) -&gt; None:\n        \"\"\"Hook called before saving a new entity.\"\"\"\n        pass\n\n    async def post_save(self, entity: ModelT) -&gt; None:\n        \"\"\"Hook called after saving a new entity.\"\"\"\n        pass\n\n    async def pre_update(self, entity: ModelT, data: InSchemaT, old_values: dict[str, object]) -&gt; None:\n        \"\"\"Hook called before updating an existing entity.\"\"\"\n        pass\n\n    async def post_update(self, entity: ModelT, changes: dict[str, tuple[object, object]]) -&gt; None:\n        \"\"\"Hook called after updating an existing entity.\"\"\"\n        pass\n\n    async def pre_delete(self, entity: ModelT) -&gt; None:\n        \"\"\"Hook called before deleting an entity.\"\"\"\n        pass\n\n    async def post_delete(self, entity: ModelT) -&gt; None:\n        \"\"\"Hook called after deleting an entity.\"\"\"\n        pass\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.LifecycleHooks.pre_save","title":"<code>pre_save(entity, data)</code>  <code>async</code>","text":"<p>Hook called before saving a new entity.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def pre_save(self, entity: ModelT, data: InSchemaT) -&gt; None:\n    \"\"\"Hook called before saving a new entity.\"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.LifecycleHooks.post_save","title":"<code>post_save(entity)</code>  <code>async</code>","text":"<p>Hook called after saving a new entity.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def post_save(self, entity: ModelT) -&gt; None:\n    \"\"\"Hook called after saving a new entity.\"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.LifecycleHooks.pre_update","title":"<code>pre_update(entity, data, old_values)</code>  <code>async</code>","text":"<p>Hook called before updating an existing entity.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def pre_update(self, entity: ModelT, data: InSchemaT, old_values: dict[str, object]) -&gt; None:\n    \"\"\"Hook called before updating an existing entity.\"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.LifecycleHooks.post_update","title":"<code>post_update(entity, changes)</code>  <code>async</code>","text":"<p>Hook called after updating an existing entity.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def post_update(self, entity: ModelT, changes: dict[str, tuple[object, object]]) -&gt; None:\n    \"\"\"Hook called after updating an existing entity.\"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.LifecycleHooks.pre_delete","title":"<code>pre_delete(entity)</code>  <code>async</code>","text":"<p>Hook called before deleting an entity.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def pre_delete(self, entity: ModelT) -&gt; None:\n    \"\"\"Hook called before deleting an entity.\"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.LifecycleHooks.post_delete","title":"<code>post_delete(entity)</code>  <code>async</code>","text":"<p>Hook called after deleting an entity.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def post_delete(self, entity: ModelT) -&gt; None:\n    \"\"\"Hook called after deleting an entity.\"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.Manager","title":"<code>Manager</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract manager interface for business logic operations.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>class Manager[InSchemaT: BaseModel, OutSchemaT: BaseModel, IdT](ABC):\n    \"\"\"Abstract manager interface for business logic operations.\"\"\"\n\n    @abstractmethod\n    async def save(self, data: InSchemaT) -&gt; OutSchemaT:\n        \"\"\"Save an entity.\"\"\"\n        ...\n\n    @abstractmethod\n    async def save_all(self, items: Iterable[InSchemaT]) -&gt; list[OutSchemaT]:\n        \"\"\"Save multiple entities.\"\"\"\n        ...\n\n    @abstractmethod\n    async def delete_by_id(self, id: IdT) -&gt; None:\n        \"\"\"Delete an entity by its ID.\"\"\"\n        ...\n\n    @abstractmethod\n    async def delete_all(self) -&gt; None:\n        \"\"\"Delete all entities.\"\"\"\n        ...\n\n    @abstractmethod\n    async def delete_all_by_id(self, ids: Sequence[IdT]) -&gt; None:\n        \"\"\"Delete multiple entities by their IDs.\"\"\"\n        ...\n\n    @abstractmethod\n    async def count(self) -&gt; int:\n        \"\"\"Count the number of entities.\"\"\"\n        ...\n\n    @abstractmethod\n    async def exists_by_id(self, id: IdT) -&gt; bool:\n        \"\"\"Check if an entity exists by its ID.\"\"\"\n        ...\n\n    @abstractmethod\n    async def find_by_id(self, id: IdT) -&gt; OutSchemaT | None:\n        \"\"\"Find an entity by its ID.\"\"\"\n        ...\n\n    @abstractmethod\n    async def find_all(self) -&gt; list[OutSchemaT]:\n        \"\"\"Find all entities.\"\"\"\n        ...\n\n    @abstractmethod\n    async def find_paginated(self, page: int, size: int) -&gt; tuple[list[OutSchemaT], int]:\n        \"\"\"Find entities with pagination.\"\"\"\n        ...\n\n    @abstractmethod\n    async def find_all_by_id(self, ids: Sequence[IdT]) -&gt; list[OutSchemaT]:\n        \"\"\"Find entities by their IDs.\"\"\"\n        ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.Manager.save","title":"<code>save(data)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Save an entity.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>@abstractmethod\nasync def save(self, data: InSchemaT) -&gt; OutSchemaT:\n    \"\"\"Save an entity.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.Manager.save_all","title":"<code>save_all(items)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Save multiple entities.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>@abstractmethod\nasync def save_all(self, items: Iterable[InSchemaT]) -&gt; list[OutSchemaT]:\n    \"\"\"Save multiple entities.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.Manager.delete_by_id","title":"<code>delete_by_id(id)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Delete an entity by its ID.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>@abstractmethod\nasync def delete_by_id(self, id: IdT) -&gt; None:\n    \"\"\"Delete an entity by its ID.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.Manager.delete_all","title":"<code>delete_all()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Delete all entities.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>@abstractmethod\nasync def delete_all(self) -&gt; None:\n    \"\"\"Delete all entities.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.Manager.delete_all_by_id","title":"<code>delete_all_by_id(ids)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Delete multiple entities by their IDs.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>@abstractmethod\nasync def delete_all_by_id(self, ids: Sequence[IdT]) -&gt; None:\n    \"\"\"Delete multiple entities by their IDs.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.Manager.count","title":"<code>count()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Count the number of entities.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>@abstractmethod\nasync def count(self) -&gt; int:\n    \"\"\"Count the number of entities.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.Manager.exists_by_id","title":"<code>exists_by_id(id)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Check if an entity exists by its ID.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>@abstractmethod\nasync def exists_by_id(self, id: IdT) -&gt; bool:\n    \"\"\"Check if an entity exists by its ID.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.Manager.find_by_id","title":"<code>find_by_id(id)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Find an entity by its ID.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>@abstractmethod\nasync def find_by_id(self, id: IdT) -&gt; OutSchemaT | None:\n    \"\"\"Find an entity by its ID.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.Manager.find_all","title":"<code>find_all()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Find all entities.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>@abstractmethod\nasync def find_all(self) -&gt; list[OutSchemaT]:\n    \"\"\"Find all entities.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.Manager.find_paginated","title":"<code>find_paginated(page, size)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Find entities with pagination.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>@abstractmethod\nasync def find_paginated(self, page: int, size: int) -&gt; tuple[list[OutSchemaT], int]:\n    \"\"\"Find entities with pagination.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.Manager.find_all_by_id","title":"<code>find_all_by_id(ids)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Find entities by their IDs.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>@abstractmethod\nasync def find_all_by_id(self, ids: Sequence[IdT]) -&gt; list[OutSchemaT]:\n    \"\"\"Find entities by their IDs.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.BaseManager","title":"<code>BaseManager</code>","text":"<p>               Bases: <code>LifecycleHooks[ModelT, InSchemaT]</code>, <code>Manager[InSchemaT, OutSchemaT, IdT]</code></p> <p>Base manager implementation with CRUD operations and lifecycle hooks.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>class BaseManager[ModelT, InSchemaT: BaseModel, OutSchemaT: BaseModel, IdT](\n    LifecycleHooks[ModelT, InSchemaT],\n    Manager[InSchemaT, OutSchemaT, IdT],\n):\n    \"\"\"Base manager implementation with CRUD operations and lifecycle hooks.\"\"\"\n\n    def __init__(\n        self,\n        repo: BaseRepository[ModelT, IdT],\n        model_cls: type[ModelT],\n        out_schema_cls: type[OutSchemaT],\n    ) -&gt; None:\n        \"\"\"Initialize manager with repository, model class, and output schema class.\"\"\"\n        self.repo = repo\n        self.model_cls = model_cls\n        self.out_schema_cls = out_schema_cls\n\n    def _to_output_schema(self, entity: ModelT) -&gt; OutSchemaT:\n        \"\"\"Convert ORM entity to output schema.\"\"\"\n        return self.out_schema_cls.model_validate(entity, from_attributes=True)\n\n    async def save(self, data: InSchemaT) -&gt; OutSchemaT:\n        \"\"\"Save an entity (create or update).\"\"\"\n        data_dict = data.model_dump(exclude_none=True)\n        entity_id = data_dict.get(\"id\")\n        existing: ModelT | None = None\n\n        if entity_id is not None:\n            existing = await self.repo.find_by_id(entity_id)\n\n        if existing is None:\n            if data_dict.get(\"id\") is None:\n                data_dict.pop(\"id\", None)\n            entity = self.model_cls(**data_dict)\n            await self.pre_save(entity, data)\n            await self.repo.save(entity)\n            await self.repo.commit()\n            await self.repo.refresh_many([entity])\n            await self.post_save(entity)\n            return self._to_output_schema(entity)\n\n        tracked_fields = set(data_dict.keys())\n        if hasattr(existing, \"level\"):  # pragma: no branch\n            tracked_fields.add(\"level\")\n        old_values = {field: getattr(existing, field) for field in tracked_fields if hasattr(existing, field)}\n\n        for key, value in data_dict.items():\n            if key == \"id\":  # pragma: no branch\n                continue\n            if not self._should_assign_field(key, value):\n                continue\n            if hasattr(existing, key):\n                setattr(existing, key, value)\n\n        await self.pre_update(existing, data, old_values)\n\n        changes: dict[str, tuple[object, object]] = {}\n        for field in tracked_fields:\n            if hasattr(existing, field):\n                new_value = getattr(existing, field)\n                old_value = old_values.get(field)\n                if old_value != new_value:\n                    changes[field] = (old_value, new_value)\n\n        await self.repo.save(existing)\n        await self.repo.commit()\n        await self.repo.refresh_many([existing])\n        await self.post_update(existing, changes)\n        return self._to_output_schema(existing)\n\n    async def save_all(self, items: Iterable[InSchemaT]) -&gt; list[OutSchemaT]:\n        entities_to_insert: list[ModelT] = []\n        updates: list[tuple[ModelT, dict[str, tuple[object, object]]]] = []\n        outputs: list[ModelT] = []\n\n        for data in items:\n            data_dict = data.model_dump(exclude_none=True)\n            entity_id = data_dict.get(\"id\")\n            existing: ModelT | None = None\n            if entity_id is not None:\n                existing = await self.repo.find_by_id(entity_id)\n\n            if existing is None:\n                if data_dict.get(\"id\") is None:\n                    data_dict.pop(\"id\", None)\n                entity = self.model_cls(**data_dict)\n                await self.pre_save(entity, data)\n                entities_to_insert.append(entity)\n                outputs.append(entity)\n                continue\n\n            tracked_fields = set(data_dict.keys())\n            if hasattr(existing, \"level\"):  # pragma: no branch\n                tracked_fields.add(\"level\")\n            old_values = {field: getattr(existing, field) for field in tracked_fields if hasattr(existing, field)}\n\n            for key, value in data_dict.items():\n                if key == \"id\":  # pragma: no branch\n                    continue\n                if not self._should_assign_field(key, value):\n                    continue\n                if hasattr(existing, key):\n                    setattr(existing, key, value)\n\n            await self.pre_update(existing, data, old_values)\n\n            changes: dict[str, tuple[object, object]] = {}\n            for field in tracked_fields:\n                if hasattr(existing, field):\n                    new_value = getattr(existing, field)\n                    old_value = old_values.get(field)\n                    if old_value != new_value:\n                        changes[field] = (old_value, new_value)\n\n            updates.append((existing, changes))\n            outputs.append(existing)\n\n        if entities_to_insert:  # pragma: no branch\n            await self.repo.save_all(entities_to_insert)\n        await self.repo.commit()\n        if outputs:  # pragma: no branch\n            await self.repo.refresh_many(outputs)\n\n        for entity in entities_to_insert:\n            await self.post_save(entity)\n        for entity, changes in updates:\n            await self.post_update(entity, changes)\n\n        return [self._to_output_schema(entity) for entity in outputs]\n\n    async def delete_by_id(self, id: IdT) -&gt; None:\n        \"\"\"Delete an entity by its ID.\"\"\"\n        entity = await self.repo.find_by_id(id)\n        if entity is None:\n            return\n        await self.pre_delete(entity)\n        await self.repo.delete(entity)\n        await self.repo.commit()\n        await self.post_delete(entity)\n\n    async def delete_all(self) -&gt; None:\n        \"\"\"Delete all entities.\"\"\"\n        entities = await self.repo.find_all()\n        for entity in entities:\n            await self.pre_delete(entity)\n        await self.repo.delete_all()\n        await self.repo.commit()\n        for entity in entities:\n            await self.post_delete(entity)\n\n    async def delete_all_by_id(self, ids: Sequence[IdT]) -&gt; None:\n        \"\"\"Delete multiple entities by their IDs.\"\"\"\n        if not ids:\n            return\n        entities = await self.repo.find_all_by_id(ids)\n        for entity in entities:\n            await self.pre_delete(entity)\n        await self.repo.delete_all_by_id(ids)\n        await self.repo.commit()\n        for entity in entities:\n            await self.post_delete(entity)\n\n    async def count(self) -&gt; int:\n        \"\"\"Count the number of entities.\"\"\"\n        return await self.repo.count()\n\n    async def exists_by_id(self, id: IdT) -&gt; bool:\n        \"\"\"Check if an entity exists by its ID.\"\"\"\n        return await self.repo.exists_by_id(id)\n\n    async def find_by_id(self, id: IdT) -&gt; OutSchemaT | None:\n        \"\"\"Find an entity by its ID.\"\"\"\n        entity = await self.repo.find_by_id(id)\n        if entity is None:\n            return None\n        return self._to_output_schema(entity)\n\n    async def find_all(self) -&gt; list[OutSchemaT]:\n        \"\"\"Find all entities.\"\"\"\n        entities = await self.repo.find_all()\n        return [self._to_output_schema(e) for e in entities]\n\n    async def find_paginated(self, page: int, size: int) -&gt; tuple[list[OutSchemaT], int]:\n        \"\"\"Find entities with pagination.\"\"\"\n        offset = (page - 1) * size\n        entities = await self.repo.find_all_paginated(offset, size)\n        total = await self.repo.count()\n        return [self._to_output_schema(e) for e in entities], total\n\n    async def find_all_by_id(self, ids: Sequence[IdT]) -&gt; list[OutSchemaT]:\n        \"\"\"Find entities by their IDs.\"\"\"\n        entities = await self.repo.find_all_by_id(ids)\n        return [self._to_output_schema(e) for e in entities]\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.BaseManager.__init__","title":"<code>__init__(repo, model_cls, out_schema_cls)</code>","text":"<p>Initialize manager with repository, model class, and output schema class.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>def __init__(\n    self,\n    repo: BaseRepository[ModelT, IdT],\n    model_cls: type[ModelT],\n    out_schema_cls: type[OutSchemaT],\n) -&gt; None:\n    \"\"\"Initialize manager with repository, model class, and output schema class.\"\"\"\n    self.repo = repo\n    self.model_cls = model_cls\n    self.out_schema_cls = out_schema_cls\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.BaseManager.save","title":"<code>save(data)</code>  <code>async</code>","text":"<p>Save an entity (create or update).</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def save(self, data: InSchemaT) -&gt; OutSchemaT:\n    \"\"\"Save an entity (create or update).\"\"\"\n    data_dict = data.model_dump(exclude_none=True)\n    entity_id = data_dict.get(\"id\")\n    existing: ModelT | None = None\n\n    if entity_id is not None:\n        existing = await self.repo.find_by_id(entity_id)\n\n    if existing is None:\n        if data_dict.get(\"id\") is None:\n            data_dict.pop(\"id\", None)\n        entity = self.model_cls(**data_dict)\n        await self.pre_save(entity, data)\n        await self.repo.save(entity)\n        await self.repo.commit()\n        await self.repo.refresh_many([entity])\n        await self.post_save(entity)\n        return self._to_output_schema(entity)\n\n    tracked_fields = set(data_dict.keys())\n    if hasattr(existing, \"level\"):  # pragma: no branch\n        tracked_fields.add(\"level\")\n    old_values = {field: getattr(existing, field) for field in tracked_fields if hasattr(existing, field)}\n\n    for key, value in data_dict.items():\n        if key == \"id\":  # pragma: no branch\n            continue\n        if not self._should_assign_field(key, value):\n            continue\n        if hasattr(existing, key):\n            setattr(existing, key, value)\n\n    await self.pre_update(existing, data, old_values)\n\n    changes: dict[str, tuple[object, object]] = {}\n    for field in tracked_fields:\n        if hasattr(existing, field):\n            new_value = getattr(existing, field)\n            old_value = old_values.get(field)\n            if old_value != new_value:\n                changes[field] = (old_value, new_value)\n\n    await self.repo.save(existing)\n    await self.repo.commit()\n    await self.repo.refresh_many([existing])\n    await self.post_update(existing, changes)\n    return self._to_output_schema(existing)\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.BaseManager.delete_by_id","title":"<code>delete_by_id(id)</code>  <code>async</code>","text":"<p>Delete an entity by its ID.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def delete_by_id(self, id: IdT) -&gt; None:\n    \"\"\"Delete an entity by its ID.\"\"\"\n    entity = await self.repo.find_by_id(id)\n    if entity is None:\n        return\n    await self.pre_delete(entity)\n    await self.repo.delete(entity)\n    await self.repo.commit()\n    await self.post_delete(entity)\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.BaseManager.delete_all","title":"<code>delete_all()</code>  <code>async</code>","text":"<p>Delete all entities.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def delete_all(self) -&gt; None:\n    \"\"\"Delete all entities.\"\"\"\n    entities = await self.repo.find_all()\n    for entity in entities:\n        await self.pre_delete(entity)\n    await self.repo.delete_all()\n    await self.repo.commit()\n    for entity in entities:\n        await self.post_delete(entity)\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.BaseManager.delete_all_by_id","title":"<code>delete_all_by_id(ids)</code>  <code>async</code>","text":"<p>Delete multiple entities by their IDs.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def delete_all_by_id(self, ids: Sequence[IdT]) -&gt; None:\n    \"\"\"Delete multiple entities by their IDs.\"\"\"\n    if not ids:\n        return\n    entities = await self.repo.find_all_by_id(ids)\n    for entity in entities:\n        await self.pre_delete(entity)\n    await self.repo.delete_all_by_id(ids)\n    await self.repo.commit()\n    for entity in entities:\n        await self.post_delete(entity)\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.BaseManager.count","title":"<code>count()</code>  <code>async</code>","text":"<p>Count the number of entities.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def count(self) -&gt; int:\n    \"\"\"Count the number of entities.\"\"\"\n    return await self.repo.count()\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.BaseManager.exists_by_id","title":"<code>exists_by_id(id)</code>  <code>async</code>","text":"<p>Check if an entity exists by its ID.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def exists_by_id(self, id: IdT) -&gt; bool:\n    \"\"\"Check if an entity exists by its ID.\"\"\"\n    return await self.repo.exists_by_id(id)\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.BaseManager.find_by_id","title":"<code>find_by_id(id)</code>  <code>async</code>","text":"<p>Find an entity by its ID.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def find_by_id(self, id: IdT) -&gt; OutSchemaT | None:\n    \"\"\"Find an entity by its ID.\"\"\"\n    entity = await self.repo.find_by_id(id)\n    if entity is None:\n        return None\n    return self._to_output_schema(entity)\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.BaseManager.find_all","title":"<code>find_all()</code>  <code>async</code>","text":"<p>Find all entities.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def find_all(self) -&gt; list[OutSchemaT]:\n    \"\"\"Find all entities.\"\"\"\n    entities = await self.repo.find_all()\n    return [self._to_output_schema(e) for e in entities]\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.BaseManager.find_paginated","title":"<code>find_paginated(page, size)</code>  <code>async</code>","text":"<p>Find entities with pagination.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def find_paginated(self, page: int, size: int) -&gt; tuple[list[OutSchemaT], int]:\n    \"\"\"Find entities with pagination.\"\"\"\n    offset = (page - 1) * size\n    entities = await self.repo.find_all_paginated(offset, size)\n    total = await self.repo.count()\n    return [self._to_output_schema(e) for e in entities], total\n</code></pre>"},{"location":"api-reference/#chapkit.core.manager.BaseManager.find_all_by_id","title":"<code>find_all_by_id(ids)</code>  <code>async</code>","text":"<p>Find entities by their IDs.</p> Source code in <code>src/chapkit/core/manager.py</code> <pre><code>async def find_all_by_id(self, ids: Sequence[IdT]) -&gt; list[OutSchemaT]:\n    \"\"\"Find entities by their IDs.\"\"\"\n    entities = await self.repo.find_all_by_id(ids)\n    return [self._to_output_schema(e) for e in entities]\n</code></pre>"},{"location":"api-reference/#schemas","title":"Schemas","text":""},{"location":"api-reference/#chapkit.core.schemas","title":"<code>schemas</code>","text":"<p>Core Pydantic schemas for entities, responses, and jobs.</p>"},{"location":"api-reference/#chapkit.core.schemas.EntityIn","title":"<code>EntityIn</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base input schema for entities with optional ID.</p> Source code in <code>src/chapkit/core/schemas.py</code> <pre><code>class EntityIn(BaseModel):\n    \"\"\"Base input schema for entities with optional ID.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    id: ULID | None = None\n</code></pre>"},{"location":"api-reference/#chapkit.core.schemas.EntityOut","title":"<code>EntityOut</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base output schema for entities with ID and timestamps.</p> Source code in <code>src/chapkit/core/schemas.py</code> <pre><code>class EntityOut(BaseModel):\n    \"\"\"Base output schema for entities with ID and timestamps.\"\"\"\n\n    model_config = ConfigDict(from_attributes=True, arbitrary_types_allowed=True)\n\n    id: ULID\n    created_at: datetime\n    updated_at: datetime\n</code></pre>"},{"location":"api-reference/#chapkit.core.schemas.PaginatedResponse","title":"<code>PaginatedResponse</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[T]</code></p> <p>Paginated response with items, total count, page number, and computed page count.</p> Source code in <code>src/chapkit/core/schemas.py</code> <pre><code>class PaginatedResponse(BaseModel, Generic[T]):\n    \"\"\"Paginated response with items, total count, page number, and computed page count.\"\"\"\n\n    items: list[T] = Field(description=\"List of items for the current page\")\n    total: int = Field(description=\"Total number of items across all pages\", ge=0)\n    page: int = Field(description=\"Current page number (1-indexed)\", ge=1)\n    size: int = Field(description=\"Number of items per page\", ge=1)\n\n    @computed_field  # type: ignore[prop-decorator]\n    @property\n    def pages(self) -&gt; int:\n        \"\"\"Total number of pages.\"\"\"\n        if self.total == 0:\n            return 0\n        return (self.total + self.size - 1) // self.size\n</code></pre>"},{"location":"api-reference/#chapkit.core.schemas.PaginatedResponse.pages","title":"<code>pages</code>  <code>property</code>","text":"<p>Total number of pages.</p>"},{"location":"api-reference/#chapkit.core.schemas.BulkOperationError","title":"<code>BulkOperationError</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Error information for a single item in a bulk operation.</p> Source code in <code>src/chapkit/core/schemas.py</code> <pre><code>class BulkOperationError(BaseModel):\n    \"\"\"Error information for a single item in a bulk operation.\"\"\"\n\n    id: str = Field(description=\"Identifier of the item that failed\")\n    reason: str = Field(description=\"Human-readable error message\")\n</code></pre>"},{"location":"api-reference/#chapkit.core.schemas.BulkOperationResult","title":"<code>BulkOperationResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of bulk operation with counts of succeeded/failed items and error details.</p> Source code in <code>src/chapkit/core/schemas.py</code> <pre><code>class BulkOperationResult(BaseModel):\n    \"\"\"Result of bulk operation with counts of succeeded/failed items and error details.\"\"\"\n\n    total: int = Field(description=\"Total number of items processed\", ge=0)\n    succeeded: int = Field(description=\"Number of items successfully processed\", ge=0)\n    failed: int = Field(description=\"Number of items that failed\", ge=0)\n    errors: list[BulkOperationError] = Field(default_factory=list, description=\"Details of failed items (if any)\")\n</code></pre>"},{"location":"api-reference/#chapkit.core.schemas.ProblemDetail","title":"<code>ProblemDetail</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>RFC 9457 Problem Details with URN error type, status, and human-readable messages.</p> Source code in <code>src/chapkit/core/schemas.py</code> <pre><code>class ProblemDetail(BaseModel):\n    \"\"\"RFC 9457 Problem Details with URN error type, status, and human-readable messages.\"\"\"\n\n    type: str = Field(\n        default=\"about:blank\",\n        description=\"URI reference identifying the problem type (URN format for chapkit errors)\",\n    )\n    title: str = Field(description=\"Short, human-readable summary of the problem type\")\n    status: int = Field(description=\"HTTP status code\", ge=100, le=599)\n    detail: str | None = Field(default=None, description=\"Human-readable explanation specific to this occurrence\")\n    instance: str | None = Field(default=None, description=\"URI reference identifying the specific occurrence\")\n    trace_id: str | None = Field(default=None, description=\"Optional trace ID for debugging\")\n\n    model_config = {\n        \"json_schema_extra\": {\n            \"examples\": [\n                {\n                    \"type\": \"urn:chapkit:error:not-found\",\n                    \"title\": \"Resource Not Found\",\n                    \"status\": 404,\n                    \"detail\": \"Config with id 01ABC... not found\",\n                    \"instance\": \"/api/config/01ABC...\",\n                }\n            ]\n        }\n    }\n</code></pre>"},{"location":"api-reference/#chapkit.core.schemas.JobStatus","title":"<code>JobStatus</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Status of a scheduled job.</p> Source code in <code>src/chapkit/core/schemas.py</code> <pre><code>class JobStatus(StrEnum):\n    \"\"\"Status of a scheduled job.\"\"\"\n\n    pending = \"pending\"\n    running = \"running\"\n    completed = \"completed\"\n    failed = \"failed\"\n    canceled = \"canceled\"\n</code></pre>"},{"location":"api-reference/#chapkit.core.schemas.JobRecord","title":"<code>JobRecord</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete record of a scheduled job's state and metadata.</p> Source code in <code>src/chapkit/core/schemas.py</code> <pre><code>class JobRecord(BaseModel):\n    \"\"\"Complete record of a scheduled job's state and metadata.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    id: ULID = Field(description=\"Unique job identifier\")\n    status: JobStatus = Field(default=JobStatus.pending, description=\"Current job status\")\n    submitted_at: datetime | None = Field(default=None, description=\"When the job was submitted\")\n    started_at: datetime | None = Field(default=None, description=\"When the job started running\")\n    finished_at: datetime | None = Field(default=None, description=\"When the job finished\")\n    error: str | None = Field(default=None, description=\"User-friendly error message if job failed\")\n    error_traceback: str | None = Field(default=None, description=\"Full error traceback for debugging\")\n    artifact_id: ULID | None = Field(default=None, description=\"ID of artifact created by job (if job returns a ULID)\")\n</code></pre>"},{"location":"api-reference/#exceptions","title":"Exceptions","text":""},{"location":"api-reference/#chapkit.core.exceptions","title":"<code>exceptions</code>","text":"<p>Custom exceptions with RFC 9457 Problem Details support.</p>"},{"location":"api-reference/#chapkit.core.exceptions.ErrorType","title":"<code>ErrorType</code>","text":"<p>URN-based error type identifiers for RFC 9457 Problem Details.</p> Source code in <code>src/chapkit/core/exceptions.py</code> <pre><code>class ErrorType:\n    \"\"\"URN-based error type identifiers for RFC 9457 Problem Details.\"\"\"\n\n    NOT_FOUND = \"urn:chapkit:error:not-found\"\n    VALIDATION_FAILED = \"urn:chapkit:error:validation-failed\"\n    CONFLICT = \"urn:chapkit:error:conflict\"\n    INVALID_ULID = \"urn:chapkit:error:invalid-ulid\"\n    INTERNAL_ERROR = \"urn:chapkit:error:internal\"\n    UNAUTHORIZED = \"urn:chapkit:error:unauthorized\"\n    FORBIDDEN = \"urn:chapkit:error:forbidden\"\n    BAD_REQUEST = \"urn:chapkit:error:bad-request\"\n</code></pre>"},{"location":"api-reference/#chapkit.core.exceptions.ChapkitException","title":"<code>ChapkitException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for chapkit with RFC 9457 Problem Details support.</p> Source code in <code>src/chapkit/core/exceptions.py</code> <pre><code>class ChapkitException(Exception):\n    \"\"\"Base exception for chapkit with RFC 9457 Problem Details support.\"\"\"\n\n    def __init__(\n        self,\n        detail: str,\n        *,\n        type_uri: str = ErrorType.INTERNAL_ERROR,\n        title: str = \"Internal Server Error\",\n        status: int = 500,\n        instance: str | None = None,\n        **extensions: Any,\n    ) -&gt; None:\n        super().__init__(detail)\n        self.type_uri = type_uri\n        self.title = title\n        self.status = status\n        self.detail = detail\n        self.instance = instance\n        self.extensions = extensions\n</code></pre>"},{"location":"api-reference/#chapkit.core.exceptions.NotFoundError","title":"<code>NotFoundError</code>","text":"<p>               Bases: <code>ChapkitException</code></p> <p>Resource not found exception (404).</p> Source code in <code>src/chapkit/core/exceptions.py</code> <pre><code>class NotFoundError(ChapkitException):\n    \"\"\"Resource not found exception (404).\"\"\"\n\n    def __init__(self, detail: str, *, instance: str | None = None, **extensions: Any) -&gt; None:\n        super().__init__(\n            detail,\n            type_uri=ErrorType.NOT_FOUND,\n            title=\"Resource Not Found\",\n            status=404,\n            instance=instance,\n            **extensions,\n        )\n</code></pre>"},{"location":"api-reference/#chapkit.core.exceptions.ValidationError","title":"<code>ValidationError</code>","text":"<p>               Bases: <code>ChapkitException</code></p> <p>Validation failed exception (400).</p> Source code in <code>src/chapkit/core/exceptions.py</code> <pre><code>class ValidationError(ChapkitException):\n    \"\"\"Validation failed exception (400).\"\"\"\n\n    def __init__(self, detail: str, *, instance: str | None = None, **extensions: Any) -&gt; None:\n        super().__init__(\n            detail,\n            type_uri=ErrorType.VALIDATION_FAILED,\n            title=\"Validation Failed\",\n            status=400,\n            instance=instance,\n            **extensions,\n        )\n</code></pre>"},{"location":"api-reference/#chapkit.core.exceptions.ConflictError","title":"<code>ConflictError</code>","text":"<p>               Bases: <code>ChapkitException</code></p> <p>Resource conflict exception (409).</p> Source code in <code>src/chapkit/core/exceptions.py</code> <pre><code>class ConflictError(ChapkitException):\n    \"\"\"Resource conflict exception (409).\"\"\"\n\n    def __init__(self, detail: str, *, instance: str | None = None, **extensions: Any) -&gt; None:\n        super().__init__(\n            detail,\n            type_uri=ErrorType.CONFLICT,\n            title=\"Resource Conflict\",\n            status=409,\n            instance=instance,\n            **extensions,\n        )\n</code></pre>"},{"location":"api-reference/#chapkit.core.exceptions.InvalidULIDError","title":"<code>InvalidULIDError</code>","text":"<p>               Bases: <code>ChapkitException</code></p> <p>Invalid ULID format exception (400).</p> Source code in <code>src/chapkit/core/exceptions.py</code> <pre><code>class InvalidULIDError(ChapkitException):\n    \"\"\"Invalid ULID format exception (400).\"\"\"\n\n    def __init__(self, detail: str, *, instance: str | None = None, **extensions: Any) -&gt; None:\n        super().__init__(\n            detail,\n            type_uri=ErrorType.INVALID_ULID,\n            title=\"Invalid ULID Format\",\n            status=400,\n            instance=instance,\n            **extensions,\n        )\n</code></pre>"},{"location":"api-reference/#chapkit.core.exceptions.BadRequestError","title":"<code>BadRequestError</code>","text":"<p>               Bases: <code>ChapkitException</code></p> <p>Bad request exception (400).</p> Source code in <code>src/chapkit/core/exceptions.py</code> <pre><code>class BadRequestError(ChapkitException):\n    \"\"\"Bad request exception (400).\"\"\"\n\n    def __init__(self, detail: str, *, instance: str | None = None, **extensions: Any) -&gt; None:\n        super().__init__(\n            detail,\n            type_uri=ErrorType.BAD_REQUEST,\n            title=\"Bad Request\",\n            status=400,\n            instance=instance,\n            **extensions,\n        )\n</code></pre>"},{"location":"api-reference/#chapkit.core.exceptions.UnauthorizedError","title":"<code>UnauthorizedError</code>","text":"<p>               Bases: <code>ChapkitException</code></p> <p>Unauthorized exception (401).</p> Source code in <code>src/chapkit/core/exceptions.py</code> <pre><code>class UnauthorizedError(ChapkitException):\n    \"\"\"Unauthorized exception (401).\"\"\"\n\n    def __init__(self, detail: str, *, instance: str | None = None, **extensions: Any) -&gt; None:\n        super().__init__(\n            detail,\n            type_uri=ErrorType.UNAUTHORIZED,\n            title=\"Unauthorized\",\n            status=401,\n            instance=instance,\n            **extensions,\n        )\n</code></pre>"},{"location":"api-reference/#chapkit.core.exceptions.ForbiddenError","title":"<code>ForbiddenError</code>","text":"<p>               Bases: <code>ChapkitException</code></p> <p>Forbidden exception (403).</p> Source code in <code>src/chapkit/core/exceptions.py</code> <pre><code>class ForbiddenError(ChapkitException):\n    \"\"\"Forbidden exception (403).\"\"\"\n\n    def __init__(self, detail: str, *, instance: str | None = None, **extensions: Any) -&gt; None:\n        super().__init__(\n            detail,\n            type_uri=ErrorType.FORBIDDEN,\n            title=\"Forbidden\",\n            status=403,\n            instance=instance,\n            **extensions,\n        )\n</code></pre>"},{"location":"api-reference/#scheduler","title":"Scheduler","text":""},{"location":"api-reference/#chapkit.core.scheduler","title":"<code>scheduler</code>","text":"<p>Job scheduler for async task management with in-memory asyncio implementation.</p>"},{"location":"api-reference/#chapkit.core.scheduler.JobScheduler","title":"<code>JobScheduler</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Abstract job scheduler interface for async task management.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>class JobScheduler(BaseModel, ABC):\n    \"\"\"Abstract job scheduler interface for async task management.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @abstractmethod\n    async def add_job(\n        self,\n        target: JobTarget,\n        /,\n        *args: Any,\n        **kwargs: Any,\n    ) -&gt; ULID:\n        \"\"\"Add a job to the scheduler and return its ID.\"\"\"\n        ...\n\n    @abstractmethod\n    async def get_status(self, job_id: ULID) -&gt; JobStatus:\n        \"\"\"Get the status of a job.\"\"\"\n        ...\n\n    @abstractmethod\n    async def get_record(self, job_id: ULID) -&gt; JobRecord:\n        \"\"\"Get the full record of a job.\"\"\"\n        ...\n\n    @abstractmethod\n    async def get_all_records(self) -&gt; list[JobRecord]:\n        \"\"\"Get all job records.\"\"\"\n        ...\n\n    @abstractmethod\n    async def cancel(self, job_id: ULID) -&gt; bool:\n        \"\"\"Cancel a running job.\"\"\"\n        ...\n\n    @abstractmethod\n    async def delete(self, job_id: ULID) -&gt; None:\n        \"\"\"Delete a job record.\"\"\"\n        ...\n\n    @abstractmethod\n    async def wait(self, job_id: ULID, timeout: float | None = None) -&gt; None:\n        \"\"\"Wait for a job to complete.\"\"\"\n        ...\n\n    @abstractmethod\n    async def get_result(self, job_id: ULID) -&gt; Any:\n        \"\"\"Get the result of a completed job.\"\"\"\n        ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.JobScheduler.add_job","title":"<code>add_job(target, /, *args, **kwargs)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Add a job to the scheduler and return its ID.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>@abstractmethod\nasync def add_job(\n    self,\n    target: JobTarget,\n    /,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; ULID:\n    \"\"\"Add a job to the scheduler and return its ID.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.JobScheduler.get_status","title":"<code>get_status(job_id)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Get the status of a job.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>@abstractmethod\nasync def get_status(self, job_id: ULID) -&gt; JobStatus:\n    \"\"\"Get the status of a job.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.JobScheduler.get_record","title":"<code>get_record(job_id)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Get the full record of a job.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>@abstractmethod\nasync def get_record(self, job_id: ULID) -&gt; JobRecord:\n    \"\"\"Get the full record of a job.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.JobScheduler.get_all_records","title":"<code>get_all_records()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Get all job records.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>@abstractmethod\nasync def get_all_records(self) -&gt; list[JobRecord]:\n    \"\"\"Get all job records.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.JobScheduler.cancel","title":"<code>cancel(job_id)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Cancel a running job.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>@abstractmethod\nasync def cancel(self, job_id: ULID) -&gt; bool:\n    \"\"\"Cancel a running job.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.JobScheduler.delete","title":"<code>delete(job_id)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Delete a job record.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>@abstractmethod\nasync def delete(self, job_id: ULID) -&gt; None:\n    \"\"\"Delete a job record.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.JobScheduler.wait","title":"<code>wait(job_id, timeout=None)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Wait for a job to complete.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>@abstractmethod\nasync def wait(self, job_id: ULID, timeout: float | None = None) -&gt; None:\n    \"\"\"Wait for a job to complete.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.JobScheduler.get_result","title":"<code>get_result(job_id)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Get the result of a completed job.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>@abstractmethod\nasync def get_result(self, job_id: ULID) -&gt; Any:\n    \"\"\"Get the result of a completed job.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.AIOJobScheduler","title":"<code>AIOJobScheduler</code>","text":"<p>               Bases: <code>JobScheduler</code></p> <p>In-memory asyncio scheduler. Sync callables run in thread pool, concurrency controlled via semaphore.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>class AIOJobScheduler(JobScheduler):\n    \"\"\"In-memory asyncio scheduler. Sync callables run in thread pool, concurrency controlled via semaphore.\"\"\"\n\n    name: str = Field(default=\"chap\")\n    max_concurrency: int | None = Field(default=None)\n\n    _records: dict[ULID, JobRecord] = PrivateAttr(default_factory=dict)\n    _results: dict[ULID, Any] = PrivateAttr(default_factory=dict)\n    _tasks: dict[ULID, asyncio.Task[Any]] = PrivateAttr(default_factory=dict)\n    _lock: asyncio.Lock = PrivateAttr(default_factory=asyncio.Lock)\n    _sema: asyncio.Semaphore | None = PrivateAttr(default=None)\n\n    def __init__(self, **data: Any):\n        \"\"\"Initialize scheduler with optional concurrency limit.\"\"\"\n        super().__init__(**data)\n        if self.max_concurrency and self.max_concurrency &gt; 0:\n            self._sema = asyncio.Semaphore(self.max_concurrency)\n\n    async def set_max_concurrency(self, n: int | None) -&gt; None:\n        \"\"\"Set maximum number of concurrent jobs.\"\"\"\n        async with self._lock:\n            self.max_concurrency = n\n            if n and n &gt; 0:\n                self._sema = asyncio.Semaphore(n)\n            else:\n                self._sema = None\n\n    async def add_job(\n        self,\n        target: JobTarget,\n        /,\n        *args: Any,\n        **kwargs: Any,\n    ) -&gt; ULID:\n        \"\"\"Add a job to the scheduler and return its ID.\"\"\"\n        now = datetime.now(timezone.utc)\n        jid = ULID()\n\n        record = JobRecord(\n            id=jid,\n            status=JobStatus.pending,\n            submitted_at=now,\n        )\n\n        async with self._lock:\n            if jid in self._tasks:\n                raise RuntimeError(f\"Job {jid!r} already scheduled\")\n            self._records[jid] = record\n\n        async def _execute_target() -&gt; Any:\n            if inspect.isawaitable(target):\n                if args or kwargs:\n                    # Close the coroutine to avoid \"coroutine was never awaited\" warning\n                    if inspect.iscoroutine(target):\n                        target.close()\n                    raise TypeError(\"Args/kwargs not supported when target is an awaitable object.\")\n                return await target\n            if inspect.iscoroutinefunction(target):\n                return await target(*args, **kwargs)\n            return await asyncio.to_thread(target, *args, **kwargs)\n\n        async def _runner() -&gt; Any:\n            if self._sema:\n                async with self._sema:\n                    return await self._run_with_state(jid, _execute_target)\n            else:\n                return await self._run_with_state(jid, _execute_target)\n\n        task = asyncio.create_task(_runner(), name=f\"{self.name}-job-{jid}\")\n\n        def _drain(t: asyncio.Task[Any]) -&gt; None:\n            try:\n                t.result()\n            except Exception:\n                pass\n\n        task.add_done_callback(_drain)\n\n        async with self._lock:\n            self._tasks[jid] = task\n\n        return jid\n\n    async def _run_with_state(\n        self,\n        jid: ULID,\n        exec_fn: JobExecutor,\n    ) -&gt; Any:\n        \"\"\"Execute job function and manage its state transitions.\"\"\"\n        async with self._lock:\n            rec = self._records[jid]\n            rec.status = JobStatus.running\n            rec.started_at = datetime.now(timezone.utc)\n\n        try:\n            result = await exec_fn()\n\n            artifact: ULID | None = result if isinstance(result, ULID) else None\n\n            async with self._lock:\n                rec = self._records[jid]\n                rec.status = JobStatus.completed\n                rec.finished_at = datetime.now(timezone.utc)\n                rec.artifact_id = artifact\n                self._results[jid] = result\n\n            return result\n\n        except asyncio.CancelledError:\n            async with self._lock:\n                rec = self._records[jid]\n                rec.status = JobStatus.canceled\n                rec.finished_at = datetime.now(timezone.utc)\n\n            raise\n\n        except Exception as e:\n            tb = traceback.format_exc()\n            # Extract clean error message (exception type and message only)\n            error_lines = tb.strip().split(\"\\n\")\n            clean_error = error_lines[-1] if error_lines else str(e)\n\n            async with self._lock:\n                rec = self._records[jid]\n                rec.status = JobStatus.failed\n                rec.finished_at = datetime.now(timezone.utc)\n                rec.error = clean_error\n                rec.error_traceback = tb\n\n            raise\n\n    async def get_all_records(self) -&gt; list[JobRecord]:\n        \"\"\"Get all job records sorted by submission time.\"\"\"\n        async with self._lock:\n            records = [r.model_copy(deep=True) for r in self._records.values()]\n\n        records.sort(\n            key=lambda r: getattr(r, \"submitted_at\", datetime.min.replace(tzinfo=timezone.utc)),\n            reverse=True,\n        )\n\n        return records\n\n    async def get_record(self, job_id: ULID) -&gt; JobRecord:\n        \"\"\"Get the full record of a job.\"\"\"\n        async with self._lock:\n            rec = self._records.get(job_id)\n\n            if rec is None:\n                raise KeyError(\"Job not found\")\n\n            return rec.model_copy(deep=True)\n\n    async def get_status(self, job_id: ULID) -&gt; JobStatus:\n        \"\"\"Get the status of a job.\"\"\"\n        async with self._lock:\n            rec = self._records.get(job_id)\n\n            if rec is None:\n                raise KeyError(\"Job not found\")\n\n            return rec.status\n\n    async def get_result(self, job_id: ULID) -&gt; Any:\n        \"\"\"Get the result of a completed job.\"\"\"\n        async with self._lock:\n            rec = self._records.get(job_id)\n\n            if rec is None:\n                raise KeyError(\"Job not found\")\n\n            if rec.status == JobStatus.completed:\n                return self._results.get(job_id)\n\n            if rec.status == JobStatus.failed:\n                msg = getattr(rec, \"error\", \"Job failed\")\n                raise RuntimeError(msg)\n\n            raise RuntimeError(f\"Job not finished (status={rec.status})\")\n\n    async def wait(self, job_id: ULID, timeout: float | None = None) -&gt; None:\n        \"\"\"Wait for a job to complete.\"\"\"\n        async with self._lock:\n            task = self._tasks.get(job_id)\n\n            if task is None:\n                raise KeyError(\"Job not found\")\n\n        await asyncio.wait_for(asyncio.shield(task), timeout=timeout)\n\n    async def cancel(self, job_id: ULID) -&gt; bool:\n        \"\"\"Cancel a running job.\"\"\"\n        async with self._lock:\n            task = self._tasks.get(job_id)\n            exists = job_id in self._records\n\n        if not exists:\n            raise KeyError(\"Job not found\")\n\n        if not task or task.done():\n            return False\n\n        task.cancel()\n\n        try:\n            await task\n        except asyncio.CancelledError:\n            pass\n\n        return True\n\n    async def delete(self, job_id: ULID) -&gt; None:\n        \"\"\"Delete a job record.\"\"\"\n        async with self._lock:\n            rec = self._records.get(job_id)\n            task = self._tasks.get(job_id)\n\n        if rec is None:\n            raise KeyError(\"Job not found\")\n\n        if task and not task.done():\n            task.cancel()\n\n            try:\n                await task\n            except asyncio.CancelledError:\n                pass\n\n        async with self._lock:\n            self._records.pop(job_id, None)\n            self._tasks.pop(job_id, None)\n            self._results.pop(job_id, None)\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.AIOJobScheduler.__init__","title":"<code>__init__(**data)</code>","text":"<p>Initialize scheduler with optional concurrency limit.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>def __init__(self, **data: Any):\n    \"\"\"Initialize scheduler with optional concurrency limit.\"\"\"\n    super().__init__(**data)\n    if self.max_concurrency and self.max_concurrency &gt; 0:\n        self._sema = asyncio.Semaphore(self.max_concurrency)\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.AIOJobScheduler.set_max_concurrency","title":"<code>set_max_concurrency(n)</code>  <code>async</code>","text":"<p>Set maximum number of concurrent jobs.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>async def set_max_concurrency(self, n: int | None) -&gt; None:\n    \"\"\"Set maximum number of concurrent jobs.\"\"\"\n    async with self._lock:\n        self.max_concurrency = n\n        if n and n &gt; 0:\n            self._sema = asyncio.Semaphore(n)\n        else:\n            self._sema = None\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.AIOJobScheduler.add_job","title":"<code>add_job(target, /, *args, **kwargs)</code>  <code>async</code>","text":"<p>Add a job to the scheduler and return its ID.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>async def add_job(\n    self,\n    target: JobTarget,\n    /,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; ULID:\n    \"\"\"Add a job to the scheduler and return its ID.\"\"\"\n    now = datetime.now(timezone.utc)\n    jid = ULID()\n\n    record = JobRecord(\n        id=jid,\n        status=JobStatus.pending,\n        submitted_at=now,\n    )\n\n    async with self._lock:\n        if jid in self._tasks:\n            raise RuntimeError(f\"Job {jid!r} already scheduled\")\n        self._records[jid] = record\n\n    async def _execute_target() -&gt; Any:\n        if inspect.isawaitable(target):\n            if args or kwargs:\n                # Close the coroutine to avoid \"coroutine was never awaited\" warning\n                if inspect.iscoroutine(target):\n                    target.close()\n                raise TypeError(\"Args/kwargs not supported when target is an awaitable object.\")\n            return await target\n        if inspect.iscoroutinefunction(target):\n            return await target(*args, **kwargs)\n        return await asyncio.to_thread(target, *args, **kwargs)\n\n    async def _runner() -&gt; Any:\n        if self._sema:\n            async with self._sema:\n                return await self._run_with_state(jid, _execute_target)\n        else:\n            return await self._run_with_state(jid, _execute_target)\n\n    task = asyncio.create_task(_runner(), name=f\"{self.name}-job-{jid}\")\n\n    def _drain(t: asyncio.Task[Any]) -&gt; None:\n        try:\n            t.result()\n        except Exception:\n            pass\n\n    task.add_done_callback(_drain)\n\n    async with self._lock:\n        self._tasks[jid] = task\n\n    return jid\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.AIOJobScheduler.get_all_records","title":"<code>get_all_records()</code>  <code>async</code>","text":"<p>Get all job records sorted by submission time.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>async def get_all_records(self) -&gt; list[JobRecord]:\n    \"\"\"Get all job records sorted by submission time.\"\"\"\n    async with self._lock:\n        records = [r.model_copy(deep=True) for r in self._records.values()]\n\n    records.sort(\n        key=lambda r: getattr(r, \"submitted_at\", datetime.min.replace(tzinfo=timezone.utc)),\n        reverse=True,\n    )\n\n    return records\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.AIOJobScheduler.get_record","title":"<code>get_record(job_id)</code>  <code>async</code>","text":"<p>Get the full record of a job.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>async def get_record(self, job_id: ULID) -&gt; JobRecord:\n    \"\"\"Get the full record of a job.\"\"\"\n    async with self._lock:\n        rec = self._records.get(job_id)\n\n        if rec is None:\n            raise KeyError(\"Job not found\")\n\n        return rec.model_copy(deep=True)\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.AIOJobScheduler.get_status","title":"<code>get_status(job_id)</code>  <code>async</code>","text":"<p>Get the status of a job.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>async def get_status(self, job_id: ULID) -&gt; JobStatus:\n    \"\"\"Get the status of a job.\"\"\"\n    async with self._lock:\n        rec = self._records.get(job_id)\n\n        if rec is None:\n            raise KeyError(\"Job not found\")\n\n        return rec.status\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.AIOJobScheduler.get_result","title":"<code>get_result(job_id)</code>  <code>async</code>","text":"<p>Get the result of a completed job.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>async def get_result(self, job_id: ULID) -&gt; Any:\n    \"\"\"Get the result of a completed job.\"\"\"\n    async with self._lock:\n        rec = self._records.get(job_id)\n\n        if rec is None:\n            raise KeyError(\"Job not found\")\n\n        if rec.status == JobStatus.completed:\n            return self._results.get(job_id)\n\n        if rec.status == JobStatus.failed:\n            msg = getattr(rec, \"error\", \"Job failed\")\n            raise RuntimeError(msg)\n\n        raise RuntimeError(f\"Job not finished (status={rec.status})\")\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.AIOJobScheduler.wait","title":"<code>wait(job_id, timeout=None)</code>  <code>async</code>","text":"<p>Wait for a job to complete.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>async def wait(self, job_id: ULID, timeout: float | None = None) -&gt; None:\n    \"\"\"Wait for a job to complete.\"\"\"\n    async with self._lock:\n        task = self._tasks.get(job_id)\n\n        if task is None:\n            raise KeyError(\"Job not found\")\n\n    await asyncio.wait_for(asyncio.shield(task), timeout=timeout)\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.AIOJobScheduler.cancel","title":"<code>cancel(job_id)</code>  <code>async</code>","text":"<p>Cancel a running job.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>async def cancel(self, job_id: ULID) -&gt; bool:\n    \"\"\"Cancel a running job.\"\"\"\n    async with self._lock:\n        task = self._tasks.get(job_id)\n        exists = job_id in self._records\n\n    if not exists:\n        raise KeyError(\"Job not found\")\n\n    if not task or task.done():\n        return False\n\n    task.cancel()\n\n    try:\n        await task\n    except asyncio.CancelledError:\n        pass\n\n    return True\n</code></pre>"},{"location":"api-reference/#chapkit.core.scheduler.AIOJobScheduler.delete","title":"<code>delete(job_id)</code>  <code>async</code>","text":"<p>Delete a job record.</p> Source code in <code>src/chapkit/core/scheduler.py</code> <pre><code>async def delete(self, job_id: ULID) -&gt; None:\n    \"\"\"Delete a job record.\"\"\"\n    async with self._lock:\n        rec = self._records.get(job_id)\n        task = self._tasks.get(job_id)\n\n    if rec is None:\n        raise KeyError(\"Job not found\")\n\n    if task and not task.done():\n        task.cancel()\n\n        try:\n            await task\n        except asyncio.CancelledError:\n            pass\n\n    async with self._lock:\n        self._records.pop(job_id, None)\n        self._tasks.pop(job_id, None)\n        self._results.pop(job_id, None)\n</code></pre>"},{"location":"api-reference/#types","title":"Types","text":""},{"location":"api-reference/#chapkit.core.types","title":"<code>types</code>","text":"<p>Custom types for chapkit - SQLAlchemy and Pydantic types.</p>"},{"location":"api-reference/#chapkit.core.types.JsonSafe","title":"<code>JsonSafe = Annotated[Any, PlainSerializer(_serialize_with_metadata, return_type=Any)]</code>  <code>module-attribute</code>","text":"<p>Pydantic type for JSON-safe serialization with graceful handling of non-serializable values.</p>"},{"location":"api-reference/#chapkit.core.types.ULIDType","title":"<code>ULIDType</code>","text":"<p>               Bases: <code>TypeDecorator[ULID]</code></p> <p>SQLAlchemy custom type for ULID stored as 26-character strings.</p> Source code in <code>src/chapkit/core/types.py</code> <pre><code>class ULIDType(TypeDecorator[ULID]):\n    \"\"\"SQLAlchemy custom type for ULID stored as 26-character strings.\"\"\"\n\n    impl = String(26)\n    cache_ok = True\n\n    def process_bind_param(self, value: ULID | str | None, dialect: Any) -&gt; str | None:\n        \"\"\"Convert ULID to string for database storage.\"\"\"\n        if value is None:\n            return None\n        if isinstance(value, str):\n            return str(ULID.from_str(value))  # Validate and normalize\n        return str(value)\n\n    def process_result_value(self, value: str | None, dialect: Any) -&gt; ULID | None:\n        \"\"\"Convert string from database to ULID object.\"\"\"\n        if value is None:\n            return None\n        return ULID.from_str(value)\n</code></pre>"},{"location":"api-reference/#chapkit.core.types.ULIDType.process_bind_param","title":"<code>process_bind_param(value, dialect)</code>","text":"<p>Convert ULID to string for database storage.</p> Source code in <code>src/chapkit/core/types.py</code> <pre><code>def process_bind_param(self, value: ULID | str | None, dialect: Any) -&gt; str | None:\n    \"\"\"Convert ULID to string for database storage.\"\"\"\n    if value is None:\n        return None\n    if isinstance(value, str):\n        return str(ULID.from_str(value))  # Validate and normalize\n    return str(value)\n</code></pre>"},{"location":"api-reference/#chapkit.core.types.ULIDType.process_result_value","title":"<code>process_result_value(value, dialect)</code>","text":"<p>Convert string from database to ULID object.</p> Source code in <code>src/chapkit/core/types.py</code> <pre><code>def process_result_value(self, value: str | None, dialect: Any) -&gt; ULID | None:\n    \"\"\"Convert string from database to ULID object.\"\"\"\n    if value is None:\n        return None\n    return ULID.from_str(value)\n</code></pre>"},{"location":"api-reference/#logging","title":"Logging","text":""},{"location":"api-reference/#chapkit.core.logging","title":"<code>logging</code>","text":"<p>Structured logging configuration with request tracing support.</p>"},{"location":"api-reference/#chapkit.core.logging.configure_logging","title":"<code>configure_logging()</code>","text":"<p>Configure structlog and intercept standard library logging.</p> Source code in <code>src/chapkit/core/logging.py</code> <pre><code>def configure_logging() -&gt; None:\n    \"\"\"Configure structlog and intercept standard library logging.\"\"\"\n    log_format = os.getenv(\"LOG_FORMAT\", \"console\").lower()\n    log_level = os.getenv(\"LOG_LEVEL\", \"INFO\").upper()\n    level = getattr(logging, log_level, logging.INFO)\n\n    # Shared processors for structlog\n    shared_processors: list[Processor] = [\n        structlog.contextvars.merge_contextvars,\n        structlog.stdlib.add_log_level,\n        structlog.processors.TimeStamper(fmt=\"iso\", utc=True),\n        structlog.processors.StackInfoRenderer(),\n    ]\n\n    # Choose renderer based on format\n    if log_format == \"json\":\n        formatter_processors = shared_processors + [\n            structlog.stdlib.ProcessorFormatter.remove_processors_meta,\n            structlog.processors.format_exc_info,\n            structlog.processors.JSONRenderer(),\n        ]\n    else:\n        formatter_processors = shared_processors + [\n            structlog.stdlib.ProcessorFormatter.remove_processors_meta,\n            structlog.processors.ExceptionRenderer(),\n            structlog.dev.ConsoleRenderer(colors=True),\n        ]\n\n    # Configure structlog to use standard library logging\n    structlog.configure(\n        processors=[\n            structlog.contextvars.merge_contextvars,\n            structlog.stdlib.add_log_level,\n            structlog.stdlib.add_logger_name,\n            structlog.processors.TimeStamper(fmt=\"iso\", utc=True),\n            structlog.processors.StackInfoRenderer(),\n            structlog.processors.CallsiteParameterAdder(\n                [\n                    structlog.processors.CallsiteParameter.FILENAME,\n                    structlog.processors.CallsiteParameter.LINENO,\n                    structlog.processors.CallsiteParameter.FUNC_NAME,\n                ]\n            ),\n            structlog.stdlib.ProcessorFormatter.wrap_for_formatter,\n        ],\n        wrapper_class=structlog.make_filtering_bound_logger(level),\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        cache_logger_on_first_use=True,\n    )\n\n    # Configure standard library logging to use structlog formatter\n    handler = logging.StreamHandler(sys.stdout)\n    handler.setFormatter(structlog.stdlib.ProcessorFormatter(processors=formatter_processors))\n\n    # Configure root logger\n    root_logger = logging.getLogger()\n    root_logger.handlers.clear()\n    root_logger.addHandler(handler)\n    root_logger.setLevel(level)\n\n    # Configure uvicorn and gunicorn loggers to use the same handler\n    for logger_name in [\"uvicorn\", \"uvicorn.access\", \"uvicorn.error\", \"gunicorn.access\", \"gunicorn.error\"]:\n        logger = logging.getLogger(logger_name)\n        logger.handlers.clear()\n        logger.addHandler(handler)\n        logger.setLevel(level)\n        logger.propagate = False\n</code></pre>"},{"location":"api-reference/#chapkit.core.logging.get_logger","title":"<code>get_logger(name=None)</code>","text":"<p>Get a configured structlog logger instance.</p> Source code in <code>src/chapkit/core/logging.py</code> <pre><code>def get_logger(name: str | None = None) -&gt; Any:\n    \"\"\"Get a configured structlog logger instance.\"\"\"\n    return structlog.get_logger(name)\n</code></pre>"},{"location":"api-reference/#chapkit.core.logging.add_request_context","title":"<code>add_request_context(**context)</code>","text":"<p>Add context variables that will be included in all log messages.</p> Source code in <code>src/chapkit/core/logging.py</code> <pre><code>def add_request_context(**context: Any) -&gt; None:\n    \"\"\"Add context variables that will be included in all log messages.\"\"\"\n    structlog.contextvars.bind_contextvars(**context)\n</code></pre>"},{"location":"api-reference/#chapkit.core.logging.clear_request_context","title":"<code>clear_request_context(*keys)</code>","text":"<p>Clear specific context variables.</p> Source code in <code>src/chapkit/core/logging.py</code> <pre><code>def clear_request_context(*keys: str) -&gt; None:\n    \"\"\"Clear specific context variables.\"\"\"\n    structlog.contextvars.unbind_contextvars(*keys)\n</code></pre>"},{"location":"api-reference/#chapkit.core.logging.reset_request_context","title":"<code>reset_request_context()</code>","text":"<p>Clear all context variables.</p> Source code in <code>src/chapkit/core/logging.py</code> <pre><code>def reset_request_context() -&gt; None:\n    \"\"\"Clear all context variables.\"\"\"\n    structlog.contextvars.clear_contextvars()\n</code></pre>"},{"location":"api-reference/#fastapi-layer","title":"FastAPI Layer","text":"<p>FastAPI-specific components for building web services.</p>"},{"location":"api-reference/#service-builders","title":"Service Builders","text":"<p>Service builder classes for composing FastAPI applications.</p>"},{"location":"api-reference/#baseservicebuilder","title":"BaseServiceBuilder","text":""},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder","title":"<code>BaseServiceBuilder</code>","text":"<p>Base service builder providing core FastAPI functionality without module dependencies.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>class BaseServiceBuilder:\n    \"\"\"Base service builder providing core FastAPI functionality without module dependencies.\"\"\"\n\n    def __init__(\n        self,\n        *,\n        info: ServiceInfo,\n        database_url: str = \"sqlite+aiosqlite:///:memory:\",\n        include_error_handlers: bool = True,\n        include_logging: bool = False,\n    ) -&gt; None:\n        \"\"\"Initialize base service builder with core options.\"\"\"\n        if info.description is None and info.summary is not None:\n            # Preserve summary as description for FastAPI metadata if description missing\n            self.info = info.model_copy(update={\"description\": info.summary})\n        else:\n            self.info = info\n        self._title = self.info.display_name\n        self._app_description = self.info.summary or self.info.description or \"\"\n        self._version = self.info.version\n        self._database_url = database_url\n        self._database_instance: Database | None = None\n        self._pool_size: int = 5\n        self._max_overflow: int = 10\n        self._pool_recycle: int = 3600\n        self._pool_pre_ping: bool = True\n        self._include_error_handlers = include_error_handlers\n        self._include_logging = include_logging\n        self._health_options: _HealthOptions | None = None\n        self._system_options: _SystemOptions | None = None\n        self._job_options: _JobOptions | None = None\n        self._auth_options: _AuthOptions | None = None\n        self._monitoring_options: _MonitoringOptions | None = None\n        self._app_configs: List[App] = []\n        self._custom_routers: List[APIRouter] = []\n        self._dependency_overrides: Dict[DependencyOverride, DependencyOverride] = {}\n        self._startup_hooks: List[LifecycleHook] = []\n        self._shutdown_hooks: List[LifecycleHook] = []\n\n    # --------------------------------------------------------------------- Fluent configuration\n\n    def with_database(\n        self,\n        url_or_instance: str | Database | None = None,\n        *,\n        pool_size: int = 5,\n        max_overflow: int = 10,\n        pool_recycle: int = 3600,\n        pool_pre_ping: bool = True,\n    ) -&gt; Self:\n        \"\"\"Configure database with URL string, Database instance, or default in-memory SQLite.\"\"\"\n        if isinstance(url_or_instance, Database):\n            # Pre-configured instance provided\n            self._database_instance = url_or_instance\n            return self  # Skip pool configuration for instances\n        elif isinstance(url_or_instance, str):\n            # String URL provided\n            self._database_url = url_or_instance\n        elif url_or_instance is None:\n            # Default: in-memory SQLite\n            self._database_url = \"sqlite+aiosqlite:///:memory:\"\n        else:\n            raise TypeError(\n                f\"Expected str, Database, or None, got {type(url_or_instance).__name__}. \"\n                \"Use .with_database() for default, .with_database('url') for custom URL, \"\n                \"or .with_database(db_instance) for pre-configured database.\"\n            )\n\n        # Configure pool settings (only applies to URL-based databases)\n        self._pool_size = pool_size\n        self._max_overflow = max_overflow\n        self._pool_recycle = pool_recycle\n        self._pool_pre_ping = pool_pre_ping\n        return self\n\n    def with_landing_page(self) -&gt; Self:\n        \"\"\"Enable landing page at root path.\"\"\"\n        return self.with_app((\"chapkit.core.api\", \"apps/landing\"))\n\n    def with_logging(self, enabled: bool = True) -&gt; Self:\n        \"\"\"Enable structured logging with request tracing.\"\"\"\n        self._include_logging = enabled\n        return self\n\n    def with_health(\n        self,\n        *,\n        prefix: str = \"/health\",\n        tags: List[str] | None = None,\n        checks: dict[str, HealthCheck] | None = None,\n        include_database_check: bool = True,\n    ) -&gt; Self:\n        \"\"\"Add health check endpoint with optional custom checks.\"\"\"\n        health_checks = checks or {}\n\n        if include_database_check:\n            health_checks[\"database\"] = self._create_database_health_check()\n\n        self._health_options = _HealthOptions(\n            prefix=prefix,\n            tags=list(tags) if tags is not None else [\"Observability\"],\n            checks=health_checks,\n        )\n        return self\n\n    def with_system(\n        self,\n        *,\n        prefix: str = \"/api/v1/system\",\n        tags: List[str] | None = None,\n    ) -&gt; Self:\n        \"\"\"Add system info endpoint.\"\"\"\n        self._system_options = _SystemOptions(\n            prefix=prefix,\n            tags=list(tags) if tags is not None else [\"Service\"],\n        )\n        return self\n\n    def with_jobs(\n        self,\n        *,\n        prefix: str = \"/api/v1/jobs\",\n        tags: List[str] | None = None,\n        max_concurrency: int | None = None,\n    ) -&gt; Self:\n        \"\"\"Add job scheduler endpoints.\"\"\"\n        self._job_options = _JobOptions(\n            prefix=prefix,\n            tags=list(tags) if tags is not None else [\"Jobs\"],\n            max_concurrency=max_concurrency,\n        )\n        return self\n\n    def with_auth(\n        self,\n        *,\n        api_keys: List[str] | None = None,\n        api_key_file: str | None = None,\n        env_var: str = \"CHAPKIT_API_KEYS\",\n        header_name: str = \"X-API-Key\",\n        unauthenticated_paths: List[str] | None = None,\n    ) -&gt; Self:\n        \"\"\"Enable API key authentication.\"\"\"\n        keys: set[str] = set()\n        auth_source: str = \"\"  # Track source for later logging\n\n        # Priority 1: Direct list (examples/dev)\n        if api_keys is not None:\n            keys = set(api_keys)\n            auth_source = \"direct_keys\"\n\n        # Priority 2: File (Docker secrets)\n        elif api_key_file is not None:\n            keys = load_api_keys_from_file(api_key_file)\n            auth_source = f\"file:{api_key_file}\"\n\n        # Priority 3: Environment variable (default)\n        else:\n            keys = load_api_keys_from_env(env_var)\n            if keys:\n                auth_source = f\"env:{env_var}\"\n            else:\n                auth_source = f\"env:{env_var}:empty\"\n\n        if not keys:\n            raise ValueError(\"No API keys configured. Provide api_keys, api_key_file, or set environment variable.\")\n\n        # Default unauthenticated paths\n        default_unauth = {\"/docs\", \"/redoc\", \"/openapi.json\", \"/health\", \"/\"}\n        unauth_set = set(unauthenticated_paths) if unauthenticated_paths else default_unauth\n\n        self._auth_options = _AuthOptions(\n            api_keys=keys,\n            header_name=header_name,\n            unauthenticated_paths=unauth_set,\n            source=auth_source,\n        )\n        return self\n\n    def with_monitoring(\n        self,\n        *,\n        prefix: str = \"/metrics\",\n        tags: List[str] | None = None,\n        service_name: str | None = None,\n        enable_traces: bool = False,\n    ) -&gt; Self:\n        \"\"\"Enable OpenTelemetry monitoring with Prometheus endpoint and auto-instrumentation.\"\"\"\n        self._monitoring_options = _MonitoringOptions(\n            prefix=prefix,\n            tags=list(tags) if tags is not None else [\"Observability\"],\n            service_name=service_name,\n            enable_traces=enable_traces,\n        )\n        return self\n\n    def with_app(self, path: str | Path | tuple[str, str], prefix: str | None = None) -&gt; Self:\n        \"\"\"Register static app from filesystem path or package resource tuple.\"\"\"\n        app = AppLoader.load(path, prefix=prefix)\n        self._app_configs.append(app)\n        return self\n\n    def with_apps(self, path: str | Path | tuple[str, str]) -&gt; Self:\n        \"\"\"Auto-discover and register all apps in directory.\"\"\"\n        apps = AppLoader.discover(path)\n        self._app_configs.extend(apps)\n        return self\n\n    def include_router(self, router: APIRouter) -&gt; Self:\n        \"\"\"Include a custom router.\"\"\"\n        self._custom_routers.append(router)\n        return self\n\n    def override_dependency(self, dependency: DependencyOverride, override: DependencyOverride) -&gt; Self:\n        \"\"\"Override a dependency for testing or customization.\"\"\"\n        self._dependency_overrides[dependency] = override\n        return self\n\n    def on_startup(self, hook: LifecycleHook) -&gt; Self:\n        \"\"\"Register a startup hook.\"\"\"\n        self._startup_hooks.append(hook)\n        return self\n\n    def on_shutdown(self, hook: LifecycleHook) -&gt; Self:\n        \"\"\"Register a shutdown hook.\"\"\"\n        self._shutdown_hooks.append(hook)\n        return self\n\n    # --------------------------------------------------------------------- Build mechanics\n\n    def build(self) -&gt; FastAPI:\n        \"\"\"Build and configure the FastAPI application.\"\"\"\n        self._validate_configuration()\n        self._validate_module_configuration()  # Extension point for subclasses\n\n        lifespan = self._build_lifespan()\n        app = FastAPI(\n            title=self._title,\n            description=self._app_description,\n            version=self._version,\n            lifespan=lifespan,\n        )\n        app.state.database_url = self._database_url\n\n        # Override schema generation to clean up generic type names\n        app.openapi = self._create_openapi_customizer(app)  # type: ignore[method-assign]\n\n        if self._include_error_handlers:\n            add_error_handlers(app)\n\n        if self._include_logging:\n            add_logging_middleware(app)\n\n        if self._auth_options:\n            app.add_middleware(\n                APIKeyMiddleware,\n                api_keys=self._auth_options.api_keys,\n                header_name=self._auth_options.header_name,\n                unauthenticated_paths=self._auth_options.unauthenticated_paths,\n            )\n            # Store auth_source for logging during startup\n            app.state.auth_source = self._auth_options.source\n            app.state.auth_key_count = len(self._auth_options.api_keys)\n\n        if self._health_options:\n            health_router = HealthRouter.create(\n                prefix=self._health_options.prefix,\n                tags=self._health_options.tags,\n                checks=self._health_options.checks,\n            )\n            app.include_router(health_router)\n\n        if self._system_options:\n            system_router = SystemRouter.create(\n                prefix=self._system_options.prefix,\n                tags=self._system_options.tags,\n            )\n            app.include_router(system_router)\n\n        if self._job_options:\n            job_router = JobRouter.create(\n                prefix=self._job_options.prefix,\n                tags=self._job_options.tags,\n                scheduler_factory=get_scheduler,\n            )\n            app.include_router(job_router)\n\n        if self._monitoring_options:\n            from .monitoring import setup_monitoring\n\n            metric_reader = setup_monitoring(\n                app,\n                service_name=self._monitoring_options.service_name,\n                enable_traces=self._monitoring_options.enable_traces,\n            )\n            metrics_router = MetricsRouter.create(\n                prefix=self._monitoring_options.prefix,\n                tags=self._monitoring_options.tags,\n                metric_reader=metric_reader,\n            )\n            app.include_router(metrics_router)\n\n        # Extension point for module-specific routers\n        self._register_module_routers(app)\n\n        for router in self._custom_routers:\n            app.include_router(router)\n\n        # Install route endpoints BEFORE mounting apps (routes take precedence over mounts)\n        self._install_info_endpoint(app, info=self.info)\n\n        # Mount apps AFTER all routes (apps act as catch-all for unmatched paths)\n        if self._app_configs:\n            from fastapi.staticfiles import StaticFiles\n\n            for app_config in self._app_configs:\n                static_files = StaticFiles(directory=str(app_config.directory), html=True)\n                app.mount(app_config.prefix, static_files, name=f\"app_{app_config.manifest.name}\")\n                logger.info(\n                    \"app.mounted\",\n                    name=app_config.manifest.name,\n                    prefix=app_config.prefix,\n                    directory=str(app_config.directory),\n                    is_package=app_config.is_package,\n                )\n\n        # Initialize app manager for metadata queries (always, even if no apps)\n        from .app import AppManager\n        from .dependencies import set_app_manager\n\n        app_manager = AppManager(self._app_configs)\n        set_app_manager(app_manager)\n\n        for dependency, override in self._dependency_overrides.items():\n            app.dependency_overrides[dependency] = override\n\n        return app\n\n    # --------------------------------------------------------------------- Extension points\n\n    def _validate_module_configuration(self) -&gt; None:\n        \"\"\"Extension point for module-specific validation (override in subclasses).\"\"\"\n        pass\n\n    def _register_module_routers(self, app: FastAPI) -&gt; None:\n        \"\"\"Extension point for registering module-specific routers (override in subclasses).\"\"\"\n        pass\n\n    # --------------------------------------------------------------------- Core helpers\n\n    def _validate_configuration(self) -&gt; None:\n        \"\"\"Validate core configuration.\"\"\"\n        # Validate health check names don't contain invalid characters\n        if self._health_options:\n            for name in self._health_options.checks.keys():\n                if not name.replace(\"_\", \"\").replace(\"-\", \"\").isalnum():\n                    raise ValueError(\n                        f\"Health check name '{name}' contains invalid characters. \"\n                        \"Only alphanumeric characters, underscores, and hyphens are allowed.\"\n                    )\n\n        # Validate app configurations\n        if self._app_configs:\n            # Deduplicate apps with same prefix (last one wins)\n            # This allows overriding apps, especially useful for root prefix \"/\"\n            seen_prefixes: dict[str, int] = {}  # prefix -&gt; last index\n            for i, app in enumerate(self._app_configs):\n                if app.prefix in seen_prefixes:\n                    # Log warning about override\n                    prev_idx = seen_prefixes[app.prefix]\n                    prev_app = self._app_configs[prev_idx]\n                    logger.warning(\n                        \"app.prefix.override\",\n                        prefix=app.prefix,\n                        replaced_app=prev_app.manifest.name,\n                        new_app=app.manifest.name,\n                    )\n                seen_prefixes[app.prefix] = i\n\n            # Keep only the last app for each prefix\n            self._app_configs = [self._app_configs[i] for i in sorted(set(seen_prefixes.values()))]\n\n            # Validate that non-root prefixes don't have duplicates (shouldn't happen after dedup, but safety check)\n            prefixes = [app.prefix for app in self._app_configs]\n            if len(prefixes) != len(set(prefixes)):\n                raise ValueError(\"Internal error: duplicate prefixes after deduplication\")\n\n    def _build_lifespan(self) -&gt; LifespanFactory:\n        \"\"\"Build lifespan context manager for app startup/shutdown.\"\"\"\n        database_url = self._database_url\n        database_instance = self._database_instance\n        pool_size = self._pool_size\n        max_overflow = self._max_overflow\n        pool_recycle = self._pool_recycle\n        pool_pre_ping = self._pool_pre_ping\n        job_options = self._job_options\n        include_logging = self._include_logging\n        startup_hooks = list(self._startup_hooks)\n        shutdown_hooks = list(self._shutdown_hooks)\n\n        @asynccontextmanager\n        async def lifespan(app: FastAPI) -&gt; AsyncIterator[None]:\n            # Configure logging if enabled\n            if include_logging:\n                configure_logging()\n\n            # Use injected database or create new one from URL\n            if database_instance is not None:\n                database = database_instance\n                should_manage_lifecycle = False\n            else:\n                # Create appropriate database type based on URL\n                if \"sqlite\" in database_url.lower():\n                    database = SqliteDatabase(\n                        database_url,\n                        pool_size=pool_size,\n                        max_overflow=max_overflow,\n                        pool_recycle=pool_recycle,\n                        pool_pre_ping=pool_pre_ping,\n                    )\n                else:\n                    database = Database(\n                        database_url,\n                        pool_size=pool_size,\n                        max_overflow=max_overflow,\n                        pool_recycle=pool_recycle,\n                        pool_pre_ping=pool_pre_ping,\n                    )\n                should_manage_lifecycle = True\n\n            # Always initialize database (safe to call multiple times)\n            await database.init()\n\n            set_database(database)\n            app.state.database = database\n\n            # Initialize scheduler if jobs are enabled\n            if job_options is not None:\n                from chapkit.core.scheduler import AIOJobScheduler\n\n                scheduler = AIOJobScheduler(max_concurrency=job_options.max_concurrency)\n                set_scheduler(scheduler)\n                app.state.scheduler = scheduler\n\n            # Log auth configuration after logging is configured\n            if hasattr(app.state, \"auth_source\"):\n                auth_source = app.state.auth_source\n                key_count = app.state.auth_key_count\n\n                if auth_source == \"direct_keys\":\n                    logger.warning(\n                        \"auth.direct_keys\",\n                        message=\"Using direct API keys - not recommended for production\",\n                        count=key_count,\n                    )\n                elif auth_source.startswith(\"file:\"):\n                    file_path = auth_source.split(\":\", 1)[1]\n                    logger.info(\"auth.loaded_from_file\", file=file_path, count=key_count)\n                elif auth_source.startswith(\"env:\"):\n                    parts = auth_source.split(\":\", 2)\n                    env_var = parts[1]\n                    if len(parts) &gt; 2 and parts[2] == \"empty\":\n                        logger.warning(\n                            \"auth.no_keys\",\n                            message=f\"No API keys found in {env_var}. Service will reject all requests.\",\n                        )\n                    else:\n                        logger.info(\"auth.loaded_from_env\", env_var=env_var, count=key_count)\n\n            for hook in startup_hooks:\n                await hook(app)\n            try:\n                yield\n            finally:\n                for hook in shutdown_hooks:\n                    await hook(app)\n                app.state.database = None\n\n                # Dispose database only if we created it\n                if should_manage_lifecycle:\n                    await database.dispose()\n\n        return lifespan\n\n    @staticmethod\n    def _create_database_health_check() -&gt; HealthCheck:\n        \"\"\"Create database connectivity health check.\"\"\"\n\n        async def check_database() -&gt; tuple[HealthState, str | None]:\n            try:\n                db = get_database()\n                async with db.session() as session:\n                    # Simple connectivity check - execute a trivial query\n                    await session.execute(text(\"SELECT 1\"))\n                    return (HealthState.HEALTHY, None)\n            except Exception as e:\n                return (HealthState.UNHEALTHY, f\"Database connection failed: {str(e)}\")\n\n        return check_database\n\n    @staticmethod\n    def _create_openapi_customizer(app: FastAPI) -&gt; Callable[[], dict[str, Any]]:\n        \"\"\"Create OpenAPI schema customizer that cleans up generic type names.\"\"\"\n\n        def custom_openapi() -&gt; dict[str, Any]:\n            if app.openapi_schema:\n                return app.openapi_schema\n\n            from fastapi.openapi.utils import get_openapi\n\n            openapi_schema = get_openapi(\n                title=app.title,\n                version=app.version,\n                description=app.description,\n                routes=app.routes,\n            )\n\n            # Clean up schema titles by removing generic type parameters\n            if \"components\" in openapi_schema and \"schemas\" in openapi_schema[\"components\"]:\n                schemas = openapi_schema[\"components\"][\"schemas\"]\n                cleaned_schemas: dict[str, Any] = {}\n\n                for schema_name, schema_def in schemas.items():\n                    # Remove generic type parameters from schema names\n                    clean_name = re.sub(r\"\\[.*?\\]\", \"\", schema_name)\n                    # If title exists in schema, clean it too\n                    if isinstance(schema_def, dict) and \"title\" in schema_def:\n                        schema_def[\"title\"] = re.sub(r\"\\[.*?\\]\", \"\", schema_def[\"title\"])\n                    cleaned_schemas[clean_name] = schema_def\n\n                openapi_schema[\"components\"][\"schemas\"] = cleaned_schemas\n\n                # Update all $ref pointers to use cleaned names\n                def clean_refs(obj: Any) -&gt; Any:\n                    if isinstance(obj, dict):\n                        if \"$ref\" in obj:\n                            obj[\"$ref\"] = re.sub(r\"\\[.*?\\]\", \"\", obj[\"$ref\"])\n                        for value in obj.values():\n                            clean_refs(value)\n                    elif isinstance(obj, list):\n                        for item in obj:\n                            clean_refs(item)\n\n                clean_refs(openapi_schema)\n\n            app.openapi_schema = openapi_schema\n            return app.openapi_schema\n\n        return custom_openapi\n\n    @staticmethod\n    def _install_info_endpoint(app: FastAPI, *, info: ServiceInfo) -&gt; None:\n        \"\"\"Install service info endpoint.\"\"\"\n        info_type = type(info)\n\n        @app.get(\"/api/v1/info\", tags=[\"Service\"], include_in_schema=True, response_model=info_type)\n        async def get_info() -&gt; ServiceInfo:\n            return info\n\n    # --------------------------------------------------------------------- Convenience\n\n    @classmethod\n    def create(cls, *, info: ServiceInfo, **kwargs: Any) -&gt; FastAPI:\n        \"\"\"Create and build a FastAPI application in one call.\"\"\"\n        return cls(info=info, **kwargs).build()\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.__init__","title":"<code>__init__(*, info, database_url='sqlite+aiosqlite:///:memory:', include_error_handlers=True, include_logging=False)</code>","text":"<p>Initialize base service builder with core options.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def __init__(\n    self,\n    *,\n    info: ServiceInfo,\n    database_url: str = \"sqlite+aiosqlite:///:memory:\",\n    include_error_handlers: bool = True,\n    include_logging: bool = False,\n) -&gt; None:\n    \"\"\"Initialize base service builder with core options.\"\"\"\n    if info.description is None and info.summary is not None:\n        # Preserve summary as description for FastAPI metadata if description missing\n        self.info = info.model_copy(update={\"description\": info.summary})\n    else:\n        self.info = info\n    self._title = self.info.display_name\n    self._app_description = self.info.summary or self.info.description or \"\"\n    self._version = self.info.version\n    self._database_url = database_url\n    self._database_instance: Database | None = None\n    self._pool_size: int = 5\n    self._max_overflow: int = 10\n    self._pool_recycle: int = 3600\n    self._pool_pre_ping: bool = True\n    self._include_error_handlers = include_error_handlers\n    self._include_logging = include_logging\n    self._health_options: _HealthOptions | None = None\n    self._system_options: _SystemOptions | None = None\n    self._job_options: _JobOptions | None = None\n    self._auth_options: _AuthOptions | None = None\n    self._monitoring_options: _MonitoringOptions | None = None\n    self._app_configs: List[App] = []\n    self._custom_routers: List[APIRouter] = []\n    self._dependency_overrides: Dict[DependencyOverride, DependencyOverride] = {}\n    self._startup_hooks: List[LifecycleHook] = []\n    self._shutdown_hooks: List[LifecycleHook] = []\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.with_database","title":"<code>with_database(url_or_instance=None, *, pool_size=5, max_overflow=10, pool_recycle=3600, pool_pre_ping=True)</code>","text":"<p>Configure database with URL string, Database instance, or default in-memory SQLite.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def with_database(\n    self,\n    url_or_instance: str | Database | None = None,\n    *,\n    pool_size: int = 5,\n    max_overflow: int = 10,\n    pool_recycle: int = 3600,\n    pool_pre_ping: bool = True,\n) -&gt; Self:\n    \"\"\"Configure database with URL string, Database instance, or default in-memory SQLite.\"\"\"\n    if isinstance(url_or_instance, Database):\n        # Pre-configured instance provided\n        self._database_instance = url_or_instance\n        return self  # Skip pool configuration for instances\n    elif isinstance(url_or_instance, str):\n        # String URL provided\n        self._database_url = url_or_instance\n    elif url_or_instance is None:\n        # Default: in-memory SQLite\n        self._database_url = \"sqlite+aiosqlite:///:memory:\"\n    else:\n        raise TypeError(\n            f\"Expected str, Database, or None, got {type(url_or_instance).__name__}. \"\n            \"Use .with_database() for default, .with_database('url') for custom URL, \"\n            \"or .with_database(db_instance) for pre-configured database.\"\n        )\n\n    # Configure pool settings (only applies to URL-based databases)\n    self._pool_size = pool_size\n    self._max_overflow = max_overflow\n    self._pool_recycle = pool_recycle\n    self._pool_pre_ping = pool_pre_ping\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.with_landing_page","title":"<code>with_landing_page()</code>","text":"<p>Enable landing page at root path.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def with_landing_page(self) -&gt; Self:\n    \"\"\"Enable landing page at root path.\"\"\"\n    return self.with_app((\"chapkit.core.api\", \"apps/landing\"))\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.with_logging","title":"<code>with_logging(enabled=True)</code>","text":"<p>Enable structured logging with request tracing.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def with_logging(self, enabled: bool = True) -&gt; Self:\n    \"\"\"Enable structured logging with request tracing.\"\"\"\n    self._include_logging = enabled\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.with_health","title":"<code>with_health(*, prefix='/health', tags=None, checks=None, include_database_check=True)</code>","text":"<p>Add health check endpoint with optional custom checks.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def with_health(\n    self,\n    *,\n    prefix: str = \"/health\",\n    tags: List[str] | None = None,\n    checks: dict[str, HealthCheck] | None = None,\n    include_database_check: bool = True,\n) -&gt; Self:\n    \"\"\"Add health check endpoint with optional custom checks.\"\"\"\n    health_checks = checks or {}\n\n    if include_database_check:\n        health_checks[\"database\"] = self._create_database_health_check()\n\n    self._health_options = _HealthOptions(\n        prefix=prefix,\n        tags=list(tags) if tags is not None else [\"Observability\"],\n        checks=health_checks,\n    )\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.with_system","title":"<code>with_system(*, prefix='/api/v1/system', tags=None)</code>","text":"<p>Add system info endpoint.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def with_system(\n    self,\n    *,\n    prefix: str = \"/api/v1/system\",\n    tags: List[str] | None = None,\n) -&gt; Self:\n    \"\"\"Add system info endpoint.\"\"\"\n    self._system_options = _SystemOptions(\n        prefix=prefix,\n        tags=list(tags) if tags is not None else [\"Service\"],\n    )\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.with_jobs","title":"<code>with_jobs(*, prefix='/api/v1/jobs', tags=None, max_concurrency=None)</code>","text":"<p>Add job scheduler endpoints.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def with_jobs(\n    self,\n    *,\n    prefix: str = \"/api/v1/jobs\",\n    tags: List[str] | None = None,\n    max_concurrency: int | None = None,\n) -&gt; Self:\n    \"\"\"Add job scheduler endpoints.\"\"\"\n    self._job_options = _JobOptions(\n        prefix=prefix,\n        tags=list(tags) if tags is not None else [\"Jobs\"],\n        max_concurrency=max_concurrency,\n    )\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.with_auth","title":"<code>with_auth(*, api_keys=None, api_key_file=None, env_var='CHAPKIT_API_KEYS', header_name='X-API-Key', unauthenticated_paths=None)</code>","text":"<p>Enable API key authentication.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def with_auth(\n    self,\n    *,\n    api_keys: List[str] | None = None,\n    api_key_file: str | None = None,\n    env_var: str = \"CHAPKIT_API_KEYS\",\n    header_name: str = \"X-API-Key\",\n    unauthenticated_paths: List[str] | None = None,\n) -&gt; Self:\n    \"\"\"Enable API key authentication.\"\"\"\n    keys: set[str] = set()\n    auth_source: str = \"\"  # Track source for later logging\n\n    # Priority 1: Direct list (examples/dev)\n    if api_keys is not None:\n        keys = set(api_keys)\n        auth_source = \"direct_keys\"\n\n    # Priority 2: File (Docker secrets)\n    elif api_key_file is not None:\n        keys = load_api_keys_from_file(api_key_file)\n        auth_source = f\"file:{api_key_file}\"\n\n    # Priority 3: Environment variable (default)\n    else:\n        keys = load_api_keys_from_env(env_var)\n        if keys:\n            auth_source = f\"env:{env_var}\"\n        else:\n            auth_source = f\"env:{env_var}:empty\"\n\n    if not keys:\n        raise ValueError(\"No API keys configured. Provide api_keys, api_key_file, or set environment variable.\")\n\n    # Default unauthenticated paths\n    default_unauth = {\"/docs\", \"/redoc\", \"/openapi.json\", \"/health\", \"/\"}\n    unauth_set = set(unauthenticated_paths) if unauthenticated_paths else default_unauth\n\n    self._auth_options = _AuthOptions(\n        api_keys=keys,\n        header_name=header_name,\n        unauthenticated_paths=unauth_set,\n        source=auth_source,\n    )\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.with_monitoring","title":"<code>with_monitoring(*, prefix='/metrics', tags=None, service_name=None, enable_traces=False)</code>","text":"<p>Enable OpenTelemetry monitoring with Prometheus endpoint and auto-instrumentation.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def with_monitoring(\n    self,\n    *,\n    prefix: str = \"/metrics\",\n    tags: List[str] | None = None,\n    service_name: str | None = None,\n    enable_traces: bool = False,\n) -&gt; Self:\n    \"\"\"Enable OpenTelemetry monitoring with Prometheus endpoint and auto-instrumentation.\"\"\"\n    self._monitoring_options = _MonitoringOptions(\n        prefix=prefix,\n        tags=list(tags) if tags is not None else [\"Observability\"],\n        service_name=service_name,\n        enable_traces=enable_traces,\n    )\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.with_app","title":"<code>with_app(path, prefix=None)</code>","text":"<p>Register static app from filesystem path or package resource tuple.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def with_app(self, path: str | Path | tuple[str, str], prefix: str | None = None) -&gt; Self:\n    \"\"\"Register static app from filesystem path or package resource tuple.\"\"\"\n    app = AppLoader.load(path, prefix=prefix)\n    self._app_configs.append(app)\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.with_apps","title":"<code>with_apps(path)</code>","text":"<p>Auto-discover and register all apps in directory.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def with_apps(self, path: str | Path | tuple[str, str]) -&gt; Self:\n    \"\"\"Auto-discover and register all apps in directory.\"\"\"\n    apps = AppLoader.discover(path)\n    self._app_configs.extend(apps)\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.include_router","title":"<code>include_router(router)</code>","text":"<p>Include a custom router.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def include_router(self, router: APIRouter) -&gt; Self:\n    \"\"\"Include a custom router.\"\"\"\n    self._custom_routers.append(router)\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.override_dependency","title":"<code>override_dependency(dependency, override)</code>","text":"<p>Override a dependency for testing or customization.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def override_dependency(self, dependency: DependencyOverride, override: DependencyOverride) -&gt; Self:\n    \"\"\"Override a dependency for testing or customization.\"\"\"\n    self._dependency_overrides[dependency] = override\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.on_startup","title":"<code>on_startup(hook)</code>","text":"<p>Register a startup hook.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def on_startup(self, hook: LifecycleHook) -&gt; Self:\n    \"\"\"Register a startup hook.\"\"\"\n    self._startup_hooks.append(hook)\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.on_shutdown","title":"<code>on_shutdown(hook)</code>","text":"<p>Register a shutdown hook.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def on_shutdown(self, hook: LifecycleHook) -&gt; Self:\n    \"\"\"Register a shutdown hook.\"\"\"\n    self._shutdown_hooks.append(hook)\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.build","title":"<code>build()</code>","text":"<p>Build and configure the FastAPI application.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>def build(self) -&gt; FastAPI:\n    \"\"\"Build and configure the FastAPI application.\"\"\"\n    self._validate_configuration()\n    self._validate_module_configuration()  # Extension point for subclasses\n\n    lifespan = self._build_lifespan()\n    app = FastAPI(\n        title=self._title,\n        description=self._app_description,\n        version=self._version,\n        lifespan=lifespan,\n    )\n    app.state.database_url = self._database_url\n\n    # Override schema generation to clean up generic type names\n    app.openapi = self._create_openapi_customizer(app)  # type: ignore[method-assign]\n\n    if self._include_error_handlers:\n        add_error_handlers(app)\n\n    if self._include_logging:\n        add_logging_middleware(app)\n\n    if self._auth_options:\n        app.add_middleware(\n            APIKeyMiddleware,\n            api_keys=self._auth_options.api_keys,\n            header_name=self._auth_options.header_name,\n            unauthenticated_paths=self._auth_options.unauthenticated_paths,\n        )\n        # Store auth_source for logging during startup\n        app.state.auth_source = self._auth_options.source\n        app.state.auth_key_count = len(self._auth_options.api_keys)\n\n    if self._health_options:\n        health_router = HealthRouter.create(\n            prefix=self._health_options.prefix,\n            tags=self._health_options.tags,\n            checks=self._health_options.checks,\n        )\n        app.include_router(health_router)\n\n    if self._system_options:\n        system_router = SystemRouter.create(\n            prefix=self._system_options.prefix,\n            tags=self._system_options.tags,\n        )\n        app.include_router(system_router)\n\n    if self._job_options:\n        job_router = JobRouter.create(\n            prefix=self._job_options.prefix,\n            tags=self._job_options.tags,\n            scheduler_factory=get_scheduler,\n        )\n        app.include_router(job_router)\n\n    if self._monitoring_options:\n        from .monitoring import setup_monitoring\n\n        metric_reader = setup_monitoring(\n            app,\n            service_name=self._monitoring_options.service_name,\n            enable_traces=self._monitoring_options.enable_traces,\n        )\n        metrics_router = MetricsRouter.create(\n            prefix=self._monitoring_options.prefix,\n            tags=self._monitoring_options.tags,\n            metric_reader=metric_reader,\n        )\n        app.include_router(metrics_router)\n\n    # Extension point for module-specific routers\n    self._register_module_routers(app)\n\n    for router in self._custom_routers:\n        app.include_router(router)\n\n    # Install route endpoints BEFORE mounting apps (routes take precedence over mounts)\n    self._install_info_endpoint(app, info=self.info)\n\n    # Mount apps AFTER all routes (apps act as catch-all for unmatched paths)\n    if self._app_configs:\n        from fastapi.staticfiles import StaticFiles\n\n        for app_config in self._app_configs:\n            static_files = StaticFiles(directory=str(app_config.directory), html=True)\n            app.mount(app_config.prefix, static_files, name=f\"app_{app_config.manifest.name}\")\n            logger.info(\n                \"app.mounted\",\n                name=app_config.manifest.name,\n                prefix=app_config.prefix,\n                directory=str(app_config.directory),\n                is_package=app_config.is_package,\n            )\n\n    # Initialize app manager for metadata queries (always, even if no apps)\n    from .app import AppManager\n    from .dependencies import set_app_manager\n\n    app_manager = AppManager(self._app_configs)\n    set_app_manager(app_manager)\n\n    for dependency, override in self._dependency_overrides.items():\n        app.dependency_overrides[dependency] = override\n\n    return app\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.service_builder.BaseServiceBuilder.create","title":"<code>create(*, info, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create and build a FastAPI application in one call.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>@classmethod\ndef create(cls, *, info: ServiceInfo, **kwargs: Any) -&gt; FastAPI:\n    \"\"\"Create and build a FastAPI application in one call.\"\"\"\n    return cls(info=info, **kwargs).build()\n</code></pre>"},{"location":"api-reference/#serviceinfo","title":"ServiceInfo","text":""},{"location":"api-reference/#chapkit.core.api.service_builder.ServiceInfo","title":"<code>ServiceInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Service metadata for FastAPI application.</p> Source code in <code>src/chapkit/core/api/service_builder.py</code> <pre><code>class ServiceInfo(BaseModel):\n    \"\"\"Service metadata for FastAPI application.\"\"\"\n\n    display_name: str\n    version: str = \"1.0.0\"\n    summary: str | None = None\n    description: str | None = None\n    contact: dict[str, str] | None = None\n    license_info: dict[str, str] | None = None\n\n    model_config = ConfigDict(extra=\"forbid\")\n</code></pre>"},{"location":"api-reference/#routers","title":"Routers","text":"<p>Base router classes and generic routers.</p>"},{"location":"api-reference/#router","title":"Router","text":""},{"location":"api-reference/#chapkit.core.api.router.Router","title":"<code>Router</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for FastAPI routers.</p> Source code in <code>src/chapkit/core/api/router.py</code> <pre><code>class Router(ABC):\n    \"\"\"Base class for FastAPI routers.\"\"\"\n\n    default_response_model_exclude_none: bool = False\n\n    def __init__(self, prefix: str, tags: Sequence[str], **kwargs: Any) -&gt; None:\n        \"\"\"Initialize router with prefix and tags.\"\"\"\n        self.router = APIRouter(prefix=prefix, tags=list(tags), **kwargs)\n        self._register_routes()\n\n    @classmethod\n    def create(cls, prefix: str, tags: Sequence[str], **kwargs: Any) -&gt; APIRouter:\n        \"\"\"Create a router instance and return the FastAPI router.\"\"\"\n        return cls(prefix=prefix, tags=tags, **kwargs).router\n\n    @abstractmethod\n    def _register_routes(self) -&gt; None:\n        \"\"\"Register routes for this router.\"\"\"\n        ...\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.router.Router.__init__","title":"<code>__init__(prefix, tags, **kwargs)</code>","text":"<p>Initialize router with prefix and tags.</p> Source code in <code>src/chapkit/core/api/router.py</code> <pre><code>def __init__(self, prefix: str, tags: Sequence[str], **kwargs: Any) -&gt; None:\n    \"\"\"Initialize router with prefix and tags.\"\"\"\n    self.router = APIRouter(prefix=prefix, tags=list(tags), **kwargs)\n    self._register_routes()\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.router.Router.create","title":"<code>create(prefix, tags, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a router instance and return the FastAPI router.</p> Source code in <code>src/chapkit/core/api/router.py</code> <pre><code>@classmethod\ndef create(cls, prefix: str, tags: Sequence[str], **kwargs: Any) -&gt; APIRouter:\n    \"\"\"Create a router instance and return the FastAPI router.\"\"\"\n    return cls(prefix=prefix, tags=tags, **kwargs).router\n</code></pre>"},{"location":"api-reference/#crudrouter","title":"CrudRouter","text":""},{"location":"api-reference/#chapkit.core.api.crud.CrudRouter","title":"<code>CrudRouter</code>","text":"<p>               Bases: <code>Router</code></p> <p>Router base class for standard REST CRUD operations.</p> Source code in <code>src/chapkit/core/api/crud.py</code> <pre><code>class CrudRouter[InSchemaT: BaseModel, OutSchemaT: BaseModel](Router):\n    \"\"\"Router base class for standard REST CRUD operations.\"\"\"\n\n    def __init__(\n        self,\n        prefix: str,\n        tags: list[str],\n        entity_in_type: type[InSchemaT],\n        entity_out_type: type[OutSchemaT],\n        manager_factory: ManagerFactory[InSchemaT, OutSchemaT],\n        *,\n        permissions: CrudPermissions | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Initialize CRUD router with entity types and manager factory.\"\"\"\n        self.manager_factory = manager_factory\n        self.entity_in_type = entity_in_type\n        self.entity_out_type = entity_out_type\n        self._permissions = permissions or CrudPermissions()\n        super().__init__(prefix=prefix, tags=tags, **kwargs)\n\n    def _register_routes(self) -&gt; None:\n        \"\"\"Register CRUD routes based on permissions.\"\"\"\n        manager_dependency, manager_annotation = self._manager_dependency()\n        perms = self._permissions\n        if perms.create:\n            self._register_create_route(manager_dependency, manager_annotation)\n        if perms.read:\n            self._register_find_all_route(manager_dependency, manager_annotation)\n            self._register_find_by_id_route(manager_dependency, manager_annotation)\n            self._register_schema_route()\n        if perms.update:\n            self._register_update_route(manager_dependency, manager_annotation)\n        if perms.delete:\n            self._register_delete_route(manager_dependency, manager_annotation)\n\n    def register_entity_operation(\n        self,\n        name: str,\n        handler: Callable[..., Any],\n        *,\n        http_method: str = \"GET\",\n        response_model: type[Any] | None = None,\n        status_code: int | None = None,\n        summary: str | None = None,\n        description: str | None = None,\n    ) -&gt; None:\n        \"\"\"Register a custom entity operation with $ prefix.\n\n        Entity operations are automatically inserted before generic {entity_id} routes\n        to ensure proper route matching (e.g., /{entity_id}/$validate should match\n        before /{entity_id}).\n        \"\"\"\n        route = f\"/{{entity_id}}/${name}\"\n        route_kwargs: dict[str, Any] = {}\n\n        if response_model is not None:\n            route_kwargs[\"response_model\"] = response_model\n        if status_code is not None:\n            route_kwargs[\"status_code\"] = status_code\n        if summary is not None:\n            route_kwargs[\"summary\"] = summary\n        if description is not None:\n            route_kwargs[\"description\"] = description\n\n        # Register the route with the appropriate HTTP method\n        http_method_lower = http_method.lower()\n        if http_method_lower == \"get\":\n            self.router.get(route, **route_kwargs)(handler)\n        elif http_method_lower == \"post\":\n            self.router.post(route, **route_kwargs)(handler)\n        elif http_method_lower == \"put\":\n            self.router.put(route, **route_kwargs)(handler)\n        elif http_method_lower == \"patch\":\n            self.router.patch(route, **route_kwargs)(handler)\n        elif http_method_lower == \"delete\":\n            self.router.delete(route, **route_kwargs)(handler)\n        else:\n            raise ValueError(f\"Unsupported HTTP method: {http_method}\")\n\n        # Move the just-added route to before generic parametric routes\n        # Entity operations like /{entity_id}/$validate should match before /{entity_id}\n        if len(self.router.routes) &gt; 1:\n            new_route = self.router.routes.pop()\n            insert_index = self._find_generic_parametric_route_index()\n            self.router.routes.insert(insert_index, new_route)\n\n    def register_collection_operation(\n        self,\n        name: str,\n        handler: Callable[..., Any],\n        *,\n        http_method: str = \"GET\",\n        response_model: type[Any] | None = None,\n        status_code: int | None = None,\n        summary: str | None = None,\n        description: str | None = None,\n    ) -&gt; None:\n        \"\"\"Register a custom collection operation with $ prefix.\n\n        Collection operations are automatically inserted before parametric {entity_id} routes\n        to ensure proper route matching (e.g., /$stats should match before /{entity_id}).\n        \"\"\"\n        route = f\"/${name}\"\n        route_kwargs: dict[str, Any] = {}\n\n        if response_model is not None:\n            route_kwargs[\"response_model\"] = response_model\n        if status_code is not None:\n            route_kwargs[\"status_code\"] = status_code\n        if summary is not None:\n            route_kwargs[\"summary\"] = summary\n        if description is not None:\n            route_kwargs[\"description\"] = description\n\n        # Register the route with the appropriate HTTP method\n        http_method_lower = http_method.lower()\n        if http_method_lower == \"get\":\n            self.router.get(route, **route_kwargs)(handler)\n        elif http_method_lower == \"post\":\n            self.router.post(route, **route_kwargs)(handler)\n        elif http_method_lower == \"put\":\n            self.router.put(route, **route_kwargs)(handler)\n        elif http_method_lower == \"patch\":\n            self.router.patch(route, **route_kwargs)(handler)\n        elif http_method_lower == \"delete\":\n            self.router.delete(route, **route_kwargs)(handler)\n        else:\n            raise ValueError(f\"Unsupported HTTP method: {http_method}\")\n\n        # Move the just-added route to before parametric routes\n        # FastAPI appends to routes list, so the last route is the one we just added\n        if len(self.router.routes) &gt; 1:\n            new_route = self.router.routes.pop()  # Remove the route we just added\n            # Find the first parametric route and insert before it\n            insert_index = self._find_parametric_route_index()\n            self.router.routes.insert(insert_index, new_route)\n\n    # Route registration helpers --------------------------------------\n\n    def _register_create_route(self, manager_dependency: Any, manager_annotation: Any) -&gt; None:\n        entity_in_annotation: Any = self.entity_in_type\n        entity_out_annotation: Any = self.entity_out_type\n        router_prefix = self.router.prefix\n\n        @self.router.post(\"\", status_code=status.HTTP_201_CREATED, response_model=entity_out_annotation)\n        async def create(\n            entity_in: InSchemaT,\n            request: Request,\n            response: Response,\n            manager: Manager[InSchemaT, OutSchemaT, ULID] = manager_dependency,\n        ) -&gt; OutSchemaT:\n            from .utilities import build_location_url\n\n            created_entity = await manager.save(entity_in)\n            entity_id = getattr(created_entity, \"id\")\n            response.headers[\"Location\"] = build_location_url(request, f\"{router_prefix}/{entity_id}\")\n            return created_entity\n\n        self._annotate_manager(create, manager_annotation)\n        create.__annotations__[\"entity_in\"] = entity_in_annotation\n        create.__annotations__[\"return\"] = entity_out_annotation\n\n    def _register_find_all_route(self, manager_dependency: Any, manager_annotation: Any) -&gt; None:\n        entity_out_annotation: Any = self.entity_out_type\n        collection_response_model: Any = list[entity_out_annotation] | PaginatedResponse[entity_out_annotation]\n\n        @self.router.get(\"\", response_model=collection_response_model)\n        async def find_all(\n            page: int | None = None,\n            size: int | None = None,\n            manager: Manager[InSchemaT, OutSchemaT, ULID] = manager_dependency,\n        ) -&gt; list[OutSchemaT] | PaginatedResponse[OutSchemaT]:\n            from .pagination import create_paginated_response\n\n            # Pagination is opt-in: both page and size must be provided\n            if page is not None and size is not None:\n                items, total = await manager.find_paginated(page, size)\n                return create_paginated_response(items, total, page, size)\n            return await manager.find_all()\n\n        self._annotate_manager(find_all, manager_annotation)\n        find_all.__annotations__[\"return\"] = list[entity_out_annotation] | PaginatedResponse[entity_out_annotation]\n\n    def _register_find_by_id_route(self, manager_dependency: Any, manager_annotation: Any) -&gt; None:\n        entity_out_annotation: Any = self.entity_out_type\n        router_prefix = self.router.prefix\n\n        @self.router.get(\"/{entity_id}\", response_model=entity_out_annotation)\n        async def find_by_id(\n            entity_id: str,\n            manager: Manager[InSchemaT, OutSchemaT, ULID] = manager_dependency,\n        ) -&gt; OutSchemaT:\n            from chapkit.core.exceptions import NotFoundError\n\n            ulid_id = self._parse_ulid(entity_id)\n            entity = await manager.find_by_id(ulid_id)\n            if entity is None:\n                raise NotFoundError(\n                    f\"Entity with id {entity_id} not found\",\n                    instance=f\"{router_prefix}/{entity_id}\",\n                )\n            return entity\n\n        self._annotate_manager(find_by_id, manager_annotation)\n        find_by_id.__annotations__[\"return\"] = entity_out_annotation\n\n    def _register_update_route(self, manager_dependency: Any, manager_annotation: Any) -&gt; None:\n        entity_in_type = self.entity_in_type\n        entity_in_annotation: Any = entity_in_type\n        entity_out_annotation: Any = self.entity_out_type\n        router_prefix = self.router.prefix\n\n        @self.router.put(\"/{entity_id}\", response_model=entity_out_annotation)\n        async def update(\n            entity_id: str,\n            entity_in: InSchemaT,\n            manager: Manager[InSchemaT, OutSchemaT, ULID] = manager_dependency,\n        ) -&gt; OutSchemaT:\n            from chapkit.core.exceptions import NotFoundError\n\n            ulid_id = self._parse_ulid(entity_id)\n            if not await manager.exists_by_id(ulid_id):\n                raise NotFoundError(\n                    f\"Entity with id {entity_id} not found\",\n                    instance=f\"{router_prefix}/{entity_id}\",\n                )\n            entity_dict = entity_in.model_dump(exclude_unset=True)\n            entity_dict[\"id\"] = ulid_id\n            entity_with_id = entity_in_type.model_validate(entity_dict)\n            return await manager.save(entity_with_id)\n\n        self._annotate_manager(update, manager_annotation)\n        update.__annotations__[\"entity_in\"] = entity_in_annotation\n        update.__annotations__[\"return\"] = entity_out_annotation\n\n    def _register_delete_route(self, manager_dependency: Any, manager_annotation: Any) -&gt; None:\n        router_prefix = self.router.prefix\n\n        @self.router.delete(\"/{entity_id}\", status_code=status.HTTP_204_NO_CONTENT)\n        async def delete_by_id(\n            entity_id: str,\n            manager: Manager[InSchemaT, OutSchemaT, ULID] = manager_dependency,\n        ) -&gt; None:\n            from chapkit.core.exceptions import NotFoundError\n\n            ulid_id = self._parse_ulid(entity_id)\n            if not await manager.exists_by_id(ulid_id):\n                raise NotFoundError(\n                    f\"Entity with id {entity_id} not found\",\n                    instance=f\"{router_prefix}/{entity_id}\",\n                )\n            await manager.delete_by_id(ulid_id)\n\n        self._annotate_manager(delete_by_id, manager_annotation)\n\n    def _register_schema_route(self) -&gt; None:\n        \"\"\"Register JSON schema endpoint for the entity output type.\"\"\"\n        entity_out_type = self.entity_out_type\n\n        async def get_schema() -&gt; dict[str, Any]:\n            return entity_out_type.model_json_schema()\n\n        self.register_collection_operation(\n            name=\"schema\",\n            handler=get_schema,\n            http_method=\"GET\",\n            response_model=dict[str, Any],\n        )\n\n    # Helper utilities -------------------------------------------------\n\n    def _manager_dependency(self) -&gt; tuple[Any, Any]:\n        manager_dependency = Depends(self.manager_factory)\n        manager_annotation: Any = Manager[Any, Any, ULID]\n        return manager_dependency, manager_annotation\n\n    def _annotate_manager(self, endpoint: Any, manager_annotation: Any) -&gt; None:\n        endpoint.__annotations__[\"manager\"] = manager_annotation\n\n    def _parse_ulid(self, entity_id: str) -&gt; ULID:\n        from chapkit.core.exceptions import InvalidULIDError\n\n        try:\n            return ULID.from_str(entity_id)\n        except ValueError as e:\n            raise InvalidULIDError(\n                f\"Invalid ULID format: {entity_id}\",\n                instance=f\"{self.router.prefix}/{entity_id}\",\n            ) from e\n\n    def _find_parametric_route_index(self) -&gt; int:\n        \"\"\"Find the index of the first parametric route containing {entity_id}.\n\n        Returns the index where collection operations should be inserted to ensure\n        they're matched before parametric routes.\n        \"\"\"\n        for i, route in enumerate(self.router.routes):\n            route_path = getattr(route, \"path\", \"\")\n            if \"{entity_id}\" in route_path:\n                return i\n        # If no parametric route found, append at the end\n        return len(self.router.routes)\n\n    def _find_generic_parametric_route_index(self) -&gt; int:\n        \"\"\"Find the index of the first generic parametric route (/{entity_id} without $).\n\n        Returns the index where entity operations should be inserted to ensure\n        they're matched before generic routes like GET/PUT/DELETE /{entity_id}.\n        \"\"\"\n        for i, route in enumerate(self.router.routes):\n            route_path = getattr(route, \"path\", \"\")\n            # Match routes like /{entity_id} but not /{entity_id}/$operation\n            if \"{entity_id}\" in route_path and \"/$\" not in route_path:\n                return i\n        # If no generic parametric route found, append at the end\n        return len(self.router.routes)\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.crud.CrudRouter.__init__","title":"<code>__init__(prefix, tags, entity_in_type, entity_out_type, manager_factory, *, permissions=None, **kwargs)</code>","text":"<p>Initialize CRUD router with entity types and manager factory.</p> Source code in <code>src/chapkit/core/api/crud.py</code> <pre><code>def __init__(\n    self,\n    prefix: str,\n    tags: list[str],\n    entity_in_type: type[InSchemaT],\n    entity_out_type: type[OutSchemaT],\n    manager_factory: ManagerFactory[InSchemaT, OutSchemaT],\n    *,\n    permissions: CrudPermissions | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize CRUD router with entity types and manager factory.\"\"\"\n    self.manager_factory = manager_factory\n    self.entity_in_type = entity_in_type\n    self.entity_out_type = entity_out_type\n    self._permissions = permissions or CrudPermissions()\n    super().__init__(prefix=prefix, tags=tags, **kwargs)\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.crud.CrudRouter.register_entity_operation","title":"<code>register_entity_operation(name, handler, *, http_method='GET', response_model=None, status_code=None, summary=None, description=None)</code>","text":"<p>Register a custom entity operation with $ prefix.</p> <p>Entity operations are automatically inserted before generic {entity_id} routes to ensure proper route matching (e.g., /{entity_id}/$validate should match before /{entity_id}).</p> Source code in <code>src/chapkit/core/api/crud.py</code> <pre><code>def register_entity_operation(\n    self,\n    name: str,\n    handler: Callable[..., Any],\n    *,\n    http_method: str = \"GET\",\n    response_model: type[Any] | None = None,\n    status_code: int | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n) -&gt; None:\n    \"\"\"Register a custom entity operation with $ prefix.\n\n    Entity operations are automatically inserted before generic {entity_id} routes\n    to ensure proper route matching (e.g., /{entity_id}/$validate should match\n    before /{entity_id}).\n    \"\"\"\n    route = f\"/{{entity_id}}/${name}\"\n    route_kwargs: dict[str, Any] = {}\n\n    if response_model is not None:\n        route_kwargs[\"response_model\"] = response_model\n    if status_code is not None:\n        route_kwargs[\"status_code\"] = status_code\n    if summary is not None:\n        route_kwargs[\"summary\"] = summary\n    if description is not None:\n        route_kwargs[\"description\"] = description\n\n    # Register the route with the appropriate HTTP method\n    http_method_lower = http_method.lower()\n    if http_method_lower == \"get\":\n        self.router.get(route, **route_kwargs)(handler)\n    elif http_method_lower == \"post\":\n        self.router.post(route, **route_kwargs)(handler)\n    elif http_method_lower == \"put\":\n        self.router.put(route, **route_kwargs)(handler)\n    elif http_method_lower == \"patch\":\n        self.router.patch(route, **route_kwargs)(handler)\n    elif http_method_lower == \"delete\":\n        self.router.delete(route, **route_kwargs)(handler)\n    else:\n        raise ValueError(f\"Unsupported HTTP method: {http_method}\")\n\n    # Move the just-added route to before generic parametric routes\n    # Entity operations like /{entity_id}/$validate should match before /{entity_id}\n    if len(self.router.routes) &gt; 1:\n        new_route = self.router.routes.pop()\n        insert_index = self._find_generic_parametric_route_index()\n        self.router.routes.insert(insert_index, new_route)\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.crud.CrudRouter.register_collection_operation","title":"<code>register_collection_operation(name, handler, *, http_method='GET', response_model=None, status_code=None, summary=None, description=None)</code>","text":"<p>Register a custom collection operation with $ prefix.</p> <p>Collection operations are automatically inserted before parametric {entity_id} routes to ensure proper route matching (e.g., /$stats should match before /{entity_id}).</p> Source code in <code>src/chapkit/core/api/crud.py</code> <pre><code>def register_collection_operation(\n    self,\n    name: str,\n    handler: Callable[..., Any],\n    *,\n    http_method: str = \"GET\",\n    response_model: type[Any] | None = None,\n    status_code: int | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n) -&gt; None:\n    \"\"\"Register a custom collection operation with $ prefix.\n\n    Collection operations are automatically inserted before parametric {entity_id} routes\n    to ensure proper route matching (e.g., /$stats should match before /{entity_id}).\n    \"\"\"\n    route = f\"/${name}\"\n    route_kwargs: dict[str, Any] = {}\n\n    if response_model is not None:\n        route_kwargs[\"response_model\"] = response_model\n    if status_code is not None:\n        route_kwargs[\"status_code\"] = status_code\n    if summary is not None:\n        route_kwargs[\"summary\"] = summary\n    if description is not None:\n        route_kwargs[\"description\"] = description\n\n    # Register the route with the appropriate HTTP method\n    http_method_lower = http_method.lower()\n    if http_method_lower == \"get\":\n        self.router.get(route, **route_kwargs)(handler)\n    elif http_method_lower == \"post\":\n        self.router.post(route, **route_kwargs)(handler)\n    elif http_method_lower == \"put\":\n        self.router.put(route, **route_kwargs)(handler)\n    elif http_method_lower == \"patch\":\n        self.router.patch(route, **route_kwargs)(handler)\n    elif http_method_lower == \"delete\":\n        self.router.delete(route, **route_kwargs)(handler)\n    else:\n        raise ValueError(f\"Unsupported HTTP method: {http_method}\")\n\n    # Move the just-added route to before parametric routes\n    # FastAPI appends to routes list, so the last route is the one we just added\n    if len(self.router.routes) &gt; 1:\n        new_route = self.router.routes.pop()  # Remove the route we just added\n        # Find the first parametric route and insert before it\n        insert_index = self._find_parametric_route_index()\n        self.router.routes.insert(insert_index, new_route)\n</code></pre>"},{"location":"api-reference/#crudpermissions","title":"CrudPermissions","text":""},{"location":"api-reference/#chapkit.core.api.crud.CrudPermissions","title":"<code>CrudPermissions</code>  <code>dataclass</code>","text":"<p>Permissions configuration for CRUD operations.</p> Source code in <code>src/chapkit/core/api/crud.py</code> <pre><code>@dataclass(slots=True)\nclass CrudPermissions:\n    \"\"\"Permissions configuration for CRUD operations.\"\"\"\n\n    create: bool = True\n    read: bool = True\n    update: bool = True\n    delete: bool = True\n</code></pre>"},{"location":"api-reference/#healthrouter","title":"HealthRouter","text":""},{"location":"api-reference/#chapkit.core.api.routers.HealthRouter","title":"<code>HealthRouter</code>","text":"<p>               Bases: <code>Router</code></p> <p>Health check router for service health monitoring.</p> Source code in <code>src/chapkit/core/api/routers/health.py</code> <pre><code>class HealthRouter(Router):\n    \"\"\"Health check router for service health monitoring.\"\"\"\n\n    default_response_model_exclude_none = True\n\n    def __init__(\n        self,\n        prefix: str,\n        tags: list[str],\n        checks: dict[str, HealthCheck] | None = None,\n        **kwargs: object,\n    ) -&gt; None:\n        \"\"\"Initialize health router with optional health checks.\"\"\"\n        self.checks = checks or {}\n        super().__init__(prefix=prefix, tags=tags, **kwargs)\n\n    def _register_routes(self) -&gt; None:\n        \"\"\"Register health check endpoint.\"\"\"\n        checks = self.checks\n\n        async def run_health_checks() -&gt; HealthStatus:\n            \"\"\"Run all health checks and aggregate results.\"\"\"\n            if not checks:\n                return HealthStatus(status=HealthState.HEALTHY)\n\n            check_results: dict[str, CheckResult] = {}\n            overall_state = HealthState.HEALTHY\n\n            for name, check_fn in checks.items():\n                try:\n                    state, message = await check_fn()\n                    check_results[name] = CheckResult(state=state, message=message)\n\n                    if state == HealthState.UNHEALTHY:\n                        overall_state = HealthState.UNHEALTHY\n                    elif state == HealthState.DEGRADED and overall_state == HealthState.HEALTHY:\n                        overall_state = HealthState.DEGRADED\n\n                except Exception as e:\n                    check_results[name] = CheckResult(state=HealthState.UNHEALTHY, message=f\"Check failed: {str(e)}\")\n                    overall_state = HealthState.UNHEALTHY\n\n            return HealthStatus(status=overall_state, checks=check_results)\n\n        @self.router.get(\n            \"\",\n            summary=\"Health check\",\n            response_model=HealthStatus,\n            response_model_exclude_none=self.default_response_model_exclude_none,\n        )\n        async def health_check() -&gt; HealthStatus:\n            return await run_health_checks()\n\n        @self.router.get(\n            \"/$stream\",\n            summary=\"Stream health status updates via SSE\",\n            description=\"Real-time Server-Sent Events stream of health status at regular intervals\",\n        )\n        async def stream_health_status(poll_interval: float = 1.0) -&gt; StreamingResponse:\n            \"\"\"Stream real-time health status updates using Server-Sent Events.\"\"\"\n\n            async def event_stream() -&gt; AsyncGenerator[bytes, None]:\n                while True:\n                    status = await run_health_checks()\n                    yield format_sse_model_event(status, exclude_none=self.default_response_model_exclude_none)\n                    await asyncio.sleep(poll_interval)\n\n            return StreamingResponse(\n                event_stream(),\n                media_type=\"text/event-stream\",\n                headers=SSE_HEADERS,\n            )\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.routers.HealthRouter.__init__","title":"<code>__init__(prefix, tags, checks=None, **kwargs)</code>","text":"<p>Initialize health router with optional health checks.</p> Source code in <code>src/chapkit/core/api/routers/health.py</code> <pre><code>def __init__(\n    self,\n    prefix: str,\n    tags: list[str],\n    checks: dict[str, HealthCheck] | None = None,\n    **kwargs: object,\n) -&gt; None:\n    \"\"\"Initialize health router with optional health checks.\"\"\"\n    self.checks = checks or {}\n    super().__init__(prefix=prefix, tags=tags, **kwargs)\n</code></pre>"},{"location":"api-reference/#jobrouter","title":"JobRouter","text":""},{"location":"api-reference/#chapkit.core.api.routers.JobRouter","title":"<code>JobRouter</code>","text":"<p>               Bases: <code>Router</code></p> <p>REST API router for job scheduler operations.</p> Source code in <code>src/chapkit/core/api/routers/job.py</code> <pre><code>class JobRouter(Router):\n    \"\"\"REST API router for job scheduler operations.\"\"\"\n\n    def __init__(\n        self,\n        prefix: str,\n        tags: list[str],\n        scheduler_factory: Callable[[], JobScheduler],\n        **kwargs: object,\n    ) -&gt; None:\n        \"\"\"Initialize job router with scheduler factory.\"\"\"\n        self.scheduler_factory = scheduler_factory\n        super().__init__(prefix=prefix, tags=tags, **kwargs)\n\n    def _register_routes(self) -&gt; None:\n        \"\"\"Register job management endpoints.\"\"\"\n        scheduler_dependency = Depends(self.scheduler_factory)\n\n        @self.router.get(\"\", summary=\"List all jobs\", response_model=list[JobRecord])\n        async def get_jobs(\n            scheduler: JobScheduler = scheduler_dependency,\n            status_filter: JobStatus | None = None,\n        ) -&gt; list[JobRecord]:\n            jobs = await scheduler.get_all_records()\n            if status_filter:\n                return [job for job in jobs if job.status == status_filter]\n            return jobs\n\n        @self.router.get(\"/$schema\", summary=\"Get jobs list schema\", response_model=dict[str, Any])\n        async def get_jobs_schema() -&gt; dict[str, Any]:\n            \"\"\"Get JSON schema for jobs list response.\"\"\"\n            return TypeAdapter(list[JobRecord]).json_schema()\n\n        @self.router.get(\"/{job_id}\", summary=\"Get job by ID\", response_model=JobRecord)\n        async def get_job(\n            job_id: str,\n            scheduler: JobScheduler = scheduler_dependency,\n        ) -&gt; JobRecord:\n            try:\n                ulid_id = ULID.from_str(job_id)\n                return await scheduler.get_record(ulid_id)\n            except (ValueError, KeyError):\n                raise HTTPException(status_code=404, detail=\"Job not found\")\n\n        @self.router.delete(\"/{job_id}\", summary=\"Cancel and delete job\", status_code=status.HTTP_204_NO_CONTENT)\n        async def delete_job(\n            job_id: str,\n            scheduler: JobScheduler = scheduler_dependency,\n        ) -&gt; Response:\n            try:\n                ulid_id = ULID.from_str(job_id)\n                await scheduler.delete(ulid_id)\n                return Response(status_code=status.HTTP_204_NO_CONTENT)\n            except (ValueError, KeyError):\n                raise HTTPException(status_code=404, detail=\"Job not found\")\n\n        @self.router.get(\n            \"/{job_id}/$stream\",\n            summary=\"Stream job status updates via SSE\",\n            description=\"Real-time Server-Sent Events stream of job status changes until terminal state\",\n        )\n        async def stream_job_status(\n            job_id: str,\n            scheduler: JobScheduler = scheduler_dependency,\n            poll_interval: float = 0.5,\n        ) -&gt; StreamingResponse:\n            \"\"\"Stream real-time job status updates using Server-Sent Events.\"\"\"\n            # Validate job_id format\n            try:\n                ulid_id = ULID.from_str(job_id)\n            except ValueError:\n                raise HTTPException(status_code=400, detail=\"Invalid job ID format\")\n\n            # Check job exists before starting stream\n            try:\n                await scheduler.get_record(ulid_id)\n            except KeyError:\n                raise HTTPException(status_code=404, detail=\"Job not found\")\n\n            # SSE event generator\n            async def event_stream() -&gt; AsyncGenerator[bytes, None]:\n                terminal_states = {\"completed\", \"failed\", \"canceled\"}\n\n                while True:\n                    try:\n                        record = await scheduler.get_record(ulid_id)\n                        # Format as SSE event\n                        yield format_sse_model_event(record)\n\n                        # Stop streaming if job reached terminal state\n                        if record.status in terminal_states:\n                            break\n\n                    except KeyError:\n                        # Job was deleted - send final event and close\n                        yield b'data: {\"status\": \"deleted\"}\\n\\n'\n                        break\n\n                    await asyncio.sleep(poll_interval)\n\n            return StreamingResponse(\n                event_stream(),\n                media_type=\"text/event-stream\",\n                headers=SSE_HEADERS,\n            )\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.routers.JobRouter.__init__","title":"<code>__init__(prefix, tags, scheduler_factory, **kwargs)</code>","text":"<p>Initialize job router with scheduler factory.</p> Source code in <code>src/chapkit/core/api/routers/job.py</code> <pre><code>def __init__(\n    self,\n    prefix: str,\n    tags: list[str],\n    scheduler_factory: Callable[[], JobScheduler],\n    **kwargs: object,\n) -&gt; None:\n    \"\"\"Initialize job router with scheduler factory.\"\"\"\n    self.scheduler_factory = scheduler_factory\n    super().__init__(prefix=prefix, tags=tags, **kwargs)\n</code></pre>"},{"location":"api-reference/#systemrouter","title":"SystemRouter","text":""},{"location":"api-reference/#chapkit.core.api.routers.SystemRouter","title":"<code>SystemRouter</code>","text":"<p>               Bases: <code>Router</code></p> <p>System information router.</p> Source code in <code>src/chapkit/core/api/routers/system.py</code> <pre><code>class SystemRouter(Router):\n    \"\"\"System information router.\"\"\"\n\n    def _register_routes(self) -&gt; None:\n        \"\"\"Register system info endpoint.\"\"\"\n\n        @self.router.get(\n            \"\",\n            summary=\"System information\",\n            response_model=SystemInfo,\n        )\n        async def get_system_info() -&gt; SystemInfo:\n            return SystemInfo(\n                current_time=datetime.now(timezone.utc),\n                timezone=str(datetime.now().astimezone().tzinfo),\n                python_version=f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",\n                platform=platform.platform(),\n                hostname=platform.node(),\n            )\n\n        @self.router.get(\n            \"/apps\",\n            summary=\"List installed apps\",\n            response_model=list[AppInfo],\n        )\n        async def list_apps(\n            app_manager: Annotated[AppManager, Depends(get_app_manager)],\n        ) -&gt; list[AppInfo]:\n            \"\"\"List all installed apps with their metadata.\"\"\"\n            return [\n                AppInfo(\n                    name=app.manifest.name,\n                    version=app.manifest.version,\n                    prefix=app.prefix,\n                    description=app.manifest.description,\n                    author=app.manifest.author,\n                    entry=app.manifest.entry,\n                    is_package=app.is_package,\n                )\n                for app in app_manager.list()\n            ]\n\n        @self.router.get(\n            \"/apps/$schema\",\n            summary=\"Get apps list schema\",\n            response_model=dict[str, Any],\n        )\n        async def get_apps_schema() -&gt; dict[str, Any]:\n            \"\"\"Get JSON schema for apps list response.\"\"\"\n            return TypeAdapter(list[AppInfo]).json_schema()\n</code></pre>"},{"location":"api-reference/#app-system","title":"App System","text":"<p>Static web application hosting system.</p>"},{"location":"api-reference/#apploader","title":"AppLoader","text":""},{"location":"api-reference/#chapkit.core.api.app.AppLoader","title":"<code>AppLoader</code>","text":"<p>Loads and validates apps from filesystem or package resources.</p> Source code in <code>src/chapkit/core/api/app.py</code> <pre><code>class AppLoader:\n    \"\"\"Loads and validates apps from filesystem or package resources.\"\"\"\n\n    @staticmethod\n    def load(path: str | Path | tuple[str, str], prefix: str | None = None) -&gt; App:\n        \"\"\"Load and validate app from filesystem path or package resource tuple.\"\"\"\n        # Detect source type and resolve to directory\n        if isinstance(path, tuple):\n            # Package resource\n            dir_path, is_package = AppLoader._resolve_package_path(path)\n        else:\n            # Filesystem path\n            dir_path = Path(path).resolve()\n            is_package = False\n\n            if not dir_path.exists():\n                raise FileNotFoundError(f\"App directory not found: {dir_path}\")\n            if not dir_path.is_dir():\n                raise NotADirectoryError(f\"App path is not a directory: {dir_path}\")\n\n        # Load and validate manifest\n        manifest_path = dir_path / \"manifest.json\"\n        if not manifest_path.exists():\n            raise FileNotFoundError(f\"manifest.json not found in: {dir_path}\")\n\n        try:\n            with manifest_path.open() as f:\n                manifest_data = json.load(f)\n        except json.JSONDecodeError as e:\n            raise ValueError(f\"Invalid JSON in manifest.json: {e}\") from e\n\n        manifest = AppManifest(**manifest_data)\n\n        # Validate entry file exists\n        entry_path = dir_path / manifest.entry\n        if not entry_path.exists():\n            raise FileNotFoundError(f\"Entry file '{manifest.entry}' not found in: {dir_path}\")\n\n        # Use override or manifest prefix\n        final_prefix = prefix if prefix is not None else manifest.prefix\n\n        # Re-validate prefix if overridden\n        if prefix is not None:\n            validated = AppManifest(\n                name=manifest.name,\n                version=manifest.version,\n                prefix=final_prefix,\n            )\n            final_prefix = validated.prefix\n\n        return App(\n            manifest=manifest,\n            directory=dir_path,\n            prefix=final_prefix,\n            is_package=is_package,\n        )\n\n    @staticmethod\n    def discover(path: str | Path | tuple[str, str]) -&gt; list[App]:\n        \"\"\"Discover all apps with manifest.json in directory.\"\"\"\n        # Resolve directory\n        if isinstance(path, tuple):\n            dir_path, _ = AppLoader._resolve_package_path(path)\n        else:\n            dir_path = Path(path).resolve()\n\n            if not dir_path.exists():\n                raise FileNotFoundError(f\"Apps directory not found: {dir_path}\")\n            if not dir_path.is_dir():\n                raise NotADirectoryError(f\"Apps path is not a directory: {dir_path}\")\n\n        # Scan for subdirectories with manifest.json\n        apps: list[App] = []\n        for subdir in dir_path.iterdir():\n            if subdir.is_dir() and (subdir / \"manifest.json\").exists():\n                try:\n                    # Determine if we're in a package context\n                    if isinstance(path, tuple):\n                        # Build tuple path for subdirectory\n                        package_name: str = path[0]\n                        base_path: str = path[1]\n                        subdir_name = subdir.name\n                        subpath = f\"{base_path}/{subdir_name}\" if base_path else subdir_name\n                        app = AppLoader.load((package_name, subpath))\n                    else:\n                        app = AppLoader.load(subdir)\n                    apps.append(app)\n                except Exception as e:\n                    # Log but don't fail discovery for invalid apps\n                    logger.warning(\n                        \"app.discovery.failed\",\n                        directory=str(subdir),\n                        error=str(e),\n                    )\n\n        return apps\n\n    @staticmethod\n    def _resolve_package_path(package_tuple: tuple[str, str]) -&gt; tuple[Path, bool]:\n        \"\"\"Resolve package resource tuple to filesystem path.\"\"\"\n        package_name, subpath = package_tuple\n\n        # Validate subpath for security\n        if \"..\" in subpath:\n            raise ValueError(f\"subpath cannot contain '..' (got: {subpath})\")\n        if subpath.startswith(\"/\"):\n            raise ValueError(f\"subpath must be relative (got: {subpath})\")\n\n        try:\n            spec = importlib.util.find_spec(package_name)\n        except (ModuleNotFoundError, ValueError) as e:\n            raise ValueError(f\"Package '{package_name}' could not be found\") from e\n\n        if spec is None or spec.origin is None:\n            raise ValueError(f\"Package '{package_name}' could not be found\")\n\n        # Resolve to package directory\n        package_dir = Path(spec.origin).parent\n        app_dir = package_dir / subpath\n\n        # Verify resolved path is still within package directory\n        try:\n            app_dir.resolve().relative_to(package_dir.resolve())\n        except ValueError as e:\n            raise ValueError(f\"App path '{subpath}' escapes package directory\") from e\n\n        if not app_dir.exists():\n            raise FileNotFoundError(f\"App path '{subpath}' not found in package '{package_name}'\")\n        if not app_dir.is_dir():\n            raise NotADirectoryError(f\"App path '{subpath}' in package '{package_name}' is not a directory\")\n\n        return app_dir, True\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.app.AppLoader.load","title":"<code>load(path, prefix=None)</code>  <code>staticmethod</code>","text":"<p>Load and validate app from filesystem path or package resource tuple.</p> Source code in <code>src/chapkit/core/api/app.py</code> <pre><code>@staticmethod\ndef load(path: str | Path | tuple[str, str], prefix: str | None = None) -&gt; App:\n    \"\"\"Load and validate app from filesystem path or package resource tuple.\"\"\"\n    # Detect source type and resolve to directory\n    if isinstance(path, tuple):\n        # Package resource\n        dir_path, is_package = AppLoader._resolve_package_path(path)\n    else:\n        # Filesystem path\n        dir_path = Path(path).resolve()\n        is_package = False\n\n        if not dir_path.exists():\n            raise FileNotFoundError(f\"App directory not found: {dir_path}\")\n        if not dir_path.is_dir():\n            raise NotADirectoryError(f\"App path is not a directory: {dir_path}\")\n\n    # Load and validate manifest\n    manifest_path = dir_path / \"manifest.json\"\n    if not manifest_path.exists():\n        raise FileNotFoundError(f\"manifest.json not found in: {dir_path}\")\n\n    try:\n        with manifest_path.open() as f:\n            manifest_data = json.load(f)\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid JSON in manifest.json: {e}\") from e\n\n    manifest = AppManifest(**manifest_data)\n\n    # Validate entry file exists\n    entry_path = dir_path / manifest.entry\n    if not entry_path.exists():\n        raise FileNotFoundError(f\"Entry file '{manifest.entry}' not found in: {dir_path}\")\n\n    # Use override or manifest prefix\n    final_prefix = prefix if prefix is not None else manifest.prefix\n\n    # Re-validate prefix if overridden\n    if prefix is not None:\n        validated = AppManifest(\n            name=manifest.name,\n            version=manifest.version,\n            prefix=final_prefix,\n        )\n        final_prefix = validated.prefix\n\n    return App(\n        manifest=manifest,\n        directory=dir_path,\n        prefix=final_prefix,\n        is_package=is_package,\n    )\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.app.AppLoader.discover","title":"<code>discover(path)</code>  <code>staticmethod</code>","text":"<p>Discover all apps with manifest.json in directory.</p> Source code in <code>src/chapkit/core/api/app.py</code> <pre><code>@staticmethod\ndef discover(path: str | Path | tuple[str, str]) -&gt; list[App]:\n    \"\"\"Discover all apps with manifest.json in directory.\"\"\"\n    # Resolve directory\n    if isinstance(path, tuple):\n        dir_path, _ = AppLoader._resolve_package_path(path)\n    else:\n        dir_path = Path(path).resolve()\n\n        if not dir_path.exists():\n            raise FileNotFoundError(f\"Apps directory not found: {dir_path}\")\n        if not dir_path.is_dir():\n            raise NotADirectoryError(f\"Apps path is not a directory: {dir_path}\")\n\n    # Scan for subdirectories with manifest.json\n    apps: list[App] = []\n    for subdir in dir_path.iterdir():\n        if subdir.is_dir() and (subdir / \"manifest.json\").exists():\n            try:\n                # Determine if we're in a package context\n                if isinstance(path, tuple):\n                    # Build tuple path for subdirectory\n                    package_name: str = path[0]\n                    base_path: str = path[1]\n                    subdir_name = subdir.name\n                    subpath = f\"{base_path}/{subdir_name}\" if base_path else subdir_name\n                    app = AppLoader.load((package_name, subpath))\n                else:\n                    app = AppLoader.load(subdir)\n                apps.append(app)\n            except Exception as e:\n                # Log but don't fail discovery for invalid apps\n                logger.warning(\n                    \"app.discovery.failed\",\n                    directory=str(subdir),\n                    error=str(e),\n                )\n\n    return apps\n</code></pre>"},{"location":"api-reference/#appmanifest","title":"AppManifest","text":""},{"location":"api-reference/#chapkit.core.api.app.AppManifest","title":"<code>AppManifest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>App manifest configuration.</p> Source code in <code>src/chapkit/core/api/app.py</code> <pre><code>class AppManifest(BaseModel):\n    \"\"\"App manifest configuration.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n\n    name: str = Field(description=\"Human-readable app name\")\n    version: str = Field(description=\"Semantic version\")\n    prefix: str = Field(description=\"URL prefix for mounting\")\n    description: str | None = Field(default=None, description=\"App description\")\n    author: str | None = Field(default=None, description=\"Author name\")\n    entry: str = Field(default=\"index.html\", description=\"Entry point filename\")\n\n    @field_validator(\"prefix\")\n    @classmethod\n    def validate_prefix(cls, v: str) -&gt; str:\n        \"\"\"Validate mount prefix format.\"\"\"\n        if not v.startswith(\"/\"):\n            raise ValueError(\"prefix must start with '/'\")\n        if \"..\" in v:\n            raise ValueError(\"prefix cannot contain '..'\")\n        if v.startswith(\"/api/\") or v == \"/api\":\n            raise ValueError(\"prefix cannot be '/api' or start with '/api/'\")\n        return v\n\n    @field_validator(\"entry\")\n    @classmethod\n    def validate_entry(cls, v: str) -&gt; str:\n        \"\"\"Validate entry file path for security.\"\"\"\n        if \"..\" in v:\n            raise ValueError(\"entry cannot contain '..'\")\n        if v.startswith(\"/\"):\n            raise ValueError(\"entry must be a relative path\")\n        # Normalize and check for path traversal\n        normalized = Path(v).as_posix()\n        if normalized.startswith(\"../\") or \"/../\" in normalized:\n            raise ValueError(\"entry cannot contain path traversal\")\n        return v\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.app.AppManifest.validate_prefix","title":"<code>validate_prefix(v)</code>  <code>classmethod</code>","text":"<p>Validate mount prefix format.</p> Source code in <code>src/chapkit/core/api/app.py</code> <pre><code>@field_validator(\"prefix\")\n@classmethod\ndef validate_prefix(cls, v: str) -&gt; str:\n    \"\"\"Validate mount prefix format.\"\"\"\n    if not v.startswith(\"/\"):\n        raise ValueError(\"prefix must start with '/'\")\n    if \"..\" in v:\n        raise ValueError(\"prefix cannot contain '..'\")\n    if v.startswith(\"/api/\") or v == \"/api\":\n        raise ValueError(\"prefix cannot be '/api' or start with '/api/'\")\n    return v\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.app.AppManifest.validate_entry","title":"<code>validate_entry(v)</code>  <code>classmethod</code>","text":"<p>Validate entry file path for security.</p> Source code in <code>src/chapkit/core/api/app.py</code> <pre><code>@field_validator(\"entry\")\n@classmethod\ndef validate_entry(cls, v: str) -&gt; str:\n    \"\"\"Validate entry file path for security.\"\"\"\n    if \"..\" in v:\n        raise ValueError(\"entry cannot contain '..'\")\n    if v.startswith(\"/\"):\n        raise ValueError(\"entry must be a relative path\")\n    # Normalize and check for path traversal\n    normalized = Path(v).as_posix()\n    if normalized.startswith(\"../\") or \"/../\" in normalized:\n        raise ValueError(\"entry cannot contain path traversal\")\n    return v\n</code></pre>"},{"location":"api-reference/#app","title":"App","text":""},{"location":"api-reference/#chapkit.core.api.app.App","title":"<code>App</code>  <code>dataclass</code>","text":"<p>Represents a loaded app with manifest and directory.</p> Source code in <code>src/chapkit/core/api/app.py</code> <pre><code>@dataclass\nclass App:\n    \"\"\"Represents a loaded app with manifest and directory.\"\"\"\n\n    manifest: AppManifest\n    directory: Path\n    prefix: str  # May differ from manifest if overridden\n    is_package: bool  # True if loaded from package resources\n</code></pre>"},{"location":"api-reference/#appmanager","title":"AppManager","text":""},{"location":"api-reference/#chapkit.core.api.app.AppManager","title":"<code>AppManager</code>","text":"<p>Lightweight manager for app metadata queries.</p> Source code in <code>src/chapkit/core/api/app.py</code> <pre><code>class AppManager:\n    \"\"\"Lightweight manager for app metadata queries.\"\"\"\n\n    def __init__(self, apps: list[App]):\n        \"\"\"Initialize with loaded apps.\"\"\"\n        self._apps = apps\n\n    def list(self) -&gt; list[App]:\n        \"\"\"Return all installed apps.\"\"\"\n        return self._apps\n\n    def get(self, prefix: str) -&gt; App | None:\n        \"\"\"Get app by mount prefix.\"\"\"\n        return next((app for app in self._apps if app.prefix == prefix), None)\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.app.AppManager.__init__","title":"<code>__init__(apps)</code>","text":"<p>Initialize with loaded apps.</p> Source code in <code>src/chapkit/core/api/app.py</code> <pre><code>def __init__(self, apps: list[App]):\n    \"\"\"Initialize with loaded apps.\"\"\"\n    self._apps = apps\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.app.AppManager.list","title":"<code>list()</code>","text":"<p>Return all installed apps.</p> Source code in <code>src/chapkit/core/api/app.py</code> <pre><code>def list(self) -&gt; list[App]:\n    \"\"\"Return all installed apps.\"\"\"\n    return self._apps\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.app.AppManager.get","title":"<code>get(prefix)</code>","text":"<p>Get app by mount prefix.</p> Source code in <code>src/chapkit/core/api/app.py</code> <pre><code>def get(self, prefix: str) -&gt; App | None:\n    \"\"\"Get app by mount prefix.\"\"\"\n    return next((app for app in self._apps if app.prefix == prefix), None)\n</code></pre>"},{"location":"api-reference/#appinfo","title":"AppInfo","text":""},{"location":"api-reference/#chapkit.core.api.app.AppInfo","title":"<code>AppInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>App metadata for API responses.</p> Source code in <code>src/chapkit/core/api/app.py</code> <pre><code>class AppInfo(BaseModel):\n    \"\"\"App metadata for API responses.\"\"\"\n\n    name: str = Field(description=\"Human-readable app name\")\n    version: str = Field(description=\"Semantic version\")\n    prefix: str = Field(description=\"URL prefix for mounting\")\n    description: str | None = Field(default=None, description=\"App description\")\n    author: str | None = Field(default=None, description=\"Author name\")\n    entry: str = Field(description=\"Entry point filename\")\n    is_package: bool = Field(description=\"Whether app is loaded from package resources\")\n</code></pre>"},{"location":"api-reference/#authentication","title":"Authentication","text":"<p>API key authentication middleware and utilities.</p>"},{"location":"api-reference/#apikeymiddleware","title":"APIKeyMiddleware","text":""},{"location":"api-reference/#chapkit.core.api.auth.APIKeyMiddleware","title":"<code>APIKeyMiddleware</code>","text":"<p>               Bases: <code>BaseHTTPMiddleware</code></p> <p>Middleware for API key authentication via X-API-Key header.</p> Source code in <code>src/chapkit/core/api/auth.py</code> <pre><code>class APIKeyMiddleware(BaseHTTPMiddleware):\n    \"\"\"Middleware for API key authentication via X-API-Key header.\"\"\"\n\n    def __init__(\n        self,\n        app: Any,\n        *,\n        api_keys: Set[str],\n        header_name: str = \"X-API-Key\",\n        unauthenticated_paths: Set[str],\n    ) -&gt; None:\n        \"\"\"Initialize API key middleware.\n\n        Args:\n            app: ASGI application\n            api_keys: Set of valid API keys\n            header_name: HTTP header name for API key\n            unauthenticated_paths: Paths that don't require authentication\n        \"\"\"\n        super().__init__(app)\n        self.api_keys = api_keys\n        self.header_name = header_name\n        self.unauthenticated_paths = unauthenticated_paths\n\n    async def dispatch(self, request: Request, call_next: MiddlewareCallNext) -&gt; Response:\n        \"\"\"Process request with API key authentication.\"\"\"\n        # Allow unauthenticated access to specific paths\n        if request.url.path in self.unauthenticated_paths:\n            return await call_next(request)\n\n        # Extract API key from header\n        api_key = request.headers.get(self.header_name)\n\n        if not api_key:\n            logger.warning(\n                \"auth.missing_key\",\n                path=request.url.path,\n                method=request.method,\n            )\n            problem = ProblemDetail(\n                type=\"urn:chapkit:error:unauthorized\",\n                title=\"Unauthorized\",\n                status=status.HTTP_401_UNAUTHORIZED,\n                detail=f\"Missing authentication header: {self.header_name}\",\n                instance=str(request.url.path),\n            )\n            return JSONResponse(\n                status_code=status.HTTP_401_UNAUTHORIZED,\n                content=problem.model_dump(exclude_none=True),\n                media_type=\"application/problem+json\",\n            )\n\n        # Validate API key\n        if api_key not in self.api_keys:\n            # Log only prefix for security\n            key_prefix = api_key[:7] if len(api_key) &gt;= 7 else \"***\"\n            logger.warning(\n                \"auth.invalid_key\",\n                key_prefix=key_prefix,\n                path=request.url.path,\n                method=request.method,\n            )\n            problem = ProblemDetail(\n                type=\"urn:chapkit:error:unauthorized\",\n                title=\"Unauthorized\",\n                status=status.HTTP_401_UNAUTHORIZED,\n                detail=\"Invalid API key\",\n                instance=str(request.url.path),\n            )\n            return JSONResponse(\n                status_code=status.HTTP_401_UNAUTHORIZED,\n                content=problem.model_dump(exclude_none=True),\n                media_type=\"application/problem+json\",\n            )\n\n        # Attach key prefix to request state for logging\n        request.state.api_key_prefix = api_key[:7] if len(api_key) &gt;= 7 else \"***\"\n\n        logger.info(\n            \"auth.success\",\n            key_prefix=request.state.api_key_prefix,\n            path=request.url.path,\n        )\n\n        return await call_next(request)\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.auth.APIKeyMiddleware.__init__","title":"<code>__init__(app, *, api_keys, header_name='X-API-Key', unauthenticated_paths)</code>","text":"<p>Initialize API key middleware.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <code>Any</code> <p>ASGI application</p> required <code>api_keys</code> <code>Set[str]</code> <p>Set of valid API keys</p> required <code>header_name</code> <code>str</code> <p>HTTP header name for API key</p> <code>'X-API-Key'</code> <code>unauthenticated_paths</code> <code>Set[str]</code> <p>Paths that don't require authentication</p> required Source code in <code>src/chapkit/core/api/auth.py</code> <pre><code>def __init__(\n    self,\n    app: Any,\n    *,\n    api_keys: Set[str],\n    header_name: str = \"X-API-Key\",\n    unauthenticated_paths: Set[str],\n) -&gt; None:\n    \"\"\"Initialize API key middleware.\n\n    Args:\n        app: ASGI application\n        api_keys: Set of valid API keys\n        header_name: HTTP header name for API key\n        unauthenticated_paths: Paths that don't require authentication\n    \"\"\"\n    super().__init__(app)\n    self.api_keys = api_keys\n    self.header_name = header_name\n    self.unauthenticated_paths = unauthenticated_paths\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.auth.APIKeyMiddleware.dispatch","title":"<code>dispatch(request, call_next)</code>  <code>async</code>","text":"<p>Process request with API key authentication.</p> Source code in <code>src/chapkit/core/api/auth.py</code> <pre><code>async def dispatch(self, request: Request, call_next: MiddlewareCallNext) -&gt; Response:\n    \"\"\"Process request with API key authentication.\"\"\"\n    # Allow unauthenticated access to specific paths\n    if request.url.path in self.unauthenticated_paths:\n        return await call_next(request)\n\n    # Extract API key from header\n    api_key = request.headers.get(self.header_name)\n\n    if not api_key:\n        logger.warning(\n            \"auth.missing_key\",\n            path=request.url.path,\n            method=request.method,\n        )\n        problem = ProblemDetail(\n            type=\"urn:chapkit:error:unauthorized\",\n            title=\"Unauthorized\",\n            status=status.HTTP_401_UNAUTHORIZED,\n            detail=f\"Missing authentication header: {self.header_name}\",\n            instance=str(request.url.path),\n        )\n        return JSONResponse(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            content=problem.model_dump(exclude_none=True),\n            media_type=\"application/problem+json\",\n        )\n\n    # Validate API key\n    if api_key not in self.api_keys:\n        # Log only prefix for security\n        key_prefix = api_key[:7] if len(api_key) &gt;= 7 else \"***\"\n        logger.warning(\n            \"auth.invalid_key\",\n            key_prefix=key_prefix,\n            path=request.url.path,\n            method=request.method,\n        )\n        problem = ProblemDetail(\n            type=\"urn:chapkit:error:unauthorized\",\n            title=\"Unauthorized\",\n            status=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Invalid API key\",\n            instance=str(request.url.path),\n        )\n        return JSONResponse(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            content=problem.model_dump(exclude_none=True),\n            media_type=\"application/problem+json\",\n        )\n\n    # Attach key prefix to request state for logging\n    request.state.api_key_prefix = api_key[:7] if len(api_key) &gt;= 7 else \"***\"\n\n    logger.info(\n        \"auth.success\",\n        key_prefix=request.state.api_key_prefix,\n        path=request.url.path,\n    )\n\n    return await call_next(request)\n</code></pre>"},{"location":"api-reference/#middleware","title":"Middleware","text":"<p>Error handling and logging middleware.</p>"},{"location":"api-reference/#chapkit.core.api.middleware","title":"<code>middleware</code>","text":"<p>FastAPI middleware for error handling, CORS, and other cross-cutting concerns.</p>"},{"location":"api-reference/#chapkit.core.api.middleware.RequestLoggingMiddleware","title":"<code>RequestLoggingMiddleware</code>","text":"<p>               Bases: <code>BaseHTTPMiddleware</code></p> <p>Middleware for logging HTTP requests with unique request IDs and context binding.</p> Source code in <code>src/chapkit/core/api/middleware.py</code> <pre><code>class RequestLoggingMiddleware(BaseHTTPMiddleware):\n    \"\"\"Middleware for logging HTTP requests with unique request IDs and context binding.\"\"\"\n\n    async def dispatch(self, request: Request, call_next: MiddlewareCallNext) -&gt; Response:\n        \"\"\"Process request with logging and context binding.\"\"\"\n        request_id = str(ULID())\n        start_time = time.perf_counter()\n\n        # Bind request context\n        add_request_context(\n            request_id=request_id,\n            method=request.method,\n            path=request.url.path,\n            client_host=request.client.host if request.client else None,\n        )\n\n        # Add request_id to request state for access in endpoints\n        request.state.request_id = request_id\n\n        logger.info(\n            \"http.request.start\",\n            query_params=str(request.url.query) if request.url.query else None,\n        )\n\n        try:\n            response = await call_next(request)\n            duration_ms = (time.perf_counter() - start_time) * 1000\n\n            logger.info(\n                \"http.request.complete\",\n                status_code=response.status_code,\n                duration_ms=round(duration_ms, 2),\n            )\n\n            # Add request_id to response headers for tracing\n            response.headers[\"X-Request-ID\"] = request_id\n\n            return response\n\n        except Exception as exc:\n            duration_ms = (time.perf_counter() - start_time) * 1000\n\n            logger.error(\n                \"http.request.error\",\n                duration_ms=round(duration_ms, 2),\n                error=str(exc),\n                exc_info=True,\n            )\n            raise\n\n        finally:\n            # Clear request context after response\n            reset_request_context()\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.middleware.RequestLoggingMiddleware.dispatch","title":"<code>dispatch(request, call_next)</code>  <code>async</code>","text":"<p>Process request with logging and context binding.</p> Source code in <code>src/chapkit/core/api/middleware.py</code> <pre><code>async def dispatch(self, request: Request, call_next: MiddlewareCallNext) -&gt; Response:\n    \"\"\"Process request with logging and context binding.\"\"\"\n    request_id = str(ULID())\n    start_time = time.perf_counter()\n\n    # Bind request context\n    add_request_context(\n        request_id=request_id,\n        method=request.method,\n        path=request.url.path,\n        client_host=request.client.host if request.client else None,\n    )\n\n    # Add request_id to request state for access in endpoints\n    request.state.request_id = request_id\n\n    logger.info(\n        \"http.request.start\",\n        query_params=str(request.url.query) if request.url.query else None,\n    )\n\n    try:\n        response = await call_next(request)\n        duration_ms = (time.perf_counter() - start_time) * 1000\n\n        logger.info(\n            \"http.request.complete\",\n            status_code=response.status_code,\n            duration_ms=round(duration_ms, 2),\n        )\n\n        # Add request_id to response headers for tracing\n        response.headers[\"X-Request-ID\"] = request_id\n\n        return response\n\n    except Exception as exc:\n        duration_ms = (time.perf_counter() - start_time) * 1000\n\n        logger.error(\n            \"http.request.error\",\n            duration_ms=round(duration_ms, 2),\n            error=str(exc),\n            exc_info=True,\n        )\n        raise\n\n    finally:\n        # Clear request context after response\n        reset_request_context()\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.middleware.database_error_handler","title":"<code>database_error_handler(request, exc)</code>  <code>async</code>","text":"<p>Handle database errors and return error response.</p> Source code in <code>src/chapkit/core/api/middleware.py</code> <pre><code>async def database_error_handler(request: Request, exc: Exception) -&gt; JSONResponse:\n    \"\"\"Handle database errors and return error response.\"\"\"\n    logger.error(\n        \"database.error\",\n        error=str(exc),\n        path=request.url.path,\n        exc_info=True,\n    )\n    return JSONResponse(\n        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n        content={\"detail\": \"Database error occurred\", \"error\": str(exc)},\n    )\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.middleware.validation_error_handler","title":"<code>validation_error_handler(request, exc)</code>  <code>async</code>","text":"<p>Handle validation errors and return error response.</p> Source code in <code>src/chapkit/core/api/middleware.py</code> <pre><code>async def validation_error_handler(request: Request, exc: Exception) -&gt; JSONResponse:\n    \"\"\"Handle validation errors and return error response.\"\"\"\n    logger.warning(\n        \"validation.error\",\n        error=str(exc),\n        path=request.url.path,\n    )\n    return JSONResponse(\n        status_code=status.HTTP_422_UNPROCESSABLE_CONTENT,\n        content={\"detail\": \"Validation error\", \"errors\": str(exc)},\n    )\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.middleware.chapkit_exception_handler","title":"<code>chapkit_exception_handler(request, exc)</code>  <code>async</code>","text":"<p>Handle ChapkitException and return RFC 9457 Problem Details.</p> Source code in <code>src/chapkit/core/api/middleware.py</code> <pre><code>async def chapkit_exception_handler(request: Request, exc: ChapkitException) -&gt; JSONResponse:\n    \"\"\"Handle ChapkitException and return RFC 9457 Problem Details.\"\"\"\n    logger.warning(\n        \"chapkit.error\",\n        error_type=exc.type_uri,\n        status=exc.status,\n        detail=exc.detail,\n        path=request.url.path,\n    )\n\n    problem = ProblemDetail(\n        type=exc.type_uri,\n        title=exc.title,\n        status=exc.status,\n        detail=exc.detail,\n        instance=exc.instance or str(request.url),\n        **exc.extensions,\n    )\n\n    return JSONResponse(\n        status_code=exc.status,\n        content=problem.model_dump(exclude_none=True),\n        media_type=\"application/problem+json\",\n    )\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.middleware.add_error_handlers","title":"<code>add_error_handlers(app)</code>","text":"<p>Add error handlers to FastAPI application.</p> Source code in <code>src/chapkit/core/api/middleware.py</code> <pre><code>def add_error_handlers(app: Any) -&gt; None:\n    \"\"\"Add error handlers to FastAPI application.\"\"\"\n    from pydantic import ValidationError\n    from sqlalchemy.exc import SQLAlchemyError\n\n    app.add_exception_handler(ChapkitException, chapkit_exception_handler)\n    app.add_exception_handler(SQLAlchemyError, database_error_handler)\n    app.add_exception_handler(ValidationError, validation_error_handler)\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.middleware.add_logging_middleware","title":"<code>add_logging_middleware(app)</code>","text":"<p>Add request logging middleware to FastAPI application.</p> Source code in <code>src/chapkit/core/api/middleware.py</code> <pre><code>def add_logging_middleware(app: Any) -&gt; None:\n    \"\"\"Add request logging middleware to FastAPI application.\"\"\"\n    app.add_middleware(RequestLoggingMiddleware)\n</code></pre>"},{"location":"api-reference/#dependencies","title":"Dependencies","text":"<p>FastAPI dependency injection functions.</p>"},{"location":"api-reference/#chapkit.core.api.dependencies","title":"<code>dependencies</code>","text":"<p>Generic FastAPI dependency injection for database and scheduler.</p>"},{"location":"api-reference/#chapkit.core.api.dependencies.set_database","title":"<code>set_database(database)</code>","text":"<p>Set the global database instance.</p> Source code in <code>src/chapkit/core/api/dependencies.py</code> <pre><code>def set_database(database: Database) -&gt; None:\n    \"\"\"Set the global database instance.\"\"\"\n    global _database\n    _database = database\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.dependencies.get_database","title":"<code>get_database()</code>","text":"<p>Get the global database instance.</p> Source code in <code>src/chapkit/core/api/dependencies.py</code> <pre><code>def get_database() -&gt; Database:\n    \"\"\"Get the global database instance.\"\"\"\n    if _database is None:\n        raise RuntimeError(\"Database not initialized. Call set_database() during app startup.\")\n    return _database\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.dependencies.get_session","title":"<code>get_session(db)</code>  <code>async</code>","text":"<p>Get a database session for dependency injection.</p> Source code in <code>src/chapkit/core/api/dependencies.py</code> <pre><code>async def get_session(db: Annotated[Database, Depends(get_database)]) -&gt; AsyncIterator[AsyncSession]:\n    \"\"\"Get a database session for dependency injection.\"\"\"\n    async with db.session() as session:\n        yield session\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.dependencies.set_scheduler","title":"<code>set_scheduler(scheduler)</code>","text":"<p>Set the global scheduler instance.</p> Source code in <code>src/chapkit/core/api/dependencies.py</code> <pre><code>def set_scheduler(scheduler: JobScheduler) -&gt; None:\n    \"\"\"Set the global scheduler instance.\"\"\"\n    global _scheduler\n    _scheduler = scheduler\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.dependencies.get_scheduler","title":"<code>get_scheduler()</code>","text":"<p>Get the global scheduler instance.</p> Source code in <code>src/chapkit/core/api/dependencies.py</code> <pre><code>def get_scheduler() -&gt; JobScheduler:\n    \"\"\"Get the global scheduler instance.\"\"\"\n    if _scheduler is None:\n        raise RuntimeError(\"Scheduler not initialized. Call set_scheduler() during app startup.\")\n    return _scheduler\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.dependencies.set_app_manager","title":"<code>set_app_manager(manager)</code>","text":"<p>Set the global app manager instance.</p> Source code in <code>src/chapkit/core/api/dependencies.py</code> <pre><code>def set_app_manager(manager: AppManager) -&gt; None:\n    \"\"\"Set the global app manager instance.\"\"\"\n    global _app_manager\n    _app_manager = manager\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.dependencies.get_app_manager","title":"<code>get_app_manager()</code>","text":"<p>Get the global app manager instance.</p> Source code in <code>src/chapkit/core/api/dependencies.py</code> <pre><code>def get_app_manager() -&gt; AppManager:\n    \"\"\"Get the global app manager instance.\"\"\"\n    if _app_manager is None:\n        raise RuntimeError(\"AppManager not initialized. Call set_app_manager() during app startup.\")\n    return _app_manager\n</code></pre>"},{"location":"api-reference/#pagination","title":"Pagination","text":"<p>Pagination helpers for collection endpoints.</p>"},{"location":"api-reference/#chapkit.core.api.pagination","title":"<code>pagination</code>","text":"<p>Pagination utilities for API endpoints.</p>"},{"location":"api-reference/#chapkit.core.api.pagination.PaginationParams","title":"<code>PaginationParams</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Query parameters for opt-in pagination (both page and size required).</p> Source code in <code>src/chapkit/core/api/pagination.py</code> <pre><code>class PaginationParams(BaseModel):\n    \"\"\"Query parameters for opt-in pagination (both page and size required).\"\"\"\n\n    page: int | None = Field(default=None, ge=1, description=\"Page number (1-indexed)\")\n    size: int | None = Field(default=None, ge=1, le=100, description=\"Number of items per page (max 100)\")\n\n    def is_paginated(self) -&gt; bool:\n        \"\"\"Check if both page and size parameters are provided.\"\"\"\n        return self.page is not None and self.size is not None\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.pagination.PaginationParams.is_paginated","title":"<code>is_paginated()</code>","text":"<p>Check if both page and size parameters are provided.</p> Source code in <code>src/chapkit/core/api/pagination.py</code> <pre><code>def is_paginated(self) -&gt; bool:\n    \"\"\"Check if both page and size parameters are provided.\"\"\"\n    return self.page is not None and self.size is not None\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.pagination.create_paginated_response","title":"<code>create_paginated_response(items, total, page, size)</code>","text":"<p>Create paginated response with items and metadata.</p> Source code in <code>src/chapkit/core/api/pagination.py</code> <pre><code>def create_paginated_response(items: list[T], total: int, page: int, size: int) -&gt; PaginatedResponse[T]:\n    \"\"\"Create paginated response with items and metadata.\"\"\"\n    return PaginatedResponse(items=items, total=total, page=page, size=size)\n</code></pre>"},{"location":"api-reference/#utilities","title":"Utilities","text":"<p>Utility functions for FastAPI applications.</p>"},{"location":"api-reference/#chapkit.core.api.utilities","title":"<code>utilities</code>","text":"<p>Utility functions for FastAPI routers and endpoints.</p>"},{"location":"api-reference/#chapkit.core.api.utilities.build_location_url","title":"<code>build_location_url(request, path)</code>","text":"<p>Build a full URL for the Location header.</p> Source code in <code>src/chapkit/core/api/utilities.py</code> <pre><code>def build_location_url(request: Request, path: str) -&gt; str:\n    \"\"\"Build a full URL for the Location header.\"\"\"\n    return f\"{request.url.scheme}://{request.url.netloc}{path}\"\n</code></pre>"},{"location":"api-reference/#chapkit.core.api.utilities.run_app","title":"<code>run_app(app, *, host=None, port=None, workers=None, reload=None, log_level=None, **uvicorn_kwargs)</code>","text":"<p>Run FastAPI app with Uvicorn development server.</p> <p>For reload to work, pass a string in \"module:app\" format. App instance disables reload automatically.</p> <p>Examples:</p> <pre><code># Direct execution (reload disabled)\nif __name__ == \"__main__\":\n    run_app(app)\n\n# With module path (reload enabled)\nrun_app(\"examples.config_api:app\")\n\n# Production: multiple workers\nrun_app(app, workers=4)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>app</code> <code>Any | str</code> <p>FastAPI app instance OR string \"module:app\" path</p> required <code>host</code> <code>str | None</code> <p>Server host (default: \"127.0.0.1\", env: HOST)</p> <code>None</code> <code>port</code> <code>int | None</code> <p>Server port (default: 8000, env: PORT)</p> <code>None</code> <code>workers</code> <code>int | None</code> <p>Number of worker processes (default: 1, env: WORKERS)</p> <code>None</code> <code>reload</code> <code>bool | None</code> <p>Enable auto-reload (default: True for string, False for instance)</p> <code>None</code> <code>log_level</code> <code>str | None</code> <p>Logging level (default: from LOG_LEVEL env var or \"info\")</p> <code>None</code> <code>**uvicorn_kwargs</code> <code>Any</code> <p>Additional uvicorn.run() arguments</p> <code>{}</code> Source code in <code>src/chapkit/core/api/utilities.py</code> <pre><code>def run_app(\n    app: Any | str,\n    *,\n    host: str | None = None,\n    port: int | None = None,\n    workers: int | None = None,\n    reload: bool | None = None,\n    log_level: str | None = None,\n    **uvicorn_kwargs: Any,\n) -&gt; None:\n    \"\"\"Run FastAPI app with Uvicorn development server.\n\n    For reload to work, pass a string in \"module:app\" format.\n    App instance disables reload automatically.\n\n    Examples:\n    --------\n        # Direct execution (reload disabled)\n        if __name__ == \"__main__\":\n            run_app(app)\n\n        # With module path (reload enabled)\n        run_app(\"examples.config_api:app\")\n\n        # Production: multiple workers\n        run_app(app, workers=4)\n\n    Args:\n        app: FastAPI app instance OR string \"module:app\" path\n        host: Server host (default: \"127.0.0.1\", env: HOST)\n        port: Server port (default: 8000, env: PORT)\n        workers: Number of worker processes (default: 1, env: WORKERS)\n        reload: Enable auto-reload (default: True for string, False for instance)\n        log_level: Logging level (default: from LOG_LEVEL env var or \"info\")\n        **uvicorn_kwargs: Additional uvicorn.run() arguments\n    \"\"\"\n    import uvicorn\n\n    # Configure structured logging before uvicorn starts\n    from chapkit.core.logging import configure_logging\n\n    configure_logging()\n\n    # Read from environment variables with defaults\n    resolved_host: str = host if host is not None else os.getenv(\"HOST\", \"127.0.0.1\")\n    resolved_port: int = port if port is not None else int(os.getenv(\"PORT\", \"8000\"))\n    resolved_workers: int = workers if workers is not None else int(os.getenv(\"WORKERS\", \"1\"))\n    resolved_log_level: str = log_level if log_level is not None else os.getenv(\"LOG_LEVEL\", \"info\").lower()\n\n    # Auto-detect reload behavior if not specified\n    if reload is None:\n        reload = isinstance(app, str)  # Enable reload for string paths, disable for instances\n\n    # Auto-reload is incompatible with multiple workers\n    if resolved_workers &gt; 1 and reload:\n        reload = False\n\n    uvicorn.run(\n        app,\n        host=resolved_host,\n        port=resolved_port,\n        workers=resolved_workers,\n        reload=reload,\n        log_level=resolved_log_level,\n        log_config=None,  # Disable uvicorn's default logging config\n        **uvicorn_kwargs,\n    )\n</code></pre>"},{"location":"api-reference/#application-layer","title":"Application Layer","text":"<p>High-level application orchestration.</p>"},{"location":"api-reference/#servicebuilder","title":"ServiceBuilder","text":"<p>Domain-aware service builder with module support.</p>"},{"location":"api-reference/#chapkit.api.service_builder.ServiceBuilder","title":"<code>ServiceBuilder</code>","text":"<p>               Bases: <code>BaseServiceBuilder</code></p> <p>Service builder with integrated module support (config, artifact, task).</p> Source code in <code>src/chapkit/api/service_builder.py</code> <pre><code>class ServiceBuilder(BaseServiceBuilder):\n    \"\"\"Service builder with integrated module support (config, artifact, task).\"\"\"\n\n    def __init__(self, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize service builder with module-specific state.\"\"\"\n        super().__init__(**kwargs)\n        self._config_options: _ConfigOptions | None = None\n        self._artifact_options: _ArtifactOptions | None = None\n        self._task_options: _TaskOptions | None = None\n        self._ml_options: _MLOptions | None = None\n\n    # --------------------------------------------------------------------- Module-specific fluent methods\n\n    def with_config(\n        self,\n        schema: type[BaseConfig],\n        *,\n        prefix: str = \"/api/v1/configs\",\n        tags: List[str] | None = None,\n        permissions: CrudPermissions | None = None,\n        allow_create: bool | None = None,\n        allow_read: bool | None = None,\n        allow_update: bool | None = None,\n        allow_delete: bool | None = None,\n    ) -&gt; Self:\n        base = permissions or CrudPermissions()\n        perms = CrudPermissions(\n            create=allow_create if allow_create is not None else base.create,\n            read=allow_read if allow_read is not None else base.read,\n            update=allow_update if allow_update is not None else base.update,\n            delete=allow_delete if allow_delete is not None else base.delete,\n        )\n        self._config_options = _ConfigOptions(\n            schema=schema,\n            prefix=prefix,\n            tags=list(tags) if tags else [\"Config\"],\n            permissions=perms,\n        )\n        return self\n\n    def with_artifacts(\n        self,\n        *,\n        hierarchy: ArtifactHierarchy,\n        prefix: str = \"/api/v1/artifacts\",\n        tags: List[str] | None = None,\n        enable_config_linking: bool = False,\n        permissions: CrudPermissions | None = None,\n        allow_create: bool | None = None,\n        allow_read: bool | None = None,\n        allow_update: bool | None = None,\n        allow_delete: bool | None = None,\n    ) -&gt; Self:\n        base = permissions or CrudPermissions()\n        perms = CrudPermissions(\n            create=allow_create if allow_create is not None else base.create,\n            read=allow_read if allow_read is not None else base.read,\n            update=allow_update if allow_update is not None else base.update,\n            delete=allow_delete if allow_delete is not None else base.delete,\n        )\n        self._artifact_options = _ArtifactOptions(\n            hierarchy=hierarchy,\n            prefix=prefix,\n            tags=list(tags) if tags else [\"Artifacts\"],\n            enable_config_linking=enable_config_linking,\n            permissions=perms,\n        )\n        return self\n\n    def with_tasks(\n        self,\n        *,\n        prefix: str = \"/api/v1/tasks\",\n        tags: List[str] | None = None,\n        permissions: CrudPermissions | None = None,\n        validate_on_startup: bool = True,\n        allow_create: bool | None = None,\n        allow_read: bool | None = None,\n        allow_update: bool | None = None,\n        allow_delete: bool | None = None,\n    ) -&gt; Self:\n        \"\"\"Enable task execution endpoints with script runner.\"\"\"\n        base = permissions or CrudPermissions()\n        perms = CrudPermissions(\n            create=allow_create if allow_create is not None else base.create,\n            read=allow_read if allow_read is not None else base.read,\n            update=allow_update if allow_update is not None else base.update,\n            delete=allow_delete if allow_delete is not None else base.delete,\n        )\n        self._task_options = _TaskOptions(\n            prefix=prefix,\n            tags=list(tags) if tags else [\"Tasks\"],\n            permissions=perms,\n            validate_on_startup=validate_on_startup,\n        )\n        return self\n\n    def with_ml(\n        self,\n        runner: ModelRunnerProtocol,\n        *,\n        prefix: str = \"/api/v1/ml\",\n        tags: List[str] | None = None,\n    ) -&gt; Self:\n        \"\"\"Enable ML train/predict endpoints with model runner.\"\"\"\n        self._ml_options = _MLOptions(\n            runner=runner,\n            prefix=prefix,\n            tags=list(tags) if tags else [\"ML\"],\n        )\n        return self\n\n    # --------------------------------------------------------------------- Extension point implementations\n\n    def _validate_module_configuration(self) -&gt; None:\n        \"\"\"Validate module-specific configuration.\"\"\"\n        if self._artifact_options and self._artifact_options.enable_config_linking and not self._config_options:\n            raise ValueError(\n                \"Artifact config-linking requires a config schema. \"\n                \"Call `with_config(...)` before enabling config linking in artifacts.\"\n            )\n\n        if self._task_options and not self._artifact_options:\n            raise ValueError(\n                \"Task execution requires artifacts to store results. Call `with_artifacts(...)` before `with_tasks()`.\"\n            )\n\n        if self._ml_options:\n            if not self._config_options:\n                raise ValueError(\n                    \"ML operations require config for model configuration. \"\n                    \"Call `with_config(...)` before `with_ml(...)`.\"\n                )\n            if not self._artifact_options:\n                raise ValueError(\n                    \"ML operations require artifacts for model storage. \"\n                    \"Call `with_artifacts(...)` before `with_ml(...)`.\"\n                )\n            if not self._job_options:\n                raise ValueError(\n                    \"ML operations require job scheduler for async execution. \"\n                    \"Call `with_jobs(...)` before `with_ml(...)`.\"\n                )\n\n    def _register_module_routers(self, app: FastAPI) -&gt; None:\n        \"\"\"Register module-specific routers (config, artifact, task).\"\"\"\n        if self._config_options:\n            config_options = self._config_options\n            config_schema = config_options.schema\n            config_dep = self._build_config_dependency(config_schema)\n            entity_in_type: type[ConfigIn[BaseConfig]] = ConfigIn[config_schema]  # type: ignore[valid-type]\n            entity_out_type: type[ConfigOut[BaseConfig]] = ConfigOut[config_schema]  # type: ignore[valid-type]\n            config_router = ConfigRouter.create(\n                prefix=config_options.prefix,\n                tags=config_options.tags,\n                manager_factory=config_dep,\n                entity_in_type=entity_in_type,\n                entity_out_type=entity_out_type,\n                permissions=config_options.permissions,\n                enable_artifact_operations=(\n                    self._artifact_options is not None and self._artifact_options.enable_config_linking\n                ),\n            )\n            app.include_router(config_router)\n            app.dependency_overrides[default_get_config_manager] = config_dep\n\n        if self._artifact_options:\n            artifact_options = self._artifact_options\n            artifact_dep = self._build_artifact_dependency(\n                hierarchy=artifact_options.hierarchy,\n                include_config=artifact_options.enable_config_linking,\n            )\n            artifact_router = ArtifactRouter.create(\n                prefix=artifact_options.prefix,\n                tags=artifact_options.tags,\n                manager_factory=artifact_dep,\n                entity_in_type=ArtifactIn,\n                entity_out_type=ArtifactOut,\n                permissions=artifact_options.permissions,\n                enable_config_access=self._config_options is not None and artifact_options.enable_config_linking,\n            )\n            app.include_router(artifact_router)\n            app.dependency_overrides[default_get_artifact_manager] = artifact_dep\n\n        if self._task_options:\n            task_options = self._task_options\n            task_dep = self._build_task_dependency()\n            task_router = TaskRouter.create(\n                prefix=task_options.prefix,\n                tags=task_options.tags,\n                manager_factory=task_dep,\n                entity_in_type=TaskIn,\n                entity_out_type=TaskOut,\n                permissions=task_options.permissions,\n            )\n            app.include_router(task_router)\n            app.dependency_overrides[default_get_task_manager] = task_dep\n\n            # Register validation startup hook if enabled\n            if task_options.validate_on_startup:\n\n                async def _validate_tasks_on_startup(app_instance: FastAPI) -&gt; None:\n                    \"\"\"Validate and disable orphaned Python tasks on startup.\"\"\"\n                    await validate_and_disable_orphaned_tasks(app_instance)\n\n                self._startup_hooks.append(_validate_tasks_on_startup)\n\n        if self._ml_options:\n            ml_options = self._ml_options\n            ml_dep = self._build_ml_dependency()\n            ml_router = MLRouter.create(\n                prefix=ml_options.prefix,\n                tags=ml_options.tags,\n                manager_factory=ml_dep,\n            )\n            app.include_router(ml_router)\n            app.dependency_overrides[default_get_ml_manager] = ml_dep\n\n    # --------------------------------------------------------------------- Module dependency builders\n\n    @staticmethod\n    def _build_config_dependency(\n        schema: type[BaseConfig],\n    ) -&gt; DependencyFactory:\n        async def _dependency(session: AsyncSession = Depends(get_session)) -&gt; ConfigManager[BaseConfig]:\n            repo = ConfigRepository(session)\n            return ConfigManager[BaseConfig](repo, schema)\n\n        return _dependency\n\n    @staticmethod\n    def _build_artifact_dependency(\n        *,\n        hierarchy: ArtifactHierarchy,\n        include_config: bool,\n    ) -&gt; DependencyFactory:\n        async def _dependency(session: AsyncSession = Depends(get_session)) -&gt; ArtifactManager:\n            artifact_repo = ArtifactRepository(session)\n            config_repo = ConfigRepository(session) if include_config else None\n            return ArtifactManager(artifact_repo, hierarchy=hierarchy, config_repo=config_repo)\n\n        return _dependency\n\n    @staticmethod\n    def _build_task_dependency() -&gt; DependencyFactory:\n        async def _dependency(\n            session: AsyncSession = Depends(get_session),\n            artifact_manager: ArtifactManager = Depends(default_get_artifact_manager),\n        ) -&gt; TaskManager:\n            repo = TaskRepository(session)\n            try:\n                scheduler = get_scheduler()\n            except RuntimeError:\n                scheduler = None\n            try:\n                database = get_database()\n            except RuntimeError:\n                database = None\n            return TaskManager(repo, scheduler, database, artifact_manager)\n\n        return _dependency\n\n    def _build_ml_dependency(self) -&gt; DependencyFactory:\n        ml_runner = self._ml_options.runner if self._ml_options else None\n        config_schema = self._config_options.schema if self._config_options else None\n\n        async def _dependency() -&gt; MLManager:\n            if ml_runner is None:\n                raise RuntimeError(\"ML runner not configured\")\n            if config_schema is None:\n                raise RuntimeError(\"Config schema not configured\")\n\n            runner: ModelRunnerProtocol = ml_runner\n            scheduler = get_scheduler()\n            database = get_database()\n            return MLManager(runner, scheduler, database, config_schema)\n\n        return _dependency\n</code></pre>"},{"location":"api-reference/#chapkit.api.service_builder.ServiceBuilder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize service builder with module-specific state.</p> Source code in <code>src/chapkit/api/service_builder.py</code> <pre><code>def __init__(self, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize service builder with module-specific state.\"\"\"\n    super().__init__(**kwargs)\n    self._config_options: _ConfigOptions | None = None\n    self._artifact_options: _ArtifactOptions | None = None\n    self._task_options: _TaskOptions | None = None\n    self._ml_options: _MLOptions | None = None\n</code></pre>"},{"location":"api-reference/#chapkit.api.service_builder.ServiceBuilder.with_tasks","title":"<code>with_tasks(*, prefix='/api/v1/tasks', tags=None, permissions=None, validate_on_startup=True, allow_create=None, allow_read=None, allow_update=None, allow_delete=None)</code>","text":"<p>Enable task execution endpoints with script runner.</p> Source code in <code>src/chapkit/api/service_builder.py</code> <pre><code>def with_tasks(\n    self,\n    *,\n    prefix: str = \"/api/v1/tasks\",\n    tags: List[str] | None = None,\n    permissions: CrudPermissions | None = None,\n    validate_on_startup: bool = True,\n    allow_create: bool | None = None,\n    allow_read: bool | None = None,\n    allow_update: bool | None = None,\n    allow_delete: bool | None = None,\n) -&gt; Self:\n    \"\"\"Enable task execution endpoints with script runner.\"\"\"\n    base = permissions or CrudPermissions()\n    perms = CrudPermissions(\n        create=allow_create if allow_create is not None else base.create,\n        read=allow_read if allow_read is not None else base.read,\n        update=allow_update if allow_update is not None else base.update,\n        delete=allow_delete if allow_delete is not None else base.delete,\n    )\n    self._task_options = _TaskOptions(\n        prefix=prefix,\n        tags=list(tags) if tags else [\"Tasks\"],\n        permissions=perms,\n        validate_on_startup=validate_on_startup,\n    )\n    return self\n</code></pre>"},{"location":"api-reference/#chapkit.api.service_builder.ServiceBuilder.with_ml","title":"<code>with_ml(runner, *, prefix='/api/v1/ml', tags=None)</code>","text":"<p>Enable ML train/predict endpoints with model runner.</p> Source code in <code>src/chapkit/api/service_builder.py</code> <pre><code>def with_ml(\n    self,\n    runner: ModelRunnerProtocol,\n    *,\n    prefix: str = \"/api/v1/ml\",\n    tags: List[str] | None = None,\n) -&gt; Self:\n    \"\"\"Enable ML train/predict endpoints with model runner.\"\"\"\n    self._ml_options = _MLOptions(\n        runner=runner,\n        prefix=prefix,\n        tags=list(tags) if tags else [\"ML\"],\n    )\n    return self\n</code></pre>"},{"location":"api-reference/#mlservicebuilder","title":"MLServiceBuilder","text":"<p>Specialized builder for machine learning services.</p>"},{"location":"api-reference/#chapkit.api.service_builder.MLServiceBuilder","title":"<code>MLServiceBuilder</code>","text":"<p>               Bases: <code>ServiceBuilder</code></p> <p>Specialized service builder for ML services with all required components pre-configured.</p> Source code in <code>src/chapkit/api/service_builder.py</code> <pre><code>class MLServiceBuilder(ServiceBuilder):\n    \"\"\"Specialized service builder for ML services with all required components pre-configured.\"\"\"\n\n    def __init__(\n        self,\n        *,\n        info: ServiceInfo | MLServiceInfo,\n        config_schema: type[BaseConfig],\n        hierarchy: ArtifactHierarchy,\n        runner: ModelRunnerProtocol,\n        database_url: str = \"sqlite+aiosqlite:///:memory:\",\n        include_error_handlers: bool = True,\n        include_logging: bool = True,\n    ) -&gt; None:\n        \"\"\"Initialize ML service builder with required ML components.\"\"\"\n        super().__init__(\n            info=info,\n            database_url=database_url,\n            include_error_handlers=include_error_handlers,\n            include_logging=include_logging,\n        )\n\n        # Automatically configure required ML components\n        self.with_health()\n        self.with_system()\n        self.with_config(config_schema)\n        self.with_artifacts(hierarchy=hierarchy, enable_config_linking=True)\n        self.with_jobs()\n        self.with_landing_page()\n        self.with_ml(runner=runner)\n</code></pre>"},{"location":"api-reference/#chapkit.api.service_builder.MLServiceBuilder.__init__","title":"<code>__init__(*, info, config_schema, hierarchy, runner, database_url='sqlite+aiosqlite:///:memory:', include_error_handlers=True, include_logging=True)</code>","text":"<p>Initialize ML service builder with required ML components.</p> Source code in <code>src/chapkit/api/service_builder.py</code> <pre><code>def __init__(\n    self,\n    *,\n    info: ServiceInfo | MLServiceInfo,\n    config_schema: type[BaseConfig],\n    hierarchy: ArtifactHierarchy,\n    runner: ModelRunnerProtocol,\n    database_url: str = \"sqlite+aiosqlite:///:memory:\",\n    include_error_handlers: bool = True,\n    include_logging: bool = True,\n) -&gt; None:\n    \"\"\"Initialize ML service builder with required ML components.\"\"\"\n    super().__init__(\n        info=info,\n        database_url=database_url,\n        include_error_handlers=include_error_handlers,\n        include_logging=include_logging,\n    )\n\n    # Automatically configure required ML components\n    self.with_health()\n    self.with_system()\n    self.with_config(config_schema)\n    self.with_artifacts(hierarchy=hierarchy, enable_config_linking=True)\n    self.with_jobs()\n    self.with_landing_page()\n    self.with_ml(runner=runner)\n</code></pre>"},{"location":"api-reference/#dependencies_1","title":"Dependencies","text":"<p>Application-level dependency injection functions.</p>"},{"location":"api-reference/#chapkit.api.dependencies","title":"<code>dependencies</code>","text":"<p>Feature-specific FastAPI dependency injection for managers.</p>"},{"location":"api-reference/#chapkit.api.dependencies.get_config_manager","title":"<code>get_config_manager(session)</code>  <code>async</code>","text":"<p>Get a config manager instance for dependency injection.</p> Source code in <code>src/chapkit/api/dependencies.py</code> <pre><code>async def get_config_manager(session: Annotated[AsyncSession, Depends(get_session)]) -&gt; ConfigManager[BaseConfig]:\n    \"\"\"Get a config manager instance for dependency injection.\"\"\"\n    repo = ConfigRepository(session)\n    return ConfigManager[BaseConfig](repo, BaseConfig)\n</code></pre>"},{"location":"api-reference/#chapkit.api.dependencies.get_artifact_manager","title":"<code>get_artifact_manager(session)</code>  <code>async</code>","text":"<p>Get an artifact manager instance for dependency injection.</p> Source code in <code>src/chapkit/api/dependencies.py</code> <pre><code>async def get_artifact_manager(session: Annotated[AsyncSession, Depends(get_session)]) -&gt; ArtifactManager:\n    \"\"\"Get an artifact manager instance for dependency injection.\"\"\"\n    artifact_repo = ArtifactRepository(session)\n    config_repo = ConfigRepository(session)\n    return ArtifactManager(artifact_repo, config_repo=config_repo)\n</code></pre>"},{"location":"api-reference/#chapkit.api.dependencies.get_task_manager","title":"<code>get_task_manager(session, artifact_manager)</code>  <code>async</code>","text":"<p>Get a task manager instance for dependency injection.</p> Source code in <code>src/chapkit/api/dependencies.py</code> <pre><code>async def get_task_manager(\n    session: Annotated[AsyncSession, Depends(get_session)],\n    artifact_manager: Annotated[ArtifactManager, Depends(get_artifact_manager)],\n) -&gt; TaskManager:\n    \"\"\"Get a task manager instance for dependency injection.\"\"\"\n    from chapkit.core import Database\n    from chapkit.core.scheduler import JobScheduler\n\n    repo = TaskRepository(session)\n\n    # Get scheduler if available\n    scheduler: JobScheduler | None\n    try:\n        scheduler = get_scheduler()\n    except RuntimeError:\n        scheduler = None\n\n    # Get database if available\n    database: Database | None\n    try:\n        database = get_database()\n    except RuntimeError:\n        database = None\n\n    return TaskManager(repo, scheduler, database, artifact_manager)\n</code></pre>"},{"location":"api-reference/#chapkit.api.dependencies.get_ml_manager","title":"<code>get_ml_manager()</code>  <code>async</code>","text":"<p>Get an ML manager instance for dependency injection.</p> <p>Note: This is a placeholder. The actual dependency is built by ServiceBuilder with the runner in closure, then overridden via app.dependency_overrides.</p> Source code in <code>src/chapkit/api/dependencies.py</code> <pre><code>async def get_ml_manager() -&gt; MLManager:\n    \"\"\"Get an ML manager instance for dependency injection.\n\n    Note: This is a placeholder. The actual dependency is built by ServiceBuilder\n    with the runner in closure, then overridden via app.dependency_overrides.\n    \"\"\"\n    raise RuntimeError(\"ML manager dependency not configured. Use ServiceBuilder.with_ml() to enable ML operations.\")\n</code></pre>"},{"location":"api-reference/#domain-modules","title":"Domain Modules","text":"<p>Vertical slice modules with complete functionality.</p>"},{"location":"api-reference/#config-module","title":"Config Module","text":"<p>Key-value configuration with JSON data support.</p>"},{"location":"api-reference/#chapkit.modules.config","title":"<code>config</code>","text":"<p>Config feature - key-value configuration with JSON data storage.</p>"},{"location":"api-reference/#chapkit.modules.config.ConfigManager","title":"<code>ConfigManager</code>","text":"<p>               Bases: <code>BaseManager[Config, ConfigIn[DataT], ConfigOut[DataT], ULID]</code></p> <p>Manager for Config entities with artifact linking operations.</p> Source code in <code>src/chapkit/modules/config/manager.py</code> <pre><code>class ConfigManager[DataT: BaseConfig](BaseManager[Config, ConfigIn[DataT], ConfigOut[DataT], ULID]):\n    \"\"\"Manager for Config entities with artifact linking operations.\"\"\"\n\n    def __init__(self, repo: ConfigRepository, data_cls: type[DataT]) -&gt; None:\n        \"\"\"Initialize config manager with repository and data class.\"\"\"\n        super().__init__(repo, Config, ConfigOut)\n        self.repo: ConfigRepository = repo\n        self.data_cls = data_cls\n\n    async def find_by_name(self, name: str) -&gt; ConfigOut[DataT] | None:\n        \"\"\"Find a config by its unique name.\"\"\"\n        config = await self.repo.find_by_name(name)\n        if config:\n            return self._to_output_schema(config)\n        return None\n\n    async def link_artifact(self, config_id: ULID, artifact_id: ULID) -&gt; None:\n        \"\"\"Link a config to a root artifact.\"\"\"\n        await self.repo.link_artifact(config_id, artifact_id)\n        await self.repo.commit()\n\n    async def unlink_artifact(self, artifact_id: ULID) -&gt; None:\n        \"\"\"Unlink an artifact from its config.\"\"\"\n        await self.repo.unlink_artifact(artifact_id)\n        await self.repo.commit()\n\n    async def get_config_for_artifact(\n        self, artifact_id: ULID, artifact_repo: ArtifactRepository\n    ) -&gt; ConfigOut[DataT] | None:\n        \"\"\"Get the config for an artifact by traversing to its root.\"\"\"\n        root = await artifact_repo.get_root_artifact(artifact_id)\n        if root is None:\n            return None\n\n        config = await self.repo.find_by_root_artifact_id(root.id)\n        if config is None:\n            return None\n\n        return self._to_output_schema(config)\n\n    async def get_linked_artifacts(self, config_id: ULID) -&gt; list[ArtifactOut]:\n        \"\"\"Get all root artifacts linked to a config.\"\"\"\n        artifacts = await self.repo.find_artifacts_for_config(config_id)\n        return [ArtifactOut.model_validate(artifact, from_attributes=True) for artifact in artifacts]\n\n    def _to_output_schema(self, entity: Config) -&gt; ConfigOut[DataT]:\n        \"\"\"Convert ORM entity to output schema with proper data class validation.\"\"\"\n        return ConfigOut[DataT].model_validate(entity, from_attributes=True, context={\"data_cls\": self.data_cls})\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigManager.__init__","title":"<code>__init__(repo, data_cls)</code>","text":"<p>Initialize config manager with repository and data class.</p> Source code in <code>src/chapkit/modules/config/manager.py</code> <pre><code>def __init__(self, repo: ConfigRepository, data_cls: type[DataT]) -&gt; None:\n    \"\"\"Initialize config manager with repository and data class.\"\"\"\n    super().__init__(repo, Config, ConfigOut)\n    self.repo: ConfigRepository = repo\n    self.data_cls = data_cls\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigManager.find_by_name","title":"<code>find_by_name(name)</code>  <code>async</code>","text":"<p>Find a config by its unique name.</p> Source code in <code>src/chapkit/modules/config/manager.py</code> <pre><code>async def find_by_name(self, name: str) -&gt; ConfigOut[DataT] | None:\n    \"\"\"Find a config by its unique name.\"\"\"\n    config = await self.repo.find_by_name(name)\n    if config:\n        return self._to_output_schema(config)\n    return None\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigManager.link_artifact","title":"<code>link_artifact(config_id, artifact_id)</code>  <code>async</code>","text":"<p>Link a config to a root artifact.</p> Source code in <code>src/chapkit/modules/config/manager.py</code> <pre><code>async def link_artifact(self, config_id: ULID, artifact_id: ULID) -&gt; None:\n    \"\"\"Link a config to a root artifact.\"\"\"\n    await self.repo.link_artifact(config_id, artifact_id)\n    await self.repo.commit()\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigManager.unlink_artifact","title":"<code>unlink_artifact(artifact_id)</code>  <code>async</code>","text":"<p>Unlink an artifact from its config.</p> Source code in <code>src/chapkit/modules/config/manager.py</code> <pre><code>async def unlink_artifact(self, artifact_id: ULID) -&gt; None:\n    \"\"\"Unlink an artifact from its config.\"\"\"\n    await self.repo.unlink_artifact(artifact_id)\n    await self.repo.commit()\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigManager.get_config_for_artifact","title":"<code>get_config_for_artifact(artifact_id, artifact_repo)</code>  <code>async</code>","text":"<p>Get the config for an artifact by traversing to its root.</p> Source code in <code>src/chapkit/modules/config/manager.py</code> <pre><code>async def get_config_for_artifact(\n    self, artifact_id: ULID, artifact_repo: ArtifactRepository\n) -&gt; ConfigOut[DataT] | None:\n    \"\"\"Get the config for an artifact by traversing to its root.\"\"\"\n    root = await artifact_repo.get_root_artifact(artifact_id)\n    if root is None:\n        return None\n\n    config = await self.repo.find_by_root_artifact_id(root.id)\n    if config is None:\n        return None\n\n    return self._to_output_schema(config)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigManager.get_linked_artifacts","title":"<code>get_linked_artifacts(config_id)</code>  <code>async</code>","text":"<p>Get all root artifacts linked to a config.</p> Source code in <code>src/chapkit/modules/config/manager.py</code> <pre><code>async def get_linked_artifacts(self, config_id: ULID) -&gt; list[ArtifactOut]:\n    \"\"\"Get all root artifacts linked to a config.\"\"\"\n    artifacts = await self.repo.find_artifacts_for_config(config_id)\n    return [ArtifactOut.model_validate(artifact, from_attributes=True) for artifact in artifacts]\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.Config","title":"<code>Config</code>","text":"<p>               Bases: <code>Entity</code></p> <p>ORM model for configuration with JSON data storage.</p> Source code in <code>src/chapkit/modules/config/models.py</code> <pre><code>class Config(Entity):\n    \"\"\"ORM model for configuration with JSON data storage.\"\"\"\n\n    __tablename__ = \"configs\"\n\n    name: Mapped[str] = mapped_column(index=True)\n    _data_json: Mapped[dict[str, Any]] = mapped_column(\"data\", JSON, nullable=False)\n\n    @property\n    def data(self) -&gt; dict[str, Any]:\n        \"\"\"Return JSON data as dict.\"\"\"\n        return self._data_json\n\n    @data.setter\n    def data(self, value: BaseConfig | dict[str, Any]) -&gt; None:\n        \"\"\"Serialize Pydantic model to JSON or store dict directly.\"\"\"\n        if isinstance(value, dict):\n            self._data_json = value\n        elif hasattr(value, \"model_dump\") and callable(value.model_dump):\n            # BaseConfig or other Pydantic model\n            self._data_json = value.model_dump(mode=\"json\")\n        else:\n            raise TypeError(f\"data must be a BaseConfig subclass or dict, got {type(value)}\")\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.Config.data","title":"<code>data</code>  <code>property</code> <code>writable</code>","text":"<p>Return JSON data as dict.</p>"},{"location":"api-reference/#chapkit.modules.config.ConfigArtifact","title":"<code>ConfigArtifact</code>","text":"<p>               Bases: <code>Base</code></p> <p>Junction table linking Configs to root Artifacts.</p> Source code in <code>src/chapkit/modules/config/models.py</code> <pre><code>class ConfigArtifact(Base):\n    \"\"\"Junction table linking Configs to root Artifacts.\"\"\"\n\n    __tablename__ = \"config_artifacts\"\n\n    config_id: Mapped[ULID] = mapped_column(\n        ULIDType,\n        ForeignKey(\"configs.id\", ondelete=\"CASCADE\"),\n        primary_key=True,\n    )\n\n    artifact_id: Mapped[ULID] = mapped_column(\n        ULIDType,\n        ForeignKey(\"artifacts.id\", ondelete=\"CASCADE\"),\n        primary_key=True,\n        unique=True,\n    )\n\n    __table_args__ = (UniqueConstraint(\"artifact_id\", name=\"uq_artifact_id\"),)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigRepository","title":"<code>ConfigRepository</code>","text":"<p>               Bases: <code>BaseRepository[Config, ULID]</code></p> <p>Repository for Config entities with artifact linking operations.</p> Source code in <code>src/chapkit/modules/config/repository.py</code> <pre><code>class ConfigRepository(BaseRepository[Config, ULID]):\n    \"\"\"Repository for Config entities with artifact linking operations.\"\"\"\n\n    def __init__(self, session: AsyncSession) -&gt; None:\n        \"\"\"Initialize config repository with database session.\"\"\"\n        super().__init__(session, Config)\n\n    async def find_by_name(self, name: str) -&gt; Config | None:\n        \"\"\"Find a config by its unique name.\"\"\"\n        result = await self.s.scalars(select(self.model).where(self.model.name == name))\n        return result.one_or_none()\n\n    async def link_artifact(self, config_id: ULID, artifact_id: ULID) -&gt; None:\n        \"\"\"Link a config to a root artifact.\"\"\"\n        artifact = await self.s.get(Artifact, artifact_id)\n        if artifact is None:\n            raise ValueError(f\"Artifact {artifact_id} not found\")\n        if artifact.parent_id is not None:\n            raise ValueError(f\"Artifact {artifact_id} is not a root artifact (parent_id={artifact.parent_id})\")\n\n        link = ConfigArtifact(config_id=config_id, artifact_id=artifact_id)\n        self.s.add(link)\n\n    async def unlink_artifact(self, artifact_id: ULID) -&gt; None:\n        \"\"\"Unlink an artifact from its config.\"\"\"\n        stmt = sql_delete(ConfigArtifact).where(ConfigArtifact.artifact_id == artifact_id)\n        await self.s.execute(stmt)\n\n    async def delete_by_id(self, id: ULID) -&gt; None:\n        \"\"\"Delete a config and cascade delete all linked artifact trees.\"\"\"\n        from chapkit.modules.artifact.repository import ArtifactRepository\n\n        linked_artifacts = await self.find_artifacts_for_config(id)\n\n        artifact_repo = ArtifactRepository(self.s)\n        for root_artifact in linked_artifacts:\n            subtree = await artifact_repo.find_subtree(root_artifact.id)\n            for artifact in subtree:\n                await self.s.delete(artifact)\n\n        await super().delete_by_id(id)\n\n    async def find_by_root_artifact_id(self, artifact_id: ULID) -&gt; Config | None:\n        \"\"\"Find the config linked to a root artifact.\"\"\"\n        stmt = (\n            select(Config)\n            .join(ConfigArtifact, Config.id == ConfigArtifact.config_id)\n            .where(ConfigArtifact.artifact_id == artifact_id)\n        )\n        result = await self.s.scalars(stmt)\n        return result.one_or_none()\n\n    async def find_artifacts_for_config(self, config_id: ULID) -&gt; list[Artifact]:\n        \"\"\"Find all root artifacts linked to a config.\"\"\"\n        stmt = (\n            select(Artifact)\n            .join(ConfigArtifact, Artifact.id == ConfigArtifact.artifact_id)\n            .where(ConfigArtifact.config_id == config_id)\n        )\n        result = await self.s.scalars(stmt)\n        return list(result.all())\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigRepository.__init__","title":"<code>__init__(session)</code>","text":"<p>Initialize config repository with database session.</p> Source code in <code>src/chapkit/modules/config/repository.py</code> <pre><code>def __init__(self, session: AsyncSession) -&gt; None:\n    \"\"\"Initialize config repository with database session.\"\"\"\n    super().__init__(session, Config)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigRepository.find_by_name","title":"<code>find_by_name(name)</code>  <code>async</code>","text":"<p>Find a config by its unique name.</p> Source code in <code>src/chapkit/modules/config/repository.py</code> <pre><code>async def find_by_name(self, name: str) -&gt; Config | None:\n    \"\"\"Find a config by its unique name.\"\"\"\n    result = await self.s.scalars(select(self.model).where(self.model.name == name))\n    return result.one_or_none()\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigRepository.link_artifact","title":"<code>link_artifact(config_id, artifact_id)</code>  <code>async</code>","text":"<p>Link a config to a root artifact.</p> Source code in <code>src/chapkit/modules/config/repository.py</code> <pre><code>async def link_artifact(self, config_id: ULID, artifact_id: ULID) -&gt; None:\n    \"\"\"Link a config to a root artifact.\"\"\"\n    artifact = await self.s.get(Artifact, artifact_id)\n    if artifact is None:\n        raise ValueError(f\"Artifact {artifact_id} not found\")\n    if artifact.parent_id is not None:\n        raise ValueError(f\"Artifact {artifact_id} is not a root artifact (parent_id={artifact.parent_id})\")\n\n    link = ConfigArtifact(config_id=config_id, artifact_id=artifact_id)\n    self.s.add(link)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigRepository.unlink_artifact","title":"<code>unlink_artifact(artifact_id)</code>  <code>async</code>","text":"<p>Unlink an artifact from its config.</p> Source code in <code>src/chapkit/modules/config/repository.py</code> <pre><code>async def unlink_artifact(self, artifact_id: ULID) -&gt; None:\n    \"\"\"Unlink an artifact from its config.\"\"\"\n    stmt = sql_delete(ConfigArtifact).where(ConfigArtifact.artifact_id == artifact_id)\n    await self.s.execute(stmt)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigRepository.delete_by_id","title":"<code>delete_by_id(id)</code>  <code>async</code>","text":"<p>Delete a config and cascade delete all linked artifact trees.</p> Source code in <code>src/chapkit/modules/config/repository.py</code> <pre><code>async def delete_by_id(self, id: ULID) -&gt; None:\n    \"\"\"Delete a config and cascade delete all linked artifact trees.\"\"\"\n    from chapkit.modules.artifact.repository import ArtifactRepository\n\n    linked_artifacts = await self.find_artifacts_for_config(id)\n\n    artifact_repo = ArtifactRepository(self.s)\n    for root_artifact in linked_artifacts:\n        subtree = await artifact_repo.find_subtree(root_artifact.id)\n        for artifact in subtree:\n            await self.s.delete(artifact)\n\n    await super().delete_by_id(id)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigRepository.find_by_root_artifact_id","title":"<code>find_by_root_artifact_id(artifact_id)</code>  <code>async</code>","text":"<p>Find the config linked to a root artifact.</p> Source code in <code>src/chapkit/modules/config/repository.py</code> <pre><code>async def find_by_root_artifact_id(self, artifact_id: ULID) -&gt; Config | None:\n    \"\"\"Find the config linked to a root artifact.\"\"\"\n    stmt = (\n        select(Config)\n        .join(ConfigArtifact, Config.id == ConfigArtifact.config_id)\n        .where(ConfigArtifact.artifact_id == artifact_id)\n    )\n    result = await self.s.scalars(stmt)\n    return result.one_or_none()\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigRepository.find_artifacts_for_config","title":"<code>find_artifacts_for_config(config_id)</code>  <code>async</code>","text":"<p>Find all root artifacts linked to a config.</p> Source code in <code>src/chapkit/modules/config/repository.py</code> <pre><code>async def find_artifacts_for_config(self, config_id: ULID) -&gt; list[Artifact]:\n    \"\"\"Find all root artifacts linked to a config.\"\"\"\n    stmt = (\n        select(Artifact)\n        .join(ConfigArtifact, Artifact.id == ConfigArtifact.artifact_id)\n        .where(ConfigArtifact.config_id == config_id)\n    )\n    result = await self.s.scalars(stmt)\n    return list(result.all())\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigRouter","title":"<code>ConfigRouter</code>","text":"<p>               Bases: <code>CrudRouter[ConfigIn[BaseConfig], ConfigOut[BaseConfig]]</code></p> <p>CRUD router for Config entities with artifact linking operations.</p> Source code in <code>src/chapkit/modules/config/router.py</code> <pre><code>class ConfigRouter(CrudRouter[ConfigIn[BaseConfig], ConfigOut[BaseConfig]]):\n    \"\"\"CRUD router for Config entities with artifact linking operations.\"\"\"\n\n    def __init__(\n        self,\n        prefix: str,\n        tags: Sequence[str],\n        manager_factory: Any,\n        entity_in_type: type[ConfigIn[BaseConfig]],\n        entity_out_type: type[ConfigOut[BaseConfig]],\n        permissions: CrudPermissions | None = None,\n        enable_artifact_operations: bool = False,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Initialize config router with entity types and manager factory.\"\"\"\n        self.enable_artifact_operations = enable_artifact_operations\n        super().__init__(\n            prefix=prefix,\n            tags=list(tags),\n            entity_in_type=entity_in_type,\n            entity_out_type=entity_out_type,\n            manager_factory=manager_factory,\n            permissions=permissions,\n            **kwargs,\n        )\n\n    def _register_routes(self) -&gt; None:\n        \"\"\"Register config CRUD routes and artifact linking operations.\"\"\"\n        super()._register_routes()\n\n        if not self.enable_artifact_operations:\n            return\n\n        manager_factory = self.manager_factory\n\n        async def link_artifact(\n            entity_id: str,\n            request: LinkArtifactRequest,\n            manager: ConfigManager[BaseConfig] = Depends(manager_factory),\n        ) -&gt; None:\n            config_id = self._parse_ulid(entity_id)\n\n            try:\n                await manager.link_artifact(config_id, request.artifact_id)\n            except ValueError as e:\n                raise HTTPException(\n                    status_code=status.HTTP_400_BAD_REQUEST,\n                    detail=str(e),\n                )\n\n        async def unlink_artifact(\n            entity_id: str,\n            request: UnlinkArtifactRequest,\n            manager: ConfigManager[BaseConfig] = Depends(manager_factory),\n        ) -&gt; None:\n            try:\n                await manager.unlink_artifact(request.artifact_id)\n            except Exception as e:\n                raise HTTPException(\n                    status_code=status.HTTP_400_BAD_REQUEST,\n                    detail=str(e),\n                )\n\n        async def get_linked_artifacts(\n            entity_id: str,\n            manager: ConfigManager[BaseConfig] = Depends(manager_factory),\n        ) -&gt; list[ArtifactOut]:\n            config_id = self._parse_ulid(entity_id)\n            return await manager.get_linked_artifacts(config_id)\n\n        self.register_entity_operation(\n            \"link-artifact\",\n            link_artifact,\n            http_method=\"POST\",\n            status_code=status.HTTP_204_NO_CONTENT,\n            summary=\"Link artifact to config\",\n            description=\"Link a config to a root artifact (parent_id IS NULL)\",\n        )\n\n        self.register_entity_operation(\n            \"unlink-artifact\",\n            unlink_artifact,\n            http_method=\"POST\",\n            status_code=status.HTTP_204_NO_CONTENT,\n            summary=\"Unlink artifact from config\",\n            description=\"Remove the link between a config and an artifact\",\n        )\n\n        self.register_entity_operation(\n            \"artifacts\",\n            get_linked_artifacts,\n            http_method=\"GET\",\n            response_model=list[ArtifactOut],\n            summary=\"Get linked artifacts\",\n            description=\"Get all root artifacts linked to this config\",\n        )\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigRouter.__init__","title":"<code>__init__(prefix, tags, manager_factory, entity_in_type, entity_out_type, permissions=None, enable_artifact_operations=False, **kwargs)</code>","text":"<p>Initialize config router with entity types and manager factory.</p> Source code in <code>src/chapkit/modules/config/router.py</code> <pre><code>def __init__(\n    self,\n    prefix: str,\n    tags: Sequence[str],\n    manager_factory: Any,\n    entity_in_type: type[ConfigIn[BaseConfig]],\n    entity_out_type: type[ConfigOut[BaseConfig]],\n    permissions: CrudPermissions | None = None,\n    enable_artifact_operations: bool = False,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize config router with entity types and manager factory.\"\"\"\n    self.enable_artifact_operations = enable_artifact_operations\n    super().__init__(\n        prefix=prefix,\n        tags=list(tags),\n        entity_in_type=entity_in_type,\n        entity_out_type=entity_out_type,\n        manager_factory=manager_factory,\n        permissions=permissions,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.BaseConfig","title":"<code>BaseConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for configuration schemas with arbitrary extra fields allowed.</p> Source code in <code>src/chapkit/modules/config/schemas.py</code> <pre><code>class BaseConfig(BaseModel):\n    \"\"\"Base class for configuration schemas with arbitrary extra fields allowed.\"\"\"\n\n    model_config = {\"extra\": \"allow\"}\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigIn","title":"<code>ConfigIn</code>","text":"<p>               Bases: <code>EntityIn</code></p> <p>Input schema for creating or updating configurations.</p> Source code in <code>src/chapkit/modules/config/schemas.py</code> <pre><code>class ConfigIn[DataT: BaseConfig](EntityIn):\n    \"\"\"Input schema for creating or updating configurations.\"\"\"\n\n    name: str\n    data: DataT\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigOut","title":"<code>ConfigOut</code>","text":"<p>               Bases: <code>EntityOut</code></p> <p>Output schema for configuration entities.</p> Source code in <code>src/chapkit/modules/config/schemas.py</code> <pre><code>class ConfigOut[DataT: BaseConfig](EntityOut):\n    \"\"\"Output schema for configuration entities.\"\"\"\n\n    name: str\n    data: DataT\n\n    model_config = {\"ser_json_timedelta\": \"float\", \"ser_json_bytes\": \"base64\"}\n\n    @field_validator(\"data\", mode=\"before\")\n    @classmethod\n    def convert_dict_to_model(cls, v: Any, info: ValidationInfo) -&gt; Any:\n        \"\"\"Convert dict to BaseConfig model if data_cls is provided in validation context.\"\"\"\n        if isinstance(v, BaseConfig):\n            return v\n        if isinstance(v, dict):\n            if info.context and \"data_cls\" in info.context:\n                data_cls = info.context[\"data_cls\"]\n                return data_cls.model_validate(v)\n        return v\n\n    @field_serializer(\"data\", when_used=\"json\")\n    def serialize_data(self, value: DataT) -&gt; dict[str, Any]:\n        \"\"\"Serialize BaseConfig data to JSON dict.\"\"\"\n        if isinstance(value, BaseConfig):  # pyright: ignore[reportUnnecessaryIsInstance]\n            return value.model_dump(mode=\"json\")\n        return value\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigOut.convert_dict_to_model","title":"<code>convert_dict_to_model(v, info)</code>  <code>classmethod</code>","text":"<p>Convert dict to BaseConfig model if data_cls is provided in validation context.</p> Source code in <code>src/chapkit/modules/config/schemas.py</code> <pre><code>@field_validator(\"data\", mode=\"before\")\n@classmethod\ndef convert_dict_to_model(cls, v: Any, info: ValidationInfo) -&gt; Any:\n    \"\"\"Convert dict to BaseConfig model if data_cls is provided in validation context.\"\"\"\n    if isinstance(v, BaseConfig):\n        return v\n    if isinstance(v, dict):\n        if info.context and \"data_cls\" in info.context:\n            data_cls = info.context[\"data_cls\"]\n            return data_cls.model_validate(v)\n    return v\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.ConfigOut.serialize_data","title":"<code>serialize_data(value)</code>","text":"<p>Serialize BaseConfig data to JSON dict.</p> Source code in <code>src/chapkit/modules/config/schemas.py</code> <pre><code>@field_serializer(\"data\", when_used=\"json\")\ndef serialize_data(self, value: DataT) -&gt; dict[str, Any]:\n    \"\"\"Serialize BaseConfig data to JSON dict.\"\"\"\n    if isinstance(value, BaseConfig):  # pyright: ignore[reportUnnecessaryIsInstance]\n        return value.model_dump(mode=\"json\")\n    return value\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.LinkArtifactRequest","title":"<code>LinkArtifactRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request schema for linking an artifact to a config.</p> Source code in <code>src/chapkit/modules/config/schemas.py</code> <pre><code>class LinkArtifactRequest(BaseModel):\n    \"\"\"Request schema for linking an artifact to a config.\"\"\"\n\n    artifact_id: ULID\n</code></pre>"},{"location":"api-reference/#chapkit.modules.config.UnlinkArtifactRequest","title":"<code>UnlinkArtifactRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request schema for unlinking an artifact from a config.</p> Source code in <code>src/chapkit/modules/config/schemas.py</code> <pre><code>class UnlinkArtifactRequest(BaseModel):\n    \"\"\"Request schema for unlinking an artifact from a config.\"\"\"\n\n    artifact_id: ULID\n</code></pre>"},{"location":"api-reference/#artifact-module","title":"Artifact Module","text":"<p>Hierarchical artifact tree storage.</p>"},{"location":"api-reference/#chapkit.modules.artifact","title":"<code>artifact</code>","text":"<p>Artifact feature - hierarchical data storage with parent-child relationships.</p>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactManager","title":"<code>ArtifactManager</code>","text":"<p>               Bases: <code>BaseManager[Artifact, ArtifactIn, ArtifactOut, ULID]</code></p> <p>Manager for Artifact entities with hierarchical tree operations.</p> Source code in <code>src/chapkit/modules/artifact/manager.py</code> <pre><code>class ArtifactManager(BaseManager[Artifact, ArtifactIn, ArtifactOut, ULID]):\n    \"\"\"Manager for Artifact entities with hierarchical tree operations.\"\"\"\n\n    def __init__(\n        self,\n        repo: ArtifactRepository,\n        hierarchy: ArtifactHierarchy | None = None,\n        config_repo: ConfigRepository | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize artifact manager with repository, hierarchy, and optional config repo.\"\"\"\n        super().__init__(repo, Artifact, ArtifactOut)\n        self.repo: ArtifactRepository = repo\n        self.hierarchy = hierarchy\n        self.config_repo = config_repo\n\n    # Public API ------------------------------------------------------\n\n    async def find_subtree(self, start_id: ULID) -&gt; list[ArtifactTreeNode]:\n        \"\"\"Find all artifacts in the subtree rooted at the given ID.\"\"\"\n        artifacts = await self.repo.find_subtree(start_id)\n        return [self._to_tree_node(artifact) for artifact in artifacts]\n\n    async def expand_artifact(self, artifact_id: ULID) -&gt; ArtifactTreeNode | None:\n        \"\"\"Expand a single artifact with hierarchy metadata but without children.\"\"\"\n        artifact = await self.repo.find_by_id(artifact_id)\n        if artifact is None:\n            return None\n\n        node = self._to_tree_node(artifact)\n        node.children = None\n\n        # Populate config if available and artifact is a root\n        if self.config_repo is not None:\n            config = await self.config_repo.find_by_root_artifact_id(artifact_id)\n            if config is not None:\n                # Use model_construct to bypass validation since we don't know the concrete data type\n                node.config = ConfigOut[BaseConfig].model_construct(\n                    id=config.id,\n                    created_at=config.created_at,\n                    updated_at=config.updated_at,\n                    name=config.name,\n                    data=config.data,\n                )\n\n        return node\n\n    async def build_tree(self, start_id: ULID) -&gt; ArtifactTreeNode | None:\n        \"\"\"Build a hierarchical tree structure rooted at the given artifact ID.\"\"\"\n        artifacts = await self.find_subtree(start_id)\n        if not artifacts:\n            return None\n\n        node_map: dict[ULID, ArtifactTreeNode] = {}\n        for node in artifacts:\n            node.children = []\n            node_map[node.id] = node\n\n        for node in artifacts:\n            if node.parent_id is None:\n                continue\n            parent = node_map.get(node.parent_id)\n            if parent is None:\n                continue\n            if parent.children is None:\n                parent.children = []\n            parent.children.append(node)\n\n        # Keep children as [] for leaf nodes (semantic: \"loaded but empty\")\n        # Only expand_artifact sets children=None (semantic: \"not loaded\")\n\n        root = node_map.get(start_id)\n\n        # Populate config for root node only\n        if root is not None and self.config_repo is not None:\n            config = await self.config_repo.find_by_root_artifact_id(start_id)\n            if config is not None:\n                # Use model_construct to bypass validation since we don't know the concrete data type\n                root.config = ConfigOut[BaseConfig].model_construct(\n                    id=config.id,\n                    created_at=config.created_at,\n                    updated_at=config.updated_at,\n                    name=config.name,\n                    data=config.data,\n                )\n\n        return root\n\n    # Lifecycle overrides --------------------------------------------\n\n    def _should_assign_field(self, field: str, value: object) -&gt; bool:\n        \"\"\"Prevent assigning None to level field during updates.\"\"\"\n        if field == \"level\" and value is None:\n            return False\n        return super()._should_assign_field(field, value)\n\n    async def pre_save(self, entity: Artifact, data: ArtifactIn) -&gt; None:\n        \"\"\"Compute and set artifact level before saving.\"\"\"\n        entity.level = await self._compute_level(entity.parent_id)\n\n    async def pre_update(self, entity: Artifact, data: ArtifactIn, old_values: dict[str, object]) -&gt; None:\n        \"\"\"Recalculate artifact level and cascade updates to descendants if parent changed.\"\"\"\n        previous_level = old_values.get(\"level\", entity.level)\n        entity.level = await self._compute_level(entity.parent_id)\n        parent_changed = old_values.get(\"parent_id\") != entity.parent_id\n        if parent_changed or previous_level != entity.level:\n            await self._recalculate_descendants(entity)\n\n    # Helper utilities ------------------------------------------------\n\n    async def _compute_level(self, parent_id: ULID | None) -&gt; int:\n        \"\"\"Compute the level of an artifact based on its parent.\"\"\"\n        if parent_id is None:\n            return 0\n        parent = await self.repo.find_by_id(parent_id)\n        if parent is None:\n            return 0  # pragma: no cover\n        return parent.level + 1\n\n    async def _recalculate_descendants(self, entity: Artifact) -&gt; None:\n        \"\"\"Recalculate levels for all descendants of an artifact.\"\"\"\n        subtree = await self.repo.find_subtree(entity.id)\n        by_parent: dict[ULID | None, list[Artifact]] = {}\n        for node in subtree:\n            by_parent.setdefault(node.parent_id, []).append(node)\n\n        queue: deque[Artifact] = deque([entity])\n        while queue:\n            current = queue.popleft()\n            for child in by_parent.get(current.id, []):\n                child.level = current.level + 1\n                queue.append(child)\n\n    def _to_tree_node(self, entity: Artifact) -&gt; ArtifactTreeNode:\n        \"\"\"Convert artifact entity to tree node with hierarchy metadata.\"\"\"\n        base = super()._to_output_schema(entity)\n        node = ArtifactTreeNode.from_artifact(base)\n        if self.hierarchy is not None:\n            meta = self.hierarchy.describe(node.level)\n            hierarchy_value = meta.get(self.hierarchy.hierarchy_key)\n            if hierarchy_value is not None:\n                node.hierarchy = str(hierarchy_value)\n            label_value = meta.get(self.hierarchy.label_key)\n            if label_value is not None:\n                node.level_label = str(label_value)\n\n        return node\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactManager.__init__","title":"<code>__init__(repo, hierarchy=None, config_repo=None)</code>","text":"<p>Initialize artifact manager with repository, hierarchy, and optional config repo.</p> Source code in <code>src/chapkit/modules/artifact/manager.py</code> <pre><code>def __init__(\n    self,\n    repo: ArtifactRepository,\n    hierarchy: ArtifactHierarchy | None = None,\n    config_repo: ConfigRepository | None = None,\n) -&gt; None:\n    \"\"\"Initialize artifact manager with repository, hierarchy, and optional config repo.\"\"\"\n    super().__init__(repo, Artifact, ArtifactOut)\n    self.repo: ArtifactRepository = repo\n    self.hierarchy = hierarchy\n    self.config_repo = config_repo\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactManager.find_subtree","title":"<code>find_subtree(start_id)</code>  <code>async</code>","text":"<p>Find all artifacts in the subtree rooted at the given ID.</p> Source code in <code>src/chapkit/modules/artifact/manager.py</code> <pre><code>async def find_subtree(self, start_id: ULID) -&gt; list[ArtifactTreeNode]:\n    \"\"\"Find all artifacts in the subtree rooted at the given ID.\"\"\"\n    artifacts = await self.repo.find_subtree(start_id)\n    return [self._to_tree_node(artifact) for artifact in artifacts]\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactManager.expand_artifact","title":"<code>expand_artifact(artifact_id)</code>  <code>async</code>","text":"<p>Expand a single artifact with hierarchy metadata but without children.</p> Source code in <code>src/chapkit/modules/artifact/manager.py</code> <pre><code>async def expand_artifact(self, artifact_id: ULID) -&gt; ArtifactTreeNode | None:\n    \"\"\"Expand a single artifact with hierarchy metadata but without children.\"\"\"\n    artifact = await self.repo.find_by_id(artifact_id)\n    if artifact is None:\n        return None\n\n    node = self._to_tree_node(artifact)\n    node.children = None\n\n    # Populate config if available and artifact is a root\n    if self.config_repo is not None:\n        config = await self.config_repo.find_by_root_artifact_id(artifact_id)\n        if config is not None:\n            # Use model_construct to bypass validation since we don't know the concrete data type\n            node.config = ConfigOut[BaseConfig].model_construct(\n                id=config.id,\n                created_at=config.created_at,\n                updated_at=config.updated_at,\n                name=config.name,\n                data=config.data,\n            )\n\n    return node\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactManager.build_tree","title":"<code>build_tree(start_id)</code>  <code>async</code>","text":"<p>Build a hierarchical tree structure rooted at the given artifact ID.</p> Source code in <code>src/chapkit/modules/artifact/manager.py</code> <pre><code>async def build_tree(self, start_id: ULID) -&gt; ArtifactTreeNode | None:\n    \"\"\"Build a hierarchical tree structure rooted at the given artifact ID.\"\"\"\n    artifacts = await self.find_subtree(start_id)\n    if not artifacts:\n        return None\n\n    node_map: dict[ULID, ArtifactTreeNode] = {}\n    for node in artifacts:\n        node.children = []\n        node_map[node.id] = node\n\n    for node in artifacts:\n        if node.parent_id is None:\n            continue\n        parent = node_map.get(node.parent_id)\n        if parent is None:\n            continue\n        if parent.children is None:\n            parent.children = []\n        parent.children.append(node)\n\n    # Keep children as [] for leaf nodes (semantic: \"loaded but empty\")\n    # Only expand_artifact sets children=None (semantic: \"not loaded\")\n\n    root = node_map.get(start_id)\n\n    # Populate config for root node only\n    if root is not None and self.config_repo is not None:\n        config = await self.config_repo.find_by_root_artifact_id(start_id)\n        if config is not None:\n            # Use model_construct to bypass validation since we don't know the concrete data type\n            root.config = ConfigOut[BaseConfig].model_construct(\n                id=config.id,\n                created_at=config.created_at,\n                updated_at=config.updated_at,\n                name=config.name,\n                data=config.data,\n            )\n\n    return root\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactManager.pre_save","title":"<code>pre_save(entity, data)</code>  <code>async</code>","text":"<p>Compute and set artifact level before saving.</p> Source code in <code>src/chapkit/modules/artifact/manager.py</code> <pre><code>async def pre_save(self, entity: Artifact, data: ArtifactIn) -&gt; None:\n    \"\"\"Compute and set artifact level before saving.\"\"\"\n    entity.level = await self._compute_level(entity.parent_id)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactManager.pre_update","title":"<code>pre_update(entity, data, old_values)</code>  <code>async</code>","text":"<p>Recalculate artifact level and cascade updates to descendants if parent changed.</p> Source code in <code>src/chapkit/modules/artifact/manager.py</code> <pre><code>async def pre_update(self, entity: Artifact, data: ArtifactIn, old_values: dict[str, object]) -&gt; None:\n    \"\"\"Recalculate artifact level and cascade updates to descendants if parent changed.\"\"\"\n    previous_level = old_values.get(\"level\", entity.level)\n    entity.level = await self._compute_level(entity.parent_id)\n    parent_changed = old_values.get(\"parent_id\") != entity.parent_id\n    if parent_changed or previous_level != entity.level:\n        await self._recalculate_descendants(entity)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.Artifact","title":"<code>Artifact</code>","text":"<p>               Bases: <code>Entity</code></p> <p>ORM model for hierarchical artifacts with parent-child relationships.</p> Source code in <code>src/chapkit/modules/artifact/models.py</code> <pre><code>class Artifact(Entity):\n    \"\"\"ORM model for hierarchical artifacts with parent-child relationships.\"\"\"\n\n    __tablename__ = \"artifacts\"\n\n    parent_id: Mapped[ULID | None] = mapped_column(\n        ULIDType,\n        ForeignKey(\"artifacts.id\", ondelete=\"SET NULL\"),\n        nullable=True,\n        index=True,\n    )\n\n    parent: Mapped[Artifact | None] = relationship(\n        remote_side=\"Artifact.id\",\n        back_populates=\"children\",\n    )\n\n    children: Mapped[list[Artifact]] = relationship(\n        back_populates=\"parent\",\n    )\n\n    data: Mapped[Any] = mapped_column(PickleType(protocol=4), nullable=False)\n    level: Mapped[int] = mapped_column(default=0, nullable=False, index=True)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactRepository","title":"<code>ArtifactRepository</code>","text":"<p>               Bases: <code>BaseRepository[Artifact, ULID]</code></p> <p>Repository for Artifact entities with tree traversal operations.</p> Source code in <code>src/chapkit/modules/artifact/repository.py</code> <pre><code>class ArtifactRepository(BaseRepository[Artifact, ULID]):\n    \"\"\"Repository for Artifact entities with tree traversal operations.\"\"\"\n\n    def __init__(self, session: AsyncSession) -&gt; None:\n        \"\"\"Initialize artifact repository with database session.\"\"\"\n        super().__init__(session, Artifact)\n\n    async def find_by_id(self, id: ULID) -&gt; Artifact | None:\n        \"\"\"Find an artifact by ID with children eagerly loaded.\"\"\"\n        return await self.s.get(self.model, id, options=[selectinload(self.model.children)])\n\n    async def find_subtree(self, start_id: ULID) -&gt; Iterable[Artifact]:\n        \"\"\"Find all artifacts in the subtree rooted at the given ID using recursive CTE.\"\"\"\n        cte = select(self.model.id).where(self.model.id == start_id).cte(name=\"descendants\", recursive=True)\n        cte = cte.union_all(select(self.model.id).where(self.model.parent_id == cte.c.id))\n\n        subtree_ids = (await self.s.scalars(select(cte.c.id))).all()\n        rows = (await self.s.scalars(select(self.model).where(self.model.id.in_(subtree_ids)))).all()\n        return rows\n\n    async def get_root_artifact(self, artifact_id: ULID) -&gt; Artifact | None:\n        \"\"\"Find the root artifact by traversing up the parent chain.\"\"\"\n        artifact = await self.s.get(self.model, artifact_id)\n        if artifact is None:\n            return None\n\n        while artifact.parent_id is not None:\n            parent = await self.s.get(self.model, artifact.parent_id)\n            if parent is None:\n                break\n            artifact = parent\n\n        return artifact\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactRepository.__init__","title":"<code>__init__(session)</code>","text":"<p>Initialize artifact repository with database session.</p> Source code in <code>src/chapkit/modules/artifact/repository.py</code> <pre><code>def __init__(self, session: AsyncSession) -&gt; None:\n    \"\"\"Initialize artifact repository with database session.\"\"\"\n    super().__init__(session, Artifact)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactRepository.find_by_id","title":"<code>find_by_id(id)</code>  <code>async</code>","text":"<p>Find an artifact by ID with children eagerly loaded.</p> Source code in <code>src/chapkit/modules/artifact/repository.py</code> <pre><code>async def find_by_id(self, id: ULID) -&gt; Artifact | None:\n    \"\"\"Find an artifact by ID with children eagerly loaded.\"\"\"\n    return await self.s.get(self.model, id, options=[selectinload(self.model.children)])\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactRepository.find_subtree","title":"<code>find_subtree(start_id)</code>  <code>async</code>","text":"<p>Find all artifacts in the subtree rooted at the given ID using recursive CTE.</p> Source code in <code>src/chapkit/modules/artifact/repository.py</code> <pre><code>async def find_subtree(self, start_id: ULID) -&gt; Iterable[Artifact]:\n    \"\"\"Find all artifacts in the subtree rooted at the given ID using recursive CTE.\"\"\"\n    cte = select(self.model.id).where(self.model.id == start_id).cte(name=\"descendants\", recursive=True)\n    cte = cte.union_all(select(self.model.id).where(self.model.parent_id == cte.c.id))\n\n    subtree_ids = (await self.s.scalars(select(cte.c.id))).all()\n    rows = (await self.s.scalars(select(self.model).where(self.model.id.in_(subtree_ids)))).all()\n    return rows\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactRepository.get_root_artifact","title":"<code>get_root_artifact(artifact_id)</code>  <code>async</code>","text":"<p>Find the root artifact by traversing up the parent chain.</p> Source code in <code>src/chapkit/modules/artifact/repository.py</code> <pre><code>async def get_root_artifact(self, artifact_id: ULID) -&gt; Artifact | None:\n    \"\"\"Find the root artifact by traversing up the parent chain.\"\"\"\n    artifact = await self.s.get(self.model, artifact_id)\n    if artifact is None:\n        return None\n\n    while artifact.parent_id is not None:\n        parent = await self.s.get(self.model, artifact.parent_id)\n        if parent is None:\n            break\n        artifact = parent\n\n    return artifact\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactRouter","title":"<code>ArtifactRouter</code>","text":"<p>               Bases: <code>CrudRouter[ArtifactIn, ArtifactOut]</code></p> <p>CRUD router for Artifact entities with tree operations and config access.</p> Source code in <code>src/chapkit/modules/artifact/router.py</code> <pre><code>class ArtifactRouter(CrudRouter[ArtifactIn, ArtifactOut]):\n    \"\"\"CRUD router for Artifact entities with tree operations and config access.\"\"\"\n\n    def __init__(\n        self,\n        prefix: str,\n        tags: Sequence[str],\n        manager_factory: Any,\n        entity_in_type: type[ArtifactIn],\n        entity_out_type: type[ArtifactOut],\n        permissions: CrudPermissions | None = None,\n        enable_config_access: bool = False,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Initialize artifact router with entity types and manager factory.\"\"\"\n        self.enable_config_access = enable_config_access\n        super().__init__(\n            prefix=prefix,\n            tags=list(tags),\n            entity_in_type=entity_in_type,\n            entity_out_type=entity_out_type,\n            manager_factory=manager_factory,\n            permissions=permissions,\n            **kwargs,\n        )\n\n    def _register_routes(self) -&gt; None:\n        \"\"\"Register artifact CRUD routes and tree operations.\"\"\"\n        super()._register_routes()\n\n        manager_factory = self.manager_factory\n\n        async def expand_artifact(\n            entity_id: str,\n            manager: ArtifactManager = Depends(manager_factory),\n        ) -&gt; ArtifactTreeNode:\n            ulid_id = self._parse_ulid(entity_id)\n\n            expanded = await manager.expand_artifact(ulid_id)\n            if expanded is None:\n                raise HTTPException(\n                    status_code=status.HTTP_404_NOT_FOUND,\n                    detail=f\"Artifact with id {entity_id} not found\",\n                )\n            return expanded\n\n        async def build_tree(\n            entity_id: str,\n            manager: ArtifactManager = Depends(manager_factory),\n        ) -&gt; ArtifactTreeNode:\n            ulid_id = self._parse_ulid(entity_id)\n\n            tree = await manager.build_tree(ulid_id)\n            if tree is None:\n                raise HTTPException(\n                    status_code=status.HTTP_404_NOT_FOUND,\n                    detail=f\"Artifact with id {entity_id} not found\",\n                )\n            return tree\n\n        self.register_entity_operation(\n            \"expand\",\n            expand_artifact,\n            response_model=ArtifactTreeNode,\n            summary=\"Expand artifact\",\n            description=\"Get artifact with hierarchy metadata but without children\",\n        )\n\n        self.register_entity_operation(\n            \"tree\",\n            build_tree,\n            response_model=ArtifactTreeNode,\n            summary=\"Build artifact tree\",\n            description=\"Build hierarchical tree structure rooted at the given artifact\",\n        )\n\n        if self.enable_config_access:\n            # Import locally to avoid circular dependency\n            from chapkit.api.dependencies import get_config_manager\n\n            async def get_config(\n                entity_id: str,\n                artifact_manager: ArtifactManager = Depends(manager_factory),\n                config_manager: ConfigManager[BaseConfig] = Depends(get_config_manager),\n            ) -&gt; ConfigOut[BaseConfig] | None:\n                artifact_id = self._parse_ulid(entity_id)\n                config = await config_manager.get_config_for_artifact(artifact_id, artifact_manager.repo)\n                return config\n\n            self.register_entity_operation(\n                \"config\",\n                get_config,\n                http_method=\"GET\",\n                response_model=ConfigOut[BaseConfig],\n                summary=\"Get artifact config\",\n                description=\"Get the config for an artifact by walking up the tree to find the root's config\",\n            )\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactRouter.__init__","title":"<code>__init__(prefix, tags, manager_factory, entity_in_type, entity_out_type, permissions=None, enable_config_access=False, **kwargs)</code>","text":"<p>Initialize artifact router with entity types and manager factory.</p> Source code in <code>src/chapkit/modules/artifact/router.py</code> <pre><code>def __init__(\n    self,\n    prefix: str,\n    tags: Sequence[str],\n    manager_factory: Any,\n    entity_in_type: type[ArtifactIn],\n    entity_out_type: type[ArtifactOut],\n    permissions: CrudPermissions | None = None,\n    enable_config_access: bool = False,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize artifact router with entity types and manager factory.\"\"\"\n    self.enable_config_access = enable_config_access\n    super().__init__(\n        prefix=prefix,\n        tags=list(tags),\n        entity_in_type=entity_in_type,\n        entity_out_type=entity_out_type,\n        manager_factory=manager_factory,\n        permissions=permissions,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactHierarchy","title":"<code>ArtifactHierarchy</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for artifact hierarchy with level labels.</p> Source code in <code>src/chapkit/modules/artifact/schemas.py</code> <pre><code>class ArtifactHierarchy(BaseModel):\n    \"\"\"Configuration for artifact hierarchy with level labels.\"\"\"\n\n    name: str = Field(..., description=\"Human readable name of this hierarchy\")\n    level_labels: Mapping[int, str] = Field(\n        default_factory=dict,\n        description=\"Mapping of numeric levels to labels (0 -&gt; 'train', etc.)\",\n    )\n\n    model_config = {\"frozen\": True}\n\n    hierarchy_key: ClassVar[str] = \"hierarchy\"\n    depth_key: ClassVar[str] = \"level_depth\"\n    label_key: ClassVar[str] = \"level_label\"\n\n    def label_for(self, level: int) -&gt; str:\n        \"\"\"Get the label for a given level or return default.\"\"\"\n        return self.level_labels.get(level, f\"level_{level}\")\n\n    def describe(self, level: int) -&gt; dict[str, Any]:\n        \"\"\"Get hierarchy metadata dict for a given level.\"\"\"\n        return {\n            self.hierarchy_key: self.name,\n            self.depth_key: level,\n            self.label_key: self.label_for(level),\n        }\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactHierarchy.label_for","title":"<code>label_for(level)</code>","text":"<p>Get the label for a given level or return default.</p> Source code in <code>src/chapkit/modules/artifact/schemas.py</code> <pre><code>def label_for(self, level: int) -&gt; str:\n    \"\"\"Get the label for a given level or return default.\"\"\"\n    return self.level_labels.get(level, f\"level_{level}\")\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactHierarchy.describe","title":"<code>describe(level)</code>","text":"<p>Get hierarchy metadata dict for a given level.</p> Source code in <code>src/chapkit/modules/artifact/schemas.py</code> <pre><code>def describe(self, level: int) -&gt; dict[str, Any]:\n    \"\"\"Get hierarchy metadata dict for a given level.\"\"\"\n    return {\n        self.hierarchy_key: self.name,\n        self.depth_key: level,\n        self.label_key: self.label_for(level),\n    }\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactIn","title":"<code>ArtifactIn</code>","text":"<p>               Bases: <code>EntityIn</code></p> <p>Input schema for creating or updating artifacts.</p> Source code in <code>src/chapkit/modules/artifact/schemas.py</code> <pre><code>class ArtifactIn(EntityIn):\n    \"\"\"Input schema for creating or updating artifacts.\"\"\"\n\n    data: Any\n    parent_id: ULID | None = None\n    level: int | None = None\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactOut","title":"<code>ArtifactOut</code>","text":"<p>               Bases: <code>EntityOut</code></p> <p>Output schema for artifact entities.</p> Source code in <code>src/chapkit/modules/artifact/schemas.py</code> <pre><code>class ArtifactOut(EntityOut):\n    \"\"\"Output schema for artifact entities.\"\"\"\n\n    data: JsonSafe\n    parent_id: ULID | None = None\n    level: int\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactTreeNode","title":"<code>ArtifactTreeNode</code>","text":"<p>               Bases: <code>ArtifactOut</code></p> <p>Artifact node with tree structure metadata and optional config.</p> Source code in <code>src/chapkit/modules/artifact/schemas.py</code> <pre><code>class ArtifactTreeNode(ArtifactOut):\n    \"\"\"Artifact node with tree structure metadata and optional config.\"\"\"\n\n    level_label: str | None = None\n    hierarchy: str | None = None\n    children: list[\"ArtifactTreeNode\"] | None = None\n    config: \"ConfigOut[BaseConfig] | None\" = None\n\n    @classmethod\n    def from_artifact(cls, artifact: ArtifactOut) -&gt; Self:\n        \"\"\"Create a tree node from an artifact output schema.\"\"\"\n        return cls.model_validate(artifact.model_dump())\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.ArtifactTreeNode.from_artifact","title":"<code>from_artifact(artifact)</code>  <code>classmethod</code>","text":"<p>Create a tree node from an artifact output schema.</p> Source code in <code>src/chapkit/modules/artifact/schemas.py</code> <pre><code>@classmethod\ndef from_artifact(cls, artifact: ArtifactOut) -&gt; Self:\n    \"\"\"Create a tree node from an artifact output schema.\"\"\"\n    return cls.model_validate(artifact.model_dump())\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.PandasDataFrame","title":"<code>PandasDataFrame</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Pydantic schema for serializing pandas DataFrames.</p> Source code in <code>src/chapkit/modules/artifact/schemas.py</code> <pre><code>class PandasDataFrame(BaseModel):\n    \"\"\"Pydantic schema for serializing pandas DataFrames.\"\"\"\n\n    columns: list[str]\n    data: list[list[Any]]\n\n    @classmethod\n    def from_dataframe(cls, df: pd.DataFrame) -&gt; Self:\n        \"\"\"Create schema from pandas DataFrame.\"\"\"\n        if not isinstance(df, pd.DataFrame):  # pyright: ignore[reportUnnecessaryIsInstance]\n            raise TypeError(f\"Expected a pandas DataFrame, but got {type(df)}\")\n        return cls(columns=df.columns.tolist(), data=df.values.tolist())\n\n    def to_dataframe(self) -&gt; pd.DataFrame:\n        \"\"\"Convert schema back to pandas DataFrame.\"\"\"\n        return pd.DataFrame(self.data, columns=self.columns)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.PandasDataFrame.from_dataframe","title":"<code>from_dataframe(df)</code>  <code>classmethod</code>","text":"<p>Create schema from pandas DataFrame.</p> Source code in <code>src/chapkit/modules/artifact/schemas.py</code> <pre><code>@classmethod\ndef from_dataframe(cls, df: pd.DataFrame) -&gt; Self:\n    \"\"\"Create schema from pandas DataFrame.\"\"\"\n    if not isinstance(df, pd.DataFrame):  # pyright: ignore[reportUnnecessaryIsInstance]\n        raise TypeError(f\"Expected a pandas DataFrame, but got {type(df)}\")\n    return cls(columns=df.columns.tolist(), data=df.values.tolist())\n</code></pre>"},{"location":"api-reference/#chapkit.modules.artifact.PandasDataFrame.to_dataframe","title":"<code>to_dataframe()</code>","text":"<p>Convert schema back to pandas DataFrame.</p> Source code in <code>src/chapkit/modules/artifact/schemas.py</code> <pre><code>def to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert schema back to pandas DataFrame.\"\"\"\n    return pd.DataFrame(self.data, columns=self.columns)\n</code></pre>"},{"location":"api-reference/#task-module","title":"Task Module","text":"<p>Script execution template system.</p>"},{"location":"api-reference/#chapkit.modules.task","title":"<code>task</code>","text":"<p>Task feature - reusable command templates for task execution.</p>"},{"location":"api-reference/#chapkit.modules.task.TaskManager","title":"<code>TaskManager</code>","text":"<p>               Bases: <code>BaseManager[Task, TaskIn, TaskOut, ULID]</code></p> <p>Manager for Task template entities with artifact-based execution.</p> Source code in <code>src/chapkit/modules/task/manager.py</code> <pre><code>class TaskManager(BaseManager[Task, TaskIn, TaskOut, ULID]):\n    \"\"\"Manager for Task template entities with artifact-based execution.\"\"\"\n\n    def __init__(\n        self,\n        repo: TaskRepository,\n        scheduler: JobScheduler | None = None,\n        database: Database | None = None,\n        artifact_manager: ArtifactManager | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize task manager with repository, scheduler, database, and artifact manager.\"\"\"\n        super().__init__(repo, Task, TaskOut)\n        self.repo: TaskRepository = repo\n        self.scheduler = scheduler\n        self.database = database\n        self.artifact_manager = artifact_manager\n\n    async def find_all(self, *, enabled: bool | None = None) -&gt; list[TaskOut]:\n        \"\"\"Find all tasks, optionally filtered by enabled status.\"\"\"\n        tasks = await self.repo.find_all(enabled=enabled)\n        return [self._to_output_schema(task) for task in tasks]\n\n    def _is_injectable_type(self, param_type: type | None) -&gt; bool:\n        \"\"\"Check if a parameter type should be injected by the framework.\"\"\"\n        if param_type is None:\n            return False\n\n        # Handle Optional[Type] -&gt; extract the non-None type\n        origin = get_origin(param_type)\n        if origin is types.UnionType or origin is Union:  # Union type (both syntaxes)\n            # For Optional types, we still want to inject if the non-None type is injectable\n            # This allows Optional[AsyncSession] to work\n            args = getattr(param_type, \"__args__\", ())\n            non_none_types = [arg for arg in args if arg is not type(None)]\n            if len(non_none_types) == 1:\n                param_type = non_none_types[0]\n\n        # Check if type is in injectable set\n        return param_type in INJECTABLE_TYPES\n\n    def _build_injection_map(self, task_id: ULID, session: AsyncSession | None) -&gt; dict[type, Any]:\n        \"\"\"Build map of injectable types to their instances.\"\"\"\n        return {\n            AsyncSession: session,\n            Database: self.database,\n            ArtifactManager: self.artifact_manager,\n            JobScheduler: self.scheduler,\n        }\n\n    def _inject_parameters(\n        self, func: Any, user_params: dict[str, Any], task_id: ULID, session: AsyncSession | None\n    ) -&gt; dict[str, Any]:\n        \"\"\"Merge user parameters with framework injections based on function signature.\"\"\"\n        sig = inspect.signature(func)\n        type_hints = get_type_hints(func)\n\n        # Build injection map\n        injection_map = self._build_injection_map(task_id, session)\n\n        # Start with user parameters\n        final_params = dict(user_params)\n\n        # Inspect each parameter in function signature\n        for param_name, param in sig.parameters.items():\n            # Skip self, *args, **kwargs\n            if param.kind in (param.VAR_POSITIONAL, param.VAR_KEYWORD):\n                continue\n\n            # Get type hint for this parameter\n            param_type = type_hints.get(param_name)\n\n            # Check if this type should be injected\n            if self._is_injectable_type(param_type):\n                # Get the actual type (handle Optional)\n                actual_type = param_type\n                origin = get_origin(param_type)\n                if origin is types.UnionType or origin is Union:\n                    args = getattr(param_type, \"__args__\", ())\n                    non_none_types = [arg for arg in args if arg is not type(None)]\n                    if non_none_types:\n                        actual_type = non_none_types[0]\n\n                # Inject if we have an instance of this type\n                if actual_type in injection_map:\n                    injectable_value = injection_map[actual_type]\n                    # For required parameters, inject even if None\n                    # For optional parameters, only inject if not None\n                    if param.default is param.empty:\n                        # Required parameter - inject whatever we have (even None)\n                        final_params[param_name] = injectable_value\n                    elif injectable_value is not None:\n                        # Optional parameter - only inject if we have a value\n                        final_params[param_name] = injectable_value\n                continue\n\n            # Not injectable - must come from user parameters\n            if param_name not in final_params:\n                # Check if parameter has a default value\n                if param.default is not param.empty:\n                    continue  # Will use default\n\n                # Required parameter missing\n                raise ValueError(\n                    f\"Missing required parameter '{param_name}' for task function. \"\n                    f\"Parameter is not injectable and not provided in task.parameters.\"\n                )\n\n        return final_params\n\n    async def execute_task(self, task_id: ULID) -&gt; ULID:\n        \"\"\"Execute a task by submitting it to the scheduler and return the job ID.\"\"\"\n        if self.scheduler is None:\n            raise ValueError(\"Task execution requires a scheduler. Use ServiceBuilder.with_jobs() to enable.\")\n\n        if self.artifact_manager is None:\n            raise ValueError(\n                \"Task execution requires artifacts. Use ServiceBuilder.with_artifacts() before with_tasks().\"\n            )\n\n        task = await self.repo.find_by_id(task_id)\n        if task is None:\n            raise ValueError(f\"Task {task_id} not found\")\n\n        # Check if task is enabled\n        if not task.enabled:\n            raise ValueError(f\"Cannot execute disabled task {task_id}\")\n\n        # Route based on task type\n        if task.task_type == \"python\":\n            job_id = await self.scheduler.add_job(self._execute_python, task_id)\n        else:  # shell\n            job_id = await self.scheduler.add_job(self._execute_command, task_id)\n\n        return job_id\n\n    async def _execute_command(self, task_id: ULID) -&gt; ULID:\n        \"\"\"Execute command and return artifact_id containing results.\"\"\"\n        if self.database is None:\n            raise RuntimeError(\"Database instance required for task execution\")\n\n        if self.artifact_manager is None:\n            raise RuntimeError(\"ArtifactManager instance required for task execution\")\n\n        # Fetch task and serialize snapshot before execution\n        async with self.database.session() as session:\n            task_repo = TaskRepository(session)\n            task = await task_repo.find_by_id(task_id)\n            if task is None:\n                raise ValueError(f\"Task {task_id} not found\")\n\n            # Capture task snapshot\n            task_snapshot = {\n                \"id\": str(task.id),\n                \"command\": task.command,\n                \"created_at\": task.created_at.isoformat(),\n                \"updated_at\": task.updated_at.isoformat(),\n            }\n\n        # Execute command using asyncio subprocess\n        process = await asyncio.create_subprocess_shell(\n            task.command,\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.PIPE,\n        )\n\n        # Wait for completion and capture output\n        stdout_bytes, stderr_bytes = await process.communicate()\n\n        # Decode outputs\n        stdout_text = stdout_bytes.decode(\"utf-8\") if stdout_bytes else \"\"\n        stderr_text = stderr_bytes.decode(\"utf-8\") if stderr_bytes else \"\"\n\n        # Create artifact with execution results\n        result_data: dict[str, Any] = {\n            \"task\": task_snapshot,\n            \"stdout\": stdout_text,\n            \"stderr\": stderr_text,\n            \"exit_code\": process.returncode,\n        }\n\n        async with self.database.session() as session:\n            artifact_repo = ArtifactRepository(session)\n            artifact_mgr = ArtifactManager(artifact_repo)\n\n            artifact_out = await artifact_mgr.save(\n                ArtifactIn(\n                    data=result_data,\n                    parent_id=None,\n                )\n            )\n\n        return artifact_out.id\n\n    async def _execute_python(self, task_id: ULID) -&gt; ULID:\n        \"\"\"Execute Python function and return artifact_id containing results.\"\"\"\n        if self.database is None:\n            raise RuntimeError(\"Database instance required for task execution\")\n\n        if self.artifact_manager is None:\n            raise RuntimeError(\"ArtifactManager instance required for task execution\")\n\n        # Create a database session for potential injection\n        session_context = self.database.session()\n        session = await session_context.__aenter__()\n\n        try:\n            # Fetch task and serialize snapshot\n            task_repo = TaskRepository(session)\n            task = await task_repo.find_by_id(task_id)\n            if task is None:\n                raise ValueError(f\"Task {task_id} not found\")\n\n            # Capture task snapshot\n            task_snapshot = {\n                \"id\": str(task.id),\n                \"command\": task.command,\n                \"task_type\": task.task_type,\n                \"parameters\": task.parameters,\n                \"created_at\": task.created_at.isoformat(),\n                \"updated_at\": task.updated_at.isoformat(),\n            }\n\n            # Get function from registry\n            try:\n                func = TaskRegistry.get(task.command)\n            except KeyError:\n                raise ValueError(f\"Python function '{task.command}' not found in registry\")\n\n            # Execute function with type-based injection\n            result_data: dict[str, Any]\n            try:\n                user_params = task.parameters or {}\n\n                # Inject framework dependencies based on function signature\n                final_params = self._inject_parameters(func, user_params, task_id, session)\n\n                # Handle sync/async functions\n                if inspect.iscoroutinefunction(func):\n                    result = await func(**final_params)\n                else:\n                    result = await asyncio.to_thread(func, **final_params)\n\n                result_data = {\n                    \"task\": task_snapshot,\n                    \"result\": result,\n                    \"error\": None,\n                }\n            except Exception as e:\n                result_data = {\n                    \"task\": task_snapshot,\n                    \"result\": None,\n                    \"error\": {\n                        \"type\": type(e).__name__,\n                        \"message\": str(e),\n                        \"traceback\": traceback.format_exc(),\n                    },\n                }\n        finally:\n            # Always close the session\n            await session_context.__aexit__(None, None, None)\n\n        # Create artifact (with a new session)\n        async with self.database.session() as artifact_session:\n            artifact_repo = ArtifactRepository(artifact_session)\n            artifact_mgr = ArtifactManager(artifact_repo)\n            artifact_out = await artifact_mgr.save(ArtifactIn(data=result_data, parent_id=None))\n\n        return artifact_out.id\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskManager.__init__","title":"<code>__init__(repo, scheduler=None, database=None, artifact_manager=None)</code>","text":"<p>Initialize task manager with repository, scheduler, database, and artifact manager.</p> Source code in <code>src/chapkit/modules/task/manager.py</code> <pre><code>def __init__(\n    self,\n    repo: TaskRepository,\n    scheduler: JobScheduler | None = None,\n    database: Database | None = None,\n    artifact_manager: ArtifactManager | None = None,\n) -&gt; None:\n    \"\"\"Initialize task manager with repository, scheduler, database, and artifact manager.\"\"\"\n    super().__init__(repo, Task, TaskOut)\n    self.repo: TaskRepository = repo\n    self.scheduler = scheduler\n    self.database = database\n    self.artifact_manager = artifact_manager\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskManager.find_all","title":"<code>find_all(*, enabled=None)</code>  <code>async</code>","text":"<p>Find all tasks, optionally filtered by enabled status.</p> Source code in <code>src/chapkit/modules/task/manager.py</code> <pre><code>async def find_all(self, *, enabled: bool | None = None) -&gt; list[TaskOut]:\n    \"\"\"Find all tasks, optionally filtered by enabled status.\"\"\"\n    tasks = await self.repo.find_all(enabled=enabled)\n    return [self._to_output_schema(task) for task in tasks]\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskManager.execute_task","title":"<code>execute_task(task_id)</code>  <code>async</code>","text":"<p>Execute a task by submitting it to the scheduler and return the job ID.</p> Source code in <code>src/chapkit/modules/task/manager.py</code> <pre><code>async def execute_task(self, task_id: ULID) -&gt; ULID:\n    \"\"\"Execute a task by submitting it to the scheduler and return the job ID.\"\"\"\n    if self.scheduler is None:\n        raise ValueError(\"Task execution requires a scheduler. Use ServiceBuilder.with_jobs() to enable.\")\n\n    if self.artifact_manager is None:\n        raise ValueError(\n            \"Task execution requires artifacts. Use ServiceBuilder.with_artifacts() before with_tasks().\"\n        )\n\n    task = await self.repo.find_by_id(task_id)\n    if task is None:\n        raise ValueError(f\"Task {task_id} not found\")\n\n    # Check if task is enabled\n    if not task.enabled:\n        raise ValueError(f\"Cannot execute disabled task {task_id}\")\n\n    # Route based on task type\n    if task.task_type == \"python\":\n        job_id = await self.scheduler.add_job(self._execute_python, task_id)\n    else:  # shell\n        job_id = await self.scheduler.add_job(self._execute_command, task_id)\n\n    return job_id\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.Task","title":"<code>Task</code>","text":"<p>               Bases: <code>Entity</code></p> <p>ORM model for reusable task templates containing commands to execute.</p> Source code in <code>src/chapkit/modules/task/models.py</code> <pre><code>class Task(Entity):\n    \"\"\"ORM model for reusable task templates containing commands to execute.\"\"\"\n\n    __tablename__ = \"tasks\"\n\n    command: Mapped[str] = mapped_column(Text, nullable=False)\n    task_type: Mapped[str] = mapped_column(Text, nullable=False, default=\"shell\", server_default=\"shell\")\n    parameters: Mapped[dict | None] = mapped_column(JSON, nullable=True)\n    enabled: Mapped[bool] = mapped_column(Boolean, nullable=False, default=True, server_default=\"1\")\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskRegistry","title":"<code>TaskRegistry</code>","text":"<p>Global registry for Python task functions.</p> Source code in <code>src/chapkit/modules/task/registry.py</code> <pre><code>class TaskRegistry:\n    \"\"\"Global registry for Python task functions.\"\"\"\n\n    _registry: dict[str, Callable[..., Any]] = {}\n\n    @classmethod\n    def register(cls, name: str) -&gt; Callable[[Callable[..., Any]], Callable[..., Any]]:\n        \"\"\"Decorator to register a task function with support for type-based dependency injection.\"\"\"\n\n        def decorator(func: Callable[..., Any]) -&gt; Callable[..., Any]:\n            if name in cls._registry:\n                raise ValueError(f\"Task '{name}' already registered\")\n            cls._registry[name] = func\n            return func\n\n        return decorator\n\n    @classmethod\n    def register_function(cls, name: str, func: Callable[..., Any]) -&gt; None:\n        \"\"\"Imperatively register a task function.\"\"\"\n        if name in cls._registry:\n            raise ValueError(f\"Task '{name}' already registered\")\n        cls._registry[name] = func\n\n    @classmethod\n    def get(cls, name: str) -&gt; Callable[..., Any]:\n        \"\"\"Retrieve a registered task function.\"\"\"\n        if name not in cls._registry:\n            raise KeyError(f\"Task '{name}' not found in registry\")\n        return cls._registry[name]\n\n    @classmethod\n    def list_all(cls) -&gt; list[str]:\n        \"\"\"List all registered task names.\"\"\"\n        return sorted(cls._registry.keys())\n\n    @classmethod\n    def clear(cls) -&gt; None:\n        \"\"\"Clear all registered tasks (useful for testing).\"\"\"\n        cls._registry.clear()\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskRegistry.register","title":"<code>register(name)</code>  <code>classmethod</code>","text":"<p>Decorator to register a task function with support for type-based dependency injection.</p> Source code in <code>src/chapkit/modules/task/registry.py</code> <pre><code>@classmethod\ndef register(cls, name: str) -&gt; Callable[[Callable[..., Any]], Callable[..., Any]]:\n    \"\"\"Decorator to register a task function with support for type-based dependency injection.\"\"\"\n\n    def decorator(func: Callable[..., Any]) -&gt; Callable[..., Any]:\n        if name in cls._registry:\n            raise ValueError(f\"Task '{name}' already registered\")\n        cls._registry[name] = func\n        return func\n\n    return decorator\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskRegistry.register_function","title":"<code>register_function(name, func)</code>  <code>classmethod</code>","text":"<p>Imperatively register a task function.</p> Source code in <code>src/chapkit/modules/task/registry.py</code> <pre><code>@classmethod\ndef register_function(cls, name: str, func: Callable[..., Any]) -&gt; None:\n    \"\"\"Imperatively register a task function.\"\"\"\n    if name in cls._registry:\n        raise ValueError(f\"Task '{name}' already registered\")\n    cls._registry[name] = func\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskRegistry.get","title":"<code>get(name)</code>  <code>classmethod</code>","text":"<p>Retrieve a registered task function.</p> Source code in <code>src/chapkit/modules/task/registry.py</code> <pre><code>@classmethod\ndef get(cls, name: str) -&gt; Callable[..., Any]:\n    \"\"\"Retrieve a registered task function.\"\"\"\n    if name not in cls._registry:\n        raise KeyError(f\"Task '{name}' not found in registry\")\n    return cls._registry[name]\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskRegistry.list_all","title":"<code>list_all()</code>  <code>classmethod</code>","text":"<p>List all registered task names.</p> Source code in <code>src/chapkit/modules/task/registry.py</code> <pre><code>@classmethod\ndef list_all(cls) -&gt; list[str]:\n    \"\"\"List all registered task names.\"\"\"\n    return sorted(cls._registry.keys())\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskRegistry.clear","title":"<code>clear()</code>  <code>classmethod</code>","text":"<p>Clear all registered tasks (useful for testing).</p> Source code in <code>src/chapkit/modules/task/registry.py</code> <pre><code>@classmethod\ndef clear(cls) -&gt; None:\n    \"\"\"Clear all registered tasks (useful for testing).\"\"\"\n    cls._registry.clear()\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskRepository","title":"<code>TaskRepository</code>","text":"<p>               Bases: <code>BaseRepository[Task, ULID]</code></p> <p>Repository for Task template entities.</p> Source code in <code>src/chapkit/modules/task/repository.py</code> <pre><code>class TaskRepository(BaseRepository[Task, ULID]):\n    \"\"\"Repository for Task template entities.\"\"\"\n\n    def __init__(self, session: AsyncSession) -&gt; None:\n        \"\"\"Initialize task repository with database session.\"\"\"\n        super().__init__(session, Task)\n\n    async def find_by_enabled(self, enabled: bool) -&gt; list[Task]:\n        \"\"\"Find all tasks by enabled status.\"\"\"\n        stmt = select(Task).where(Task.enabled == enabled).order_by(Task.created_at.desc())\n        result = await self.s.execute(stmt)\n        return list(result.scalars().all())\n\n    async def find_all(self, *, enabled: bool | None = None) -&gt; list[Task]:\n        \"\"\"Find all tasks, optionally filtered by enabled status.\"\"\"\n        if enabled is None:\n            result = await super().find_all()\n            return list(result)\n        return await self.find_by_enabled(enabled)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskRepository.__init__","title":"<code>__init__(session)</code>","text":"<p>Initialize task repository with database session.</p> Source code in <code>src/chapkit/modules/task/repository.py</code> <pre><code>def __init__(self, session: AsyncSession) -&gt; None:\n    \"\"\"Initialize task repository with database session.\"\"\"\n    super().__init__(session, Task)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskRepository.find_by_enabled","title":"<code>find_by_enabled(enabled)</code>  <code>async</code>","text":"<p>Find all tasks by enabled status.</p> Source code in <code>src/chapkit/modules/task/repository.py</code> <pre><code>async def find_by_enabled(self, enabled: bool) -&gt; list[Task]:\n    \"\"\"Find all tasks by enabled status.\"\"\"\n    stmt = select(Task).where(Task.enabled == enabled).order_by(Task.created_at.desc())\n    result = await self.s.execute(stmt)\n    return list(result.scalars().all())\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskRepository.find_all","title":"<code>find_all(*, enabled=None)</code>  <code>async</code>","text":"<p>Find all tasks, optionally filtered by enabled status.</p> Source code in <code>src/chapkit/modules/task/repository.py</code> <pre><code>async def find_all(self, *, enabled: bool | None = None) -&gt; list[Task]:\n    \"\"\"Find all tasks, optionally filtered by enabled status.\"\"\"\n    if enabled is None:\n        result = await super().find_all()\n        return list(result)\n    return await self.find_by_enabled(enabled)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskRouter","title":"<code>TaskRouter</code>","text":"<p>               Bases: <code>CrudRouter[TaskIn, TaskOut]</code></p> <p>CRUD router for Task entities with execution operation.</p> Source code in <code>src/chapkit/modules/task/router.py</code> <pre><code>class TaskRouter(CrudRouter[TaskIn, TaskOut]):\n    \"\"\"CRUD router for Task entities with execution operation.\"\"\"\n\n    def __init__(\n        self,\n        prefix: str,\n        tags: Sequence[str],\n        manager_factory: Any,\n        entity_in_type: type[TaskIn],\n        entity_out_type: type[TaskOut],\n        permissions: CrudPermissions | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Initialize task router with entity types and manager factory.\"\"\"\n        super().__init__(\n            prefix=prefix,\n            tags=list(tags),\n            entity_in_type=entity_in_type,\n            entity_out_type=entity_out_type,\n            manager_factory=manager_factory,\n            permissions=permissions,\n            **kwargs,\n        )\n\n    def _register_find_all_route(self, manager_dependency: Any, manager_annotation: Any) -&gt; None:\n        \"\"\"Register find all route with enabled filtering support.\"\"\"\n        entity_out_annotation: Any = self.entity_out_type\n        collection_response_model: Any = list[entity_out_annotation] | PaginatedResponse[entity_out_annotation]\n\n        @self.router.get(\"\", response_model=collection_response_model)\n        async def find_all(\n            page: int | None = None,\n            size: int | None = None,\n            enabled: bool | None = Query(None, description=\"Filter by enabled status\"),\n            manager: Manager[TaskIn, TaskOut, ULID] = manager_dependency,\n        ) -&gt; list[TaskOut] | PaginatedResponse[TaskOut]:\n            from chapkit.core.api.pagination import create_paginated_response\n\n            # Pagination is opt-in: both page and size must be provided\n            if page is not None and size is not None:\n                items, total = await manager.find_paginated(page, size)\n                return create_paginated_response(items, total, page, size)\n\n            # Use TaskRepository's find_all with enabled filtering\n            # Cast manager to access repository with enabled parameter\n            task_manager = manager  # TaskManager with TaskRepository\n            return await task_manager.find_all(enabled=enabled)  # type: ignore[call-arg]\n\n        self._annotate_manager(find_all, manager_annotation)\n        find_all.__annotations__[\"return\"] = list[entity_out_annotation] | PaginatedResponse[entity_out_annotation]\n\n    def _register_routes(self) -&gt; None:\n        \"\"\"Register task CRUD routes and execution operation.\"\"\"\n        super()._register_routes()\n\n        manager_factory = self.manager_factory\n\n        async def execute_task(\n            entity_id: str,\n            manager: TaskManager = Depends(manager_factory),\n        ) -&gt; TaskExecuteResponse:\n            \"\"\"Execute a task asynchronously via the job scheduler.\"\"\"\n            task_id = self._parse_ulid(entity_id)\n\n            try:\n                job_id = await manager.execute_task(task_id)\n                return TaskExecuteResponse(\n                    job_id=str(job_id),\n                    message=f\"Task submitted for execution. Job ID: {job_id}\",\n                )\n            except ValueError as e:\n                raise HTTPException(\n                    status_code=status.HTTP_400_BAD_REQUEST,\n                    detail=str(e),\n                )\n            except RuntimeError as e:\n                raise HTTPException(\n                    status_code=status.HTTP_409_CONFLICT,\n                    detail=str(e),\n                )\n\n        self.register_entity_operation(\n            \"execute\",\n            execute_task,\n            http_method=\"POST\",\n            response_model=TaskExecuteResponse,\n            status_code=status.HTTP_202_ACCEPTED,\n            summary=\"Execute task\",\n            description=\"Submit the task to the scheduler for execution\",\n        )\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskRouter.__init__","title":"<code>__init__(prefix, tags, manager_factory, entity_in_type, entity_out_type, permissions=None, **kwargs)</code>","text":"<p>Initialize task router with entity types and manager factory.</p> Source code in <code>src/chapkit/modules/task/router.py</code> <pre><code>def __init__(\n    self,\n    prefix: str,\n    tags: Sequence[str],\n    manager_factory: Any,\n    entity_in_type: type[TaskIn],\n    entity_out_type: type[TaskOut],\n    permissions: CrudPermissions | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize task router with entity types and manager factory.\"\"\"\n    super().__init__(\n        prefix=prefix,\n        tags=list(tags),\n        entity_in_type=entity_in_type,\n        entity_out_type=entity_out_type,\n        manager_factory=manager_factory,\n        permissions=permissions,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskIn","title":"<code>TaskIn</code>","text":"<p>               Bases: <code>EntityIn</code></p> <p>Input schema for creating or updating task templates.</p> Source code in <code>src/chapkit/modules/task/schemas.py</code> <pre><code>class TaskIn(EntityIn):\n    \"\"\"Input schema for creating or updating task templates.\"\"\"\n\n    command: str = Field(description=\"Shell command or Python function name to execute\")\n    task_type: Literal[\"shell\", \"python\"] = Field(default=\"shell\", description=\"Type of task: 'shell' or 'python'\")\n    parameters: dict[str, Any] | None = Field(\n        default=None, description=\"Parameters to pass to Python function (ignored for shell tasks)\"\n    )\n    enabled: bool = Field(default=True, description=\"Whether task is enabled for execution\")\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.TaskOut","title":"<code>TaskOut</code>","text":"<p>               Bases: <code>EntityOut</code></p> <p>Output schema for task template entities.</p> Source code in <code>src/chapkit/modules/task/schemas.py</code> <pre><code>class TaskOut(EntityOut):\n    \"\"\"Output schema for task template entities.\"\"\"\n\n    command: str = Field(description=\"Shell command or Python function name to execute\")\n    task_type: str = Field(description=\"Type of task: 'shell' or 'python'\")\n    parameters: dict[str, Any] | None = Field(default=None, description=\"Parameters to pass to Python function\")\n    enabled: bool = Field(description=\"Whether task is enabled for execution\")\n</code></pre>"},{"location":"api-reference/#chapkit.modules.task.validate_and_disable_orphaned_tasks","title":"<code>validate_and_disable_orphaned_tasks(app)</code>  <code>async</code>","text":"<p>Validate Python tasks and disable orphaned ones that reference missing functions.</p> Source code in <code>src/chapkit/modules/task/validation.py</code> <pre><code>async def validate_and_disable_orphaned_tasks(app: FastAPI) -&gt; int:\n    \"\"\"Validate Python tasks and disable orphaned ones that reference missing functions.\"\"\"\n    database: Database | None = getattr(app.state, \"database\", None)\n    if database is None:\n        logger.debug(\"No database configured, skipping task validation\")\n        return 0\n\n    disabled_count = 0\n\n    async with database.session() as session:\n        task_repo = TaskRepository(session)\n        task_manager = TaskManager(task_repo, scheduler=None, database=None, artifact_manager=None)\n\n        # Get all tasks\n        all_tasks = await task_manager.find_all()\n\n        # Get registered function names\n        registered_functions = set(TaskRegistry.list_all())\n\n        # Find orphaned Python tasks\n        orphaned_tasks = [\n            task for task in all_tasks if task.task_type == \"python\" and task.command not in registered_functions\n        ]\n\n        if orphaned_tasks:\n            logger.warning(\n                \"Found orphaned Python tasks - disabling them\",\n                extra={\n                    \"count\": len(orphaned_tasks),\n                    \"task_ids\": [str(task.id) for task in orphaned_tasks],\n                    \"commands\": [task.command for task in orphaned_tasks],\n                },\n            )\n\n            # Disable each orphaned task\n            for task in orphaned_tasks:\n                logger.info(\n                    f\"Disabling orphaned task {task.id}: function '{task.command}' not found in registry\",\n                    extra={\"task_id\": str(task.id), \"command\": task.command, \"task_type\": task.task_type},\n                )\n\n                # Create TaskIn with enabled=False\n                task_type_value = task.task_type if task.task_type in (\"shell\", \"python\") else \"shell\"\n                task_in = TaskIn(\n                    id=task.id,\n                    command=task.command,\n                    task_type=task_type_value,  # type: ignore[arg-type]\n                    parameters=task.parameters,\n                    enabled=False,\n                )\n                await task_manager.save(task_in)\n                disabled_count += 1\n\n    if disabled_count &gt; 0:\n        logger.warning(f\"Disabled {disabled_count} orphaned Python task(s)\")\n    else:\n        logger.debug(\"No orphaned Python tasks found\")\n\n    return disabled_count\n</code></pre>"},{"location":"api-reference/#ml-module","title":"ML Module","text":"<p>Machine learning train and predict operations.</p>"},{"location":"api-reference/#chapkit.modules.ml","title":"<code>ml</code>","text":"<p>ML module for train/predict operations with artifact-based model storage.</p>"},{"location":"api-reference/#chapkit.modules.ml.MLManager","title":"<code>MLManager</code>","text":"<p>Manager for ML train/predict operations with job scheduling and artifact storage.</p> Source code in <code>src/chapkit/modules/ml/manager.py</code> <pre><code>class MLManager:\n    \"\"\"Manager for ML train/predict operations with job scheduling and artifact storage.\"\"\"\n\n    def __init__(\n        self,\n        runner: ModelRunnerProtocol,\n        scheduler: JobScheduler,\n        database: Database,\n        config_schema: type[BaseConfig],\n    ) -&gt; None:\n        \"\"\"Initialize ML manager with runner, scheduler, database, and config schema.\"\"\"\n        self.runner = runner\n        self.scheduler = scheduler\n        self.database = database\n        self.config_schema = config_schema\n\n    async def execute_train(self, request: TrainRequest) -&gt; TrainResponse:\n        \"\"\"Submit a training job to the scheduler and return job/artifact IDs.\"\"\"\n        # Pre-allocate artifact ID for the trained model\n        model_artifact_id = ULID()\n\n        # Submit job to scheduler\n        job_id = await self.scheduler.add_job(\n            self._train_task,\n            request,\n            model_artifact_id,\n        )\n\n        return TrainResponse(\n            job_id=str(job_id),\n            model_artifact_id=str(model_artifact_id),\n            message=f\"Training job submitted. Job ID: {job_id}\",\n        )\n\n    async def execute_predict(self, request: PredictRequest) -&gt; PredictResponse:\n        \"\"\"Submit a prediction job to the scheduler and return job/artifact IDs.\"\"\"\n        # Pre-allocate artifact ID for predictions\n        prediction_artifact_id = ULID()\n\n        # Submit job to scheduler\n        job_id = await self.scheduler.add_job(\n            self._predict_task,\n            request,\n            prediction_artifact_id,\n        )\n\n        return PredictResponse(\n            job_id=str(job_id),\n            prediction_artifact_id=str(prediction_artifact_id),\n            message=f\"Prediction job submitted. Job ID: {job_id}\",\n        )\n\n    async def _train_task(self, request: TrainRequest, model_artifact_id: ULID) -&gt; ULID:\n        \"\"\"Execute training task and store trained model in artifact.\"\"\"\n        # Load config\n        async with self.database.session() as session:\n            config_repo = ConfigRepository(session)\n            config_manager: ConfigManager[BaseConfig] = ConfigManager(config_repo, self.config_schema)\n            config = await config_manager.find_by_id(request.config_id)\n\n            if config is None:\n                raise ValueError(f\"Config {request.config_id} not found\")\n\n        # Convert PandasDataFrame to pandas\n        data_df = request.data.to_dataframe()\n\n        # Train model with timing\n        training_started_at = datetime.datetime.now(datetime.UTC)\n        trained_model = await self.runner.on_train(\n            config=config.data,\n            data=data_df,\n            geo=request.geo,\n        )\n        training_completed_at = datetime.datetime.now(datetime.UTC)\n        training_duration = (training_completed_at - training_started_at).total_seconds()\n\n        # Calculate model metrics\n        model_type = _extract_model_type(trained_model)\n        model_size_bytes = _calculate_model_size(trained_model)\n\n        # Store trained model in artifact with metadata\n        async with self.database.session() as session:\n            artifact_repo = ArtifactRepository(session)\n            artifact_manager = ArtifactManager(artifact_repo)\n            config_repo = ConfigRepository(session)\n\n            # Create and validate artifact data with Pydantic\n            artifact_data_model = TrainedModelArtifactData(\n                ml_type=\"trained_model\",\n                config_id=str(request.config_id),\n                model=trained_model,\n                started_at=training_started_at.isoformat(),\n                completed_at=training_completed_at.isoformat(),\n                duration_seconds=round(training_duration, 2),\n                model_type=model_type,\n                model_size_bytes=model_size_bytes,\n            )\n\n            await artifact_manager.save(\n                ArtifactIn(\n                    id=model_artifact_id,\n                    data=artifact_data_model.model_dump(),\n                    parent_id=None,\n                    level=0,\n                )\n            )\n\n            # Link config to root artifact for tree traversal\n            await config_repo.link_artifact(request.config_id, model_artifact_id)\n            await config_repo.commit()\n\n        return model_artifact_id\n\n    async def _predict_task(self, request: PredictRequest, prediction_artifact_id: ULID) -&gt; ULID:\n        \"\"\"Execute prediction task and store predictions in artifact.\"\"\"\n        # Load model artifact\n        async with self.database.session() as session:\n            artifact_repo = ArtifactRepository(session)\n            artifact_manager = ArtifactManager(artifact_repo)\n            model_artifact = await artifact_manager.find_by_id(request.model_artifact_id)\n\n            if model_artifact is None:\n                raise ValueError(f\"Model artifact {request.model_artifact_id} not found\")\n\n        # Extract model and config_id from artifact\n        model_data = model_artifact.data\n        if not isinstance(model_data, dict) or model_data.get(\"ml_type\") != \"trained_model\":\n            raise ValueError(f\"Artifact {request.model_artifact_id} is not a trained model\")\n\n        trained_model = model_data[\"model\"]\n        config_id = ULID.from_str(model_data[\"config_id\"])\n\n        # Load config\n        async with self.database.session() as session:\n            config_repo = ConfigRepository(session)\n            config_manager: ConfigManager[BaseConfig] = ConfigManager(config_repo, self.config_schema)\n            config = await config_manager.find_by_id(config_id)\n\n            if config is None:\n                raise ValueError(f\"Config {config_id} not found\")\n\n        # Convert PandasDataFrames to pandas\n        historic_df = request.historic.to_dataframe()\n        future_df = request.future.to_dataframe()\n\n        # Make predictions with timing\n        prediction_started_at = datetime.datetime.now(datetime.UTC)\n        predictions_df = await self.runner.on_predict(\n            config=config.data,\n            model=trained_model,\n            historic=historic_df,\n            future=future_df,\n            geo=request.geo,\n        )\n        prediction_completed_at = datetime.datetime.now(datetime.UTC)\n        prediction_duration = (prediction_completed_at - prediction_started_at).total_seconds()\n\n        # Store predictions in artifact with parent linkage\n        async with self.database.session() as session:\n            artifact_repo = ArtifactRepository(session)\n            artifact_manager = ArtifactManager(artifact_repo)\n\n            from chapkit.modules.artifact.schemas import PandasDataFrame\n\n            # Create and validate artifact data with Pydantic\n            artifact_data_model = PredictionArtifactData(\n                ml_type=\"prediction\",\n                model_artifact_id=str(request.model_artifact_id),\n                config_id=str(config_id),\n                predictions=PandasDataFrame.from_dataframe(predictions_df),\n                started_at=prediction_started_at.isoformat(),\n                completed_at=prediction_completed_at.isoformat(),\n                duration_seconds=round(prediction_duration, 2),\n            )\n\n            await artifact_manager.save(\n                ArtifactIn(\n                    id=prediction_artifact_id,\n                    data=artifact_data_model.model_dump(),\n                    parent_id=request.model_artifact_id,\n                    level=1,\n                )\n            )\n\n        return prediction_artifact_id\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.MLManager.__init__","title":"<code>__init__(runner, scheduler, database, config_schema)</code>","text":"<p>Initialize ML manager with runner, scheduler, database, and config schema.</p> Source code in <code>src/chapkit/modules/ml/manager.py</code> <pre><code>def __init__(\n    self,\n    runner: ModelRunnerProtocol,\n    scheduler: JobScheduler,\n    database: Database,\n    config_schema: type[BaseConfig],\n) -&gt; None:\n    \"\"\"Initialize ML manager with runner, scheduler, database, and config schema.\"\"\"\n    self.runner = runner\n    self.scheduler = scheduler\n    self.database = database\n    self.config_schema = config_schema\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.MLManager.execute_train","title":"<code>execute_train(request)</code>  <code>async</code>","text":"<p>Submit a training job to the scheduler and return job/artifact IDs.</p> Source code in <code>src/chapkit/modules/ml/manager.py</code> <pre><code>async def execute_train(self, request: TrainRequest) -&gt; TrainResponse:\n    \"\"\"Submit a training job to the scheduler and return job/artifact IDs.\"\"\"\n    # Pre-allocate artifact ID for the trained model\n    model_artifact_id = ULID()\n\n    # Submit job to scheduler\n    job_id = await self.scheduler.add_job(\n        self._train_task,\n        request,\n        model_artifact_id,\n    )\n\n    return TrainResponse(\n        job_id=str(job_id),\n        model_artifact_id=str(model_artifact_id),\n        message=f\"Training job submitted. Job ID: {job_id}\",\n    )\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.MLManager.execute_predict","title":"<code>execute_predict(request)</code>  <code>async</code>","text":"<p>Submit a prediction job to the scheduler and return job/artifact IDs.</p> Source code in <code>src/chapkit/modules/ml/manager.py</code> <pre><code>async def execute_predict(self, request: PredictRequest) -&gt; PredictResponse:\n    \"\"\"Submit a prediction job to the scheduler and return job/artifact IDs.\"\"\"\n    # Pre-allocate artifact ID for predictions\n    prediction_artifact_id = ULID()\n\n    # Submit job to scheduler\n    job_id = await self.scheduler.add_job(\n        self._predict_task,\n        request,\n        prediction_artifact_id,\n    )\n\n    return PredictResponse(\n        job_id=str(job_id),\n        prediction_artifact_id=str(prediction_artifact_id),\n        message=f\"Prediction job submitted. Job ID: {job_id}\",\n    )\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.MLRouter","title":"<code>MLRouter</code>","text":"<p>               Bases: <code>Router</code></p> <p>Router with $train and $predict collection operations.</p> Source code in <code>src/chapkit/modules/ml/router.py</code> <pre><code>class MLRouter(Router):\n    \"\"\"Router with $train and $predict collection operations.\"\"\"\n\n    def __init__(\n        self,\n        prefix: str,\n        tags: list[str],\n        manager_factory: Any,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Initialize ML router with manager factory.\"\"\"\n        self.manager_factory = manager_factory\n        super().__init__(prefix=prefix, tags=tags, **kwargs)\n\n    def _register_routes(self) -&gt; None:\n        \"\"\"Register ML train and predict routes.\"\"\"\n        from fastapi import HTTPException\n\n        manager_factory = self.manager_factory\n\n        @self.router.post(\n            \"/$train\",\n            response_model=TrainResponse,\n            status_code=status.HTTP_202_ACCEPTED,\n            summary=\"Train model\",\n            description=\"Submit a training job to the scheduler\",\n        )\n        async def train(\n            request: TrainRequest,\n            manager: MLManager = Depends(manager_factory),\n        ) -&gt; TrainResponse:\n            \"\"\"Train a model asynchronously and return job/artifact IDs.\"\"\"\n            try:\n                response = await manager.execute_train(request)\n                train_counter, _ = _get_counters()\n                train_counter.add(1)\n                return response\n            except ValueError as e:\n                raise HTTPException(\n                    status_code=status.HTTP_400_BAD_REQUEST,\n                    detail=str(e),\n                )\n            except RuntimeError as e:\n                raise HTTPException(\n                    status_code=status.HTTP_409_CONFLICT,\n                    detail=str(e),\n                )\n\n        @self.router.post(\n            \"/$predict\",\n            response_model=PredictResponse,\n            status_code=status.HTTP_202_ACCEPTED,\n            summary=\"Make predictions\",\n            description=\"Submit a prediction job to the scheduler\",\n        )\n        async def predict(\n            request: PredictRequest,\n            manager: MLManager = Depends(manager_factory),\n        ) -&gt; PredictResponse:\n            \"\"\"Make predictions asynchronously and return job/artifact IDs.\"\"\"\n            try:\n                response = await manager.execute_predict(request)\n                _, predict_counter = _get_counters()\n                predict_counter.add(1)\n                return response\n            except ValueError as e:\n                raise HTTPException(\n                    status_code=status.HTTP_400_BAD_REQUEST,\n                    detail=str(e),\n                )\n            except RuntimeError as e:\n                raise HTTPException(\n                    status_code=status.HTTP_409_CONFLICT,\n                    detail=str(e),\n                )\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.MLRouter.__init__","title":"<code>__init__(prefix, tags, manager_factory, **kwargs)</code>","text":"<p>Initialize ML router with manager factory.</p> Source code in <code>src/chapkit/modules/ml/router.py</code> <pre><code>def __init__(\n    self,\n    prefix: str,\n    tags: list[str],\n    manager_factory: Any,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize ML router with manager factory.\"\"\"\n    self.manager_factory = manager_factory\n    super().__init__(prefix=prefix, tags=tags, **kwargs)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.BaseModelRunner","title":"<code>BaseModelRunner</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for model runners with lifecycle hooks.</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>class BaseModelRunner(ABC):\n    \"\"\"Abstract base class for model runners with lifecycle hooks.\"\"\"\n\n    async def on_init(self) -&gt; None:\n        \"\"\"Optional initialization hook called before training or prediction.\"\"\"\n        pass\n\n    async def on_cleanup(self) -&gt; None:\n        \"\"\"Optional cleanup hook called after training or prediction.\"\"\"\n        pass\n\n    @abstractmethod\n    async def on_train(\n        self,\n        config: BaseConfig,\n        data: pd.DataFrame,\n        geo: FeatureCollection | None = None,\n    ) -&gt; Any:\n        \"\"\"Train a model and return the trained model object (must be pickleable).\"\"\"\n        ...\n\n    @abstractmethod\n    async def on_predict(\n        self,\n        config: BaseConfig,\n        model: Any,\n        historic: pd.DataFrame,\n        future: pd.DataFrame,\n        geo: FeatureCollection | None = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Make predictions using a trained model and return predictions as DataFrame.\"\"\"\n        ...\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.BaseModelRunner.on_init","title":"<code>on_init()</code>  <code>async</code>","text":"<p>Optional initialization hook called before training or prediction.</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>async def on_init(self) -&gt; None:\n    \"\"\"Optional initialization hook called before training or prediction.\"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.BaseModelRunner.on_cleanup","title":"<code>on_cleanup()</code>  <code>async</code>","text":"<p>Optional cleanup hook called after training or prediction.</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>async def on_cleanup(self) -&gt; None:\n    \"\"\"Optional cleanup hook called after training or prediction.\"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.BaseModelRunner.on_train","title":"<code>on_train(config, data, geo=None)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Train a model and return the trained model object (must be pickleable).</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>@abstractmethod\nasync def on_train(\n    self,\n    config: BaseConfig,\n    data: pd.DataFrame,\n    geo: FeatureCollection | None = None,\n) -&gt; Any:\n    \"\"\"Train a model and return the trained model object (must be pickleable).\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.BaseModelRunner.on_predict","title":"<code>on_predict(config, model, historic, future, geo=None)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Make predictions using a trained model and return predictions as DataFrame.</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>@abstractmethod\nasync def on_predict(\n    self,\n    config: BaseConfig,\n    model: Any,\n    historic: pd.DataFrame,\n    future: pd.DataFrame,\n    geo: FeatureCollection | None = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Make predictions using a trained model and return predictions as DataFrame.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.FunctionalModelRunner","title":"<code>FunctionalModelRunner</code>","text":"<p>               Bases: <code>BaseModelRunner</code>, <code>Generic[ConfigT]</code></p> <p>Functional model runner wrapping train and predict functions.</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>class FunctionalModelRunner(BaseModelRunner, Generic[ConfigT]):\n    \"\"\"Functional model runner wrapping train and predict functions.\"\"\"\n\n    def __init__(\n        self,\n        on_train: TrainFunction[ConfigT],\n        on_predict: PredictFunction[ConfigT],\n    ) -&gt; None:\n        \"\"\"Initialize functional runner with train and predict functions.\"\"\"\n        self._on_train = on_train\n        self._on_predict = on_predict\n\n    async def on_train(\n        self,\n        config: BaseConfig,\n        data: pd.DataFrame,\n        geo: FeatureCollection | None = None,\n    ) -&gt; Any:\n        \"\"\"Train a model and return the trained model object.\"\"\"\n        return await self._on_train(config, data, geo)  # type: ignore[arg-type]\n\n    async def on_predict(\n        self,\n        config: BaseConfig,\n        model: Any,\n        historic: pd.DataFrame,\n        future: pd.DataFrame,\n        geo: FeatureCollection | None = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Make predictions using a trained model.\"\"\"\n        return await self._on_predict(config, model, historic, future, geo)  # type: ignore[arg-type]\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.FunctionalModelRunner.__init__","title":"<code>__init__(on_train, on_predict)</code>","text":"<p>Initialize functional runner with train and predict functions.</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>def __init__(\n    self,\n    on_train: TrainFunction[ConfigT],\n    on_predict: PredictFunction[ConfigT],\n) -&gt; None:\n    \"\"\"Initialize functional runner with train and predict functions.\"\"\"\n    self._on_train = on_train\n    self._on_predict = on_predict\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.FunctionalModelRunner.on_train","title":"<code>on_train(config, data, geo=None)</code>  <code>async</code>","text":"<p>Train a model and return the trained model object.</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>async def on_train(\n    self,\n    config: BaseConfig,\n    data: pd.DataFrame,\n    geo: FeatureCollection | None = None,\n) -&gt; Any:\n    \"\"\"Train a model and return the trained model object.\"\"\"\n    return await self._on_train(config, data, geo)  # type: ignore[arg-type]\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.FunctionalModelRunner.on_predict","title":"<code>on_predict(config, model, historic, future, geo=None)</code>  <code>async</code>","text":"<p>Make predictions using a trained model.</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>async def on_predict(\n    self,\n    config: BaseConfig,\n    model: Any,\n    historic: pd.DataFrame,\n    future: pd.DataFrame,\n    geo: FeatureCollection | None = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Make predictions using a trained model.\"\"\"\n    return await self._on_predict(config, model, historic, future, geo)  # type: ignore[arg-type]\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.ShellModelRunner","title":"<code>ShellModelRunner</code>","text":"<p>               Bases: <code>BaseModelRunner</code></p> <p>Shell-based model runner that executes external scripts for train/predict operations.</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>class ShellModelRunner(BaseModelRunner):\n    \"\"\"Shell-based model runner that executes external scripts for train/predict operations.\"\"\"\n\n    def __init__(\n        self,\n        train_command: str,\n        predict_command: str,\n        model_format: str = \"pickle\",\n    ) -&gt; None:\n        \"\"\"Initialize shell runner with command templates for train/predict operations.\"\"\"\n        self.train_command = train_command\n        self.predict_command = predict_command\n        self.model_format = model_format\n\n    async def on_train(\n        self,\n        config: BaseConfig,\n        data: pd.DataFrame,\n        geo: FeatureCollection | None = None,\n    ) -&gt; Any:\n        \"\"\"Train a model by executing external training script.\"\"\"\n        temp_dir = Path(tempfile.mkdtemp(prefix=\"chapkit_ml_train_\"))\n\n        try:\n            # Write config to JSON file\n            config_file = temp_dir / \"config.json\"\n            config_file.write_text(json.dumps(config.model_dump(), indent=2))\n\n            # Write training data to CSV\n            data_file = temp_dir / \"data.csv\"\n            data.to_csv(data_file, index=False)\n\n            # Write geo data if provided\n            geo_file = temp_dir / \"geo.json\" if geo else None\n            if geo:\n                assert geo_file is not None  # For type checker\n                geo_file.write_text(geo.model_dump_json(indent=2))\n\n            # Model file path\n            model_file = temp_dir / f\"model.{self.model_format}\"\n\n            # Substitute variables in command\n            command = self.train_command.format(\n                config_file=str(config_file),\n                data_file=str(data_file),\n                model_file=str(model_file),\n                geo_file=str(geo_file) if geo_file else \"\",\n            )\n\n            logger.info(\"executing_train_script\", command=command, temp_dir=str(temp_dir))\n\n            # Execute subprocess\n            process = await asyncio.create_subprocess_shell(\n                command,\n                stdout=asyncio.subprocess.PIPE,\n                stderr=asyncio.subprocess.PIPE,\n                cwd=str(temp_dir),\n            )\n\n            stdout_bytes, stderr_bytes = await process.communicate()\n            stdout = stdout_bytes.decode(\"utf-8\") if stdout_bytes else \"\"\n            stderr = stderr_bytes.decode(\"utf-8\") if stderr_bytes else \"\"\n\n            if process.returncode != 0:\n                logger.error(\"train_script_failed\", exit_code=process.returncode, stderr=stderr)\n                raise RuntimeError(f\"Training script failed with exit code {process.returncode}: {stderr}\")\n\n            logger.info(\"train_script_completed\", stdout=stdout[:500], stderr=stderr[:500])\n\n            # Load trained model from file\n            if not model_file.exists():\n                raise RuntimeError(f\"Training script did not create model file at {model_file}\")\n\n            with open(model_file, \"rb\") as f:\n                model = pickle.load(f)\n\n            return model\n\n        finally:\n            # Cleanup temp files\n            import shutil\n\n            shutil.rmtree(temp_dir, ignore_errors=True)\n\n    async def on_predict(\n        self,\n        config: BaseConfig,\n        model: Any,\n        historic: pd.DataFrame,\n        future: pd.DataFrame,\n        geo: FeatureCollection | None = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Make predictions by executing external prediction script.\"\"\"\n        temp_dir = Path(tempfile.mkdtemp(prefix=\"chapkit_ml_predict_\"))\n\n        try:\n            # Write config to JSON file\n            config_file = temp_dir / \"config.json\"\n            config_file.write_text(json.dumps(config.model_dump(), indent=2))\n\n            # Write model to file\n            model_file = temp_dir / f\"model.{self.model_format}\"\n            with open(model_file, \"wb\") as f:\n                pickle.dump(model, f)\n\n            # Write historic data\n            historic_file = temp_dir / \"historic.csv\"\n            historic.to_csv(historic_file, index=False)\n\n            # Write future data to CSV\n            future_file = temp_dir / \"future.csv\"\n            future.to_csv(future_file, index=False)\n\n            # Write geo data if provided\n            geo_file = temp_dir / \"geo.json\" if geo else None\n            if geo:\n                assert geo_file is not None  # For type checker\n                geo_file.write_text(geo.model_dump_json(indent=2))\n\n            # Output file path\n            output_file = temp_dir / \"predictions.csv\"\n\n            # Substitute variables in command\n            command = self.predict_command.format(\n                config_file=str(config_file),\n                model_file=str(model_file),\n                historic_file=str(historic_file),\n                future_file=str(future_file),\n                output_file=str(output_file),\n                geo_file=str(geo_file) if geo_file else \"\",\n            )\n\n            logger.info(\"executing_predict_script\", command=command, temp_dir=str(temp_dir))\n\n            # Execute subprocess\n            process = await asyncio.create_subprocess_shell(\n                command,\n                stdout=asyncio.subprocess.PIPE,\n                stderr=asyncio.subprocess.PIPE,\n                cwd=str(temp_dir),\n            )\n\n            stdout_bytes, stderr_bytes = await process.communicate()\n            stdout = stdout_bytes.decode(\"utf-8\") if stdout_bytes else \"\"\n            stderr = stderr_bytes.decode(\"utf-8\") if stderr_bytes else \"\"\n\n            if process.returncode != 0:\n                logger.error(\"predict_script_failed\", exit_code=process.returncode, stderr=stderr)\n                raise RuntimeError(f\"Prediction script failed with exit code {process.returncode}: {stderr}\")\n\n            logger.info(\"predict_script_completed\", stdout=stdout[:500], stderr=stderr[:500])\n\n            # Load predictions from file\n            if not output_file.exists():\n                raise RuntimeError(f\"Prediction script did not create output file at {output_file}\")\n\n            predictions = pd.read_csv(output_file)\n            return predictions\n\n        finally:\n            # Cleanup temp files\n            import shutil\n\n            shutil.rmtree(temp_dir, ignore_errors=True)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.ShellModelRunner.__init__","title":"<code>__init__(train_command, predict_command, model_format='pickle')</code>","text":"<p>Initialize shell runner with command templates for train/predict operations.</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>def __init__(\n    self,\n    train_command: str,\n    predict_command: str,\n    model_format: str = \"pickle\",\n) -&gt; None:\n    \"\"\"Initialize shell runner with command templates for train/predict operations.\"\"\"\n    self.train_command = train_command\n    self.predict_command = predict_command\n    self.model_format = model_format\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.ShellModelRunner.on_train","title":"<code>on_train(config, data, geo=None)</code>  <code>async</code>","text":"<p>Train a model by executing external training script.</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>async def on_train(\n    self,\n    config: BaseConfig,\n    data: pd.DataFrame,\n    geo: FeatureCollection | None = None,\n) -&gt; Any:\n    \"\"\"Train a model by executing external training script.\"\"\"\n    temp_dir = Path(tempfile.mkdtemp(prefix=\"chapkit_ml_train_\"))\n\n    try:\n        # Write config to JSON file\n        config_file = temp_dir / \"config.json\"\n        config_file.write_text(json.dumps(config.model_dump(), indent=2))\n\n        # Write training data to CSV\n        data_file = temp_dir / \"data.csv\"\n        data.to_csv(data_file, index=False)\n\n        # Write geo data if provided\n        geo_file = temp_dir / \"geo.json\" if geo else None\n        if geo:\n            assert geo_file is not None  # For type checker\n            geo_file.write_text(geo.model_dump_json(indent=2))\n\n        # Model file path\n        model_file = temp_dir / f\"model.{self.model_format}\"\n\n        # Substitute variables in command\n        command = self.train_command.format(\n            config_file=str(config_file),\n            data_file=str(data_file),\n            model_file=str(model_file),\n            geo_file=str(geo_file) if geo_file else \"\",\n        )\n\n        logger.info(\"executing_train_script\", command=command, temp_dir=str(temp_dir))\n\n        # Execute subprocess\n        process = await asyncio.create_subprocess_shell(\n            command,\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.PIPE,\n            cwd=str(temp_dir),\n        )\n\n        stdout_bytes, stderr_bytes = await process.communicate()\n        stdout = stdout_bytes.decode(\"utf-8\") if stdout_bytes else \"\"\n        stderr = stderr_bytes.decode(\"utf-8\") if stderr_bytes else \"\"\n\n        if process.returncode != 0:\n            logger.error(\"train_script_failed\", exit_code=process.returncode, stderr=stderr)\n            raise RuntimeError(f\"Training script failed with exit code {process.returncode}: {stderr}\")\n\n        logger.info(\"train_script_completed\", stdout=stdout[:500], stderr=stderr[:500])\n\n        # Load trained model from file\n        if not model_file.exists():\n            raise RuntimeError(f\"Training script did not create model file at {model_file}\")\n\n        with open(model_file, \"rb\") as f:\n            model = pickle.load(f)\n\n        return model\n\n    finally:\n        # Cleanup temp files\n        import shutil\n\n        shutil.rmtree(temp_dir, ignore_errors=True)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.ShellModelRunner.on_predict","title":"<code>on_predict(config, model, historic, future, geo=None)</code>  <code>async</code>","text":"<p>Make predictions by executing external prediction script.</p> Source code in <code>src/chapkit/modules/ml/runner.py</code> <pre><code>async def on_predict(\n    self,\n    config: BaseConfig,\n    model: Any,\n    historic: pd.DataFrame,\n    future: pd.DataFrame,\n    geo: FeatureCollection | None = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Make predictions by executing external prediction script.\"\"\"\n    temp_dir = Path(tempfile.mkdtemp(prefix=\"chapkit_ml_predict_\"))\n\n    try:\n        # Write config to JSON file\n        config_file = temp_dir / \"config.json\"\n        config_file.write_text(json.dumps(config.model_dump(), indent=2))\n\n        # Write model to file\n        model_file = temp_dir / f\"model.{self.model_format}\"\n        with open(model_file, \"wb\") as f:\n            pickle.dump(model, f)\n\n        # Write historic data\n        historic_file = temp_dir / \"historic.csv\"\n        historic.to_csv(historic_file, index=False)\n\n        # Write future data to CSV\n        future_file = temp_dir / \"future.csv\"\n        future.to_csv(future_file, index=False)\n\n        # Write geo data if provided\n        geo_file = temp_dir / \"geo.json\" if geo else None\n        if geo:\n            assert geo_file is not None  # For type checker\n            geo_file.write_text(geo.model_dump_json(indent=2))\n\n        # Output file path\n        output_file = temp_dir / \"predictions.csv\"\n\n        # Substitute variables in command\n        command = self.predict_command.format(\n            config_file=str(config_file),\n            model_file=str(model_file),\n            historic_file=str(historic_file),\n            future_file=str(future_file),\n            output_file=str(output_file),\n            geo_file=str(geo_file) if geo_file else \"\",\n        )\n\n        logger.info(\"executing_predict_script\", command=command, temp_dir=str(temp_dir))\n\n        # Execute subprocess\n        process = await asyncio.create_subprocess_shell(\n            command,\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.PIPE,\n            cwd=str(temp_dir),\n        )\n\n        stdout_bytes, stderr_bytes = await process.communicate()\n        stdout = stdout_bytes.decode(\"utf-8\") if stdout_bytes else \"\"\n        stderr = stderr_bytes.decode(\"utf-8\") if stderr_bytes else \"\"\n\n        if process.returncode != 0:\n            logger.error(\"predict_script_failed\", exit_code=process.returncode, stderr=stderr)\n            raise RuntimeError(f\"Prediction script failed with exit code {process.returncode}: {stderr}\")\n\n        logger.info(\"predict_script_completed\", stdout=stdout[:500], stderr=stderr[:500])\n\n        # Load predictions from file\n        if not output_file.exists():\n            raise RuntimeError(f\"Prediction script did not create output file at {output_file}\")\n\n        predictions = pd.read_csv(output_file)\n        return predictions\n\n    finally:\n        # Cleanup temp files\n        import shutil\n\n        shutil.rmtree(temp_dir, ignore_errors=True)\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.ModelRunnerProtocol","title":"<code>ModelRunnerProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol defining the interface for model runners.</p> Source code in <code>src/chapkit/modules/ml/schemas.py</code> <pre><code>class ModelRunnerProtocol(Protocol):\n    \"\"\"Protocol defining the interface for model runners.\"\"\"\n\n    async def on_train(\n        self,\n        config: BaseConfig,\n        data: pd.DataFrame,\n        geo: FeatureCollection | None = None,\n    ) -&gt; Any:\n        \"\"\"Train a model and return the trained model object (must be pickleable).\"\"\"\n        ...\n\n    async def on_predict(\n        self,\n        config: BaseConfig,\n        model: Any,\n        historic: pd.DataFrame,\n        future: pd.DataFrame,\n        geo: FeatureCollection | None = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Make predictions using a trained model and return predictions as DataFrame.\"\"\"\n        ...\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.ModelRunnerProtocol.on_train","title":"<code>on_train(config, data, geo=None)</code>  <code>async</code>","text":"<p>Train a model and return the trained model object (must be pickleable).</p> Source code in <code>src/chapkit/modules/ml/schemas.py</code> <pre><code>async def on_train(\n    self,\n    config: BaseConfig,\n    data: pd.DataFrame,\n    geo: FeatureCollection | None = None,\n) -&gt; Any:\n    \"\"\"Train a model and return the trained model object (must be pickleable).\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.ModelRunnerProtocol.on_predict","title":"<code>on_predict(config, model, historic, future, geo=None)</code>  <code>async</code>","text":"<p>Make predictions using a trained model and return predictions as DataFrame.</p> Source code in <code>src/chapkit/modules/ml/schemas.py</code> <pre><code>async def on_predict(\n    self,\n    config: BaseConfig,\n    model: Any,\n    historic: pd.DataFrame,\n    future: pd.DataFrame,\n    geo: FeatureCollection | None = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Make predictions using a trained model and return predictions as DataFrame.\"\"\"\n    ...\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.PredictionArtifactData","title":"<code>PredictionArtifactData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Schema for prediction artifact data stored in the artifact system.</p> Source code in <code>src/chapkit/modules/ml/schemas.py</code> <pre><code>class PredictionArtifactData(BaseModel):\n    \"\"\"Schema for prediction artifact data stored in the artifact system.\"\"\"\n\n    ml_type: Literal[\"prediction\"] = Field(description=\"Artifact type identifier\")\n    config_id: str = Field(description=\"ID of the config used for prediction\")\n    model_artifact_id: str = Field(description=\"ID of the trained model artifact used for prediction\")\n    started_at: str = Field(description=\"ISO format timestamp when operation started\")\n    completed_at: str = Field(description=\"ISO format timestamp when operation completed\")\n    duration_seconds: float = Field(description=\"Operation duration in seconds (rounded to 2 decimals)\")\n    predictions: PandasDataFrame = Field(description=\"Prediction results as structured DataFrame\")\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.PredictRequest","title":"<code>PredictRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request schema for making predictions.</p> Source code in <code>src/chapkit/modules/ml/schemas.py</code> <pre><code>class PredictRequest(BaseModel):\n    \"\"\"Request schema for making predictions.\"\"\"\n\n    model_artifact_id: ULID = Field(description=\"ID of the artifact containing the trained model\")\n    historic: PandasDataFrame = Field(description=\"Historic data as pandas DataFrame\")\n    future: PandasDataFrame = Field(description=\"Future/prediction data as pandas DataFrame\")\n    geo: FeatureCollection | None = Field(default=None, description=\"Optional geospatial data\")\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.PredictResponse","title":"<code>PredictResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response schema for predict operation submission.</p> Source code in <code>src/chapkit/modules/ml/schemas.py</code> <pre><code>class PredictResponse(BaseModel):\n    \"\"\"Response schema for predict operation submission.\"\"\"\n\n    job_id: str = Field(description=\"ID of the prediction job in the scheduler\")\n    prediction_artifact_id: str = Field(description=\"ID that will contain the prediction artifact\")\n    message: str = Field(description=\"Human-readable message\")\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.TrainedModelArtifactData","title":"<code>TrainedModelArtifactData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Schema for trained model artifact data stored in the artifact system.</p> Source code in <code>src/chapkit/modules/ml/schemas.py</code> <pre><code>class TrainedModelArtifactData(BaseModel):\n    \"\"\"Schema for trained model artifact data stored in the artifact system.\"\"\"\n\n    ml_type: Literal[\"trained_model\"] = Field(description=\"Artifact type identifier\")\n    config_id: str = Field(description=\"ID of the config used for training\")\n    started_at: str = Field(description=\"ISO format timestamp when operation started\")\n    completed_at: str = Field(description=\"ISO format timestamp when operation completed\")\n    duration_seconds: float = Field(description=\"Operation duration in seconds (rounded to 2 decimals)\")\n    model: Any = Field(description=\"The trained model object (must be pickleable)\")\n    model_type: str | None = Field(default=None, description=\"Fully qualified class name of the model\")\n    model_size_bytes: int | None = Field(default=None, description=\"Serialized pickle size of the model in bytes\")\n\n    model_config = {\"arbitrary_types_allowed\": True}\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.TrainRequest","title":"<code>TrainRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request schema for training a model.</p> Source code in <code>src/chapkit/modules/ml/schemas.py</code> <pre><code>class TrainRequest(BaseModel):\n    \"\"\"Request schema for training a model.\"\"\"\n\n    config_id: ULID = Field(description=\"ID of the config to use for training\")\n    data: PandasDataFrame = Field(description=\"Training data as pandas DataFrame\")\n    geo: FeatureCollection | None = Field(default=None, description=\"Optional geospatial data\")\n</code></pre>"},{"location":"api-reference/#chapkit.modules.ml.TrainResponse","title":"<code>TrainResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response schema for train operation submission.</p> Source code in <code>src/chapkit/modules/ml/schemas.py</code> <pre><code>class TrainResponse(BaseModel):\n    \"\"\"Response schema for train operation submission.\"\"\"\n\n    job_id: str = Field(description=\"ID of the training job in the scheduler\")\n    model_artifact_id: str = Field(description=\"ID that will contain the trained model artifact\")\n    message: str = Field(description=\"Human-readable message\")\n</code></pre>"},{"location":"guides/app-hosting/","title":"App Hosting","text":"<p>Chapkit enables hosting static web applications (HTML/JS/CSS) alongside your FastAPI service, allowing you to serve dashboards, admin panels, documentation sites, and other web UIs from the same server as your API.</p>"},{"location":"guides/app-hosting/#quick-start","title":"Quick Start","text":""},{"location":"guides/app-hosting/#mount-a-single-app","title":"Mount a Single App","text":"<pre><code>from chapkit.core.api import BaseServiceBuilder, ServiceInfo\n\napp = (\n    BaseServiceBuilder(info=ServiceInfo(display_name=\"My Service\"))\n    .with_health()\n    .with_app(\"./apps/dashboard\")  # Mount app from filesystem\n    .build()\n)\n</code></pre> <p>Your dashboard is now available at the prefix defined in <code>manifest.json</code> (e.g., <code>/dashboard</code>).</p>"},{"location":"guides/app-hosting/#auto-discover-multiple-apps","title":"Auto-Discover Multiple Apps","text":"<pre><code>app = (\n    BaseServiceBuilder(info=ServiceInfo(display_name=\"My Service\"))\n    .with_health()\n    .with_apps(\"./apps\")  # Discovers all subdirectories with manifest.json\n    .build()\n)\n</code></pre> <p>All apps in the <code>apps/</code> directory are automatically discovered and mounted.</p>"},{"location":"guides/app-hosting/#app-structure","title":"App Structure","text":"<p>Each app is a directory containing a <code>manifest.json</code> file and static files (HTML, CSS, JavaScript, images).</p>"},{"location":"guides/app-hosting/#directory-layout","title":"Directory Layout","text":"<pre><code>my-app/\n\u251c\u2500\u2500 manifest.json    # Required: App metadata and configuration\n\u251c\u2500\u2500 index.html       # Required: Entry point (configurable)\n\u251c\u2500\u2500 style.css        # Optional: Stylesheets\n\u251c\u2500\u2500 script.js        # Optional: JavaScript\n\u2514\u2500\u2500 assets/          # Optional: Images, fonts, etc.\n    \u2514\u2500\u2500 logo.png\n</code></pre>"},{"location":"guides/app-hosting/#manifest-format","title":"Manifest Format","text":"<p>manifest.json: <pre><code>{\n  \"name\": \"My Dashboard\",\n  \"version\": \"1.0.0\",\n  \"prefix\": \"/dashboard\",\n  \"description\": \"Interactive data dashboard\",\n  \"author\": \"Your Name\",\n  \"entry\": \"index.html\"\n}\n</code></pre></p> <p>Required fields: - name (<code>string</code>): Human-readable app name - version (<code>string</code>): Semantic version (e.g., \"1.0.0\") - prefix (<code>string</code>): URL prefix for mounting (must start with <code>/</code>)</p> <p>Optional fields: - description (<code>string</code>): Brief description of the app - author (<code>string</code>): Author name or organization - entry (<code>string</code>): Entry point filename. Default: <code>\"index.html\"</code></p>"},{"location":"guides/app-hosting/#configuration-options","title":"Configuration Options","text":""},{"location":"guides/app-hosting/#single-app-with_app","title":"Single App: <code>.with_app()</code>","text":"<p>Mount a single app from a filesystem path or package resource:</p> <pre><code># Mount from filesystem\n.with_app(\"./apps/dashboard\")\n\n# Mount from filesystem with custom prefix\n.with_app(\"./apps/dashboard\", prefix=\"/admin\")\n\n# Mount from Python package\n.with_app((\"mycompany.apps\", \"dashboard\"))\n</code></pre> <p>Parameters: - path (<code>str | Path | tuple[str, str]</code>): Filesystem path or package tuple - prefix (<code>str | None</code>): Override the prefix from manifest.json</p>"},{"location":"guides/app-hosting/#multiple-apps-with_apps","title":"Multiple Apps: <code>.with_apps()</code>","text":"<p>Auto-discover and mount all apps in a directory or package:</p> <pre><code># Discover from filesystem directory\n.with_apps(\"./apps\")\n\n# Discover from Python package\n.with_apps((\"mycompany.apps\", \"webapps\"))\n</code></pre> <p>Parameters: - path (<code>str | Path | tuple[str, str]</code>): Directory path or package tuple</p>"},{"location":"guides/app-hosting/#path-types","title":"Path Types","text":""},{"location":"guides/app-hosting/#filesystem-paths","title":"Filesystem Paths","text":"<p>Paths are resolved relative to the current working directory (where the service runs):</p> <pre><code># Relative paths\n.with_app(\"./apps/dashboard\")\n.with_app(\"apps/dashboard\")\n\n# Absolute paths\n.with_app(\"/opt/myproject/apps/dashboard\")\n</code></pre> <p>Project structure: <pre><code>myproject/\n\u251c\u2500\u2500 apps/\n\u2502   \u251c\u2500\u2500 dashboard/\n\u2502   \u2502   \u251c\u2500\u2500 manifest.json\n\u2502   \u2502   \u2514\u2500\u2500 index.html\n\u2502   \u2514\u2500\u2500 admin/\n\u2502       \u251c\u2500\u2500 manifest.json\n\u2502       \u2514\u2500\u2500 index.html\n\u251c\u2500\u2500 main.py\n\u2514\u2500\u2500 pyproject.toml\n</code></pre></p> <p>Usage in main.py: <pre><code>app = (\n    BaseServiceBuilder(info=ServiceInfo(display_name=\"My Service\"))\n    .with_app(\"./apps/dashboard\")      # Single app\n    .with_apps(\"./apps\")               # All apps\n    .build()\n)\n</code></pre></p>"},{"location":"guides/app-hosting/#package-resources","title":"Package Resources","text":"<p>Bundle apps with your Python package using tuple syntax <code>(package_name, subpath)</code>:</p> <pre><code># Single app from package\n.with_app((\"mycompany.apps\", \"dashboard\"))\n\n# All apps from package directory\n.with_apps((\"mycompany.apps\", \"webapps\"))\n</code></pre> <p>Package structure: <pre><code>mycompany/\n  apps/\n    webapps/\n      dashboard/\n        manifest.json\n        index.html\n      admin/\n        manifest.json\n        index.html\n</code></pre></p> <p>Why use package resources? - Ship default apps with your library - Version apps alongside Python code - Distribute apps via PyPI - Easy deployment (no external files needed)</p>"},{"location":"guides/app-hosting/#override-semantics","title":"Override Semantics","text":""},{"location":"guides/app-hosting/#multiple-app-calls","title":"Multiple App Calls","text":"<p>Calling <code>.with_app()</code> and <code>.with_apps()</code> multiple times is cumulative - all apps from all calls are combined:</p> <pre><code>app = (\n    BaseServiceBuilder(info=info)\n    .with_apps(\"./apps/set1\")      # Discover apps from set1/\n    .with_apps(\"./apps/set2\")      # Discover apps from set2/\n    .with_app(\"./apps/custom\")     # Add single custom app\n    .build()\n)\n</code></pre> <p>All apps from both directories plus the custom app will be mounted.</p> <p>This works for all path types:</p> <pre><code># Filesystem paths\n.with_apps(\"./apps/dir1\").with_apps(\"./apps/dir2\")\n\n# Package resources\n.with_apps((\"pkg1\", \"apps\")).with_apps((\"pkg2\", \"apps\"))\n\n# Mixed approaches\n.with_apps(\"./apps\").with_apps((\"mypackage\", \"bundled_apps\"))\n</code></pre>"},{"location":"guides/app-hosting/#duplicate-prefixes","title":"Duplicate Prefixes","text":"<p>When multiple apps use the same prefix, the last one wins:</p> <pre><code>app = (\n    BaseServiceBuilder(info=info)\n    .with_app(\"apps/dashboard\")                    # Mounts at /dashboard\n    .with_app(\"apps/better-dashboard\", prefix=\"/dashboard\")  # Replaces first\n    .build()\n)\n</code></pre> <p>This applies to duplicates from multiple <code>.with_app()</code> or <code>.with_apps()</code> calls as well. If <code>./apps/set1</code> contains a dashboard at <code>/dashboard</code> and <code>./apps/set2</code> also contains a dashboard at <code>/dashboard</code>, the one from <code>set2</code> wins (assuming <code>set2</code> was added last).</p> <p>The service logs a warning when an app overrides another: <pre><code>app.prefix.override prefix=/dashboard replaced_app=Dashboard new_app=BetterDashboard\n</code></pre></p>"},{"location":"guides/app-hosting/#landing-page-override","title":"Landing Page Override","text":"<p><code>.with_landing_page()</code> internally mounts a built-in app at <code>/</code>. You can override it:</p> <pre><code>app = (\n    BaseServiceBuilder(info=info)\n    .with_landing_page()                  # Built-in landing page at /\n    .with_app(\"apps/custom-home\", prefix=\"/\")  # Replace with custom\n    .build()\n)\n</code></pre>"},{"location":"guides/app-hosting/#root-apps","title":"Root Apps","text":"<p>Apps can mount at root (<code>/</code>), but be aware of a limitation:</p> <p>Root mounts intercept trailing slash redirects. Use exact paths for API endpoints: - Correct: <code>/api/v1/configs</code> - Incorrect: <code>/api/v1/configs/</code> (may return 404)</p> <p>API routes always take precedence over apps (routes are registered first).</p>"},{"location":"guides/app-hosting/#restrictions","title":"Restrictions","text":""},{"location":"guides/app-hosting/#blocked-prefixes","title":"Blocked Prefixes","text":"<p>Apps cannot mount at <code>/api</code> or <code>/api/**</code> (reserved for API endpoints):</p> <pre><code># This will raise ValueError\n.with_app(\"apps/api-dashboard\", prefix=\"/api/dashboard\")\n</code></pre>"},{"location":"guides/app-hosting/#prefix-format","title":"Prefix Format","text":"<p>Prefixes must: - Start with <code>/</code> - Not contain <code>..</code> (path traversal protection) - Be valid URL paths</p> <pre><code># Valid prefixes\n.with_app(\"apps/dashboard\", prefix=\"/dashboard\")\n.with_app(\"apps/admin\", prefix=\"/admin/panel\")\n.with_app(\"apps/home\", prefix=\"/\")\n\n# Invalid prefixes\n.with_app(\"apps/bad\", prefix=\"dashboard\")    # Missing leading /\n.with_app(\"apps/bad\", prefix=\"/../../etc\")   # Path traversal\n</code></pre>"},{"location":"guides/app-hosting/#testing-apps","title":"Testing Apps","text":""},{"location":"guides/app-hosting/#with-curl","title":"With cURL","text":"<pre><code># Test app is accessible\ncurl http://localhost:8000/dashboard/\n\n# Test app assets\ncurl http://localhost:8000/dashboard/style.css\n\n# Test API still works\ncurl http://localhost:8000/api/v1/configs\n</code></pre>"},{"location":"guides/app-hosting/#with-browser","title":"With Browser","text":"<ol> <li>Start your service: <code>fastapi dev your_file.py</code></li> <li>Navigate to app: http://localhost:8000/dashboard</li> <li>Check browser console for errors</li> <li>Verify API requests work: http://localhost:8000/api/v1/configs</li> </ol>"},{"location":"guides/app-hosting/#in-tests","title":"In Tests","text":"<pre><code>from starlette.testclient import TestClient\n\ndef test_app_is_accessible():\n    with TestClient(app) as client:\n        # Test app loads\n        response = client.get(\"/dashboard/\")\n        assert response.status_code == 200\n        assert b\"Dashboard\" in response.content\n\n        # Test app assets\n        response = client.get(\"/dashboard/style.css\")\n        assert response.status_code == 200\n\n        # Test API still works\n        response = client.get(\"/api/v1/configs\")\n        assert response.status_code == 200\n</code></pre>"},{"location":"guides/app-hosting/#docker-deployment","title":"Docker Deployment","text":""},{"location":"guides/app-hosting/#dockerfile","title":"Dockerfile","text":"<pre><code>FROM python:3.13-slim\n\nWORKDIR /app\n\n# Copy application code\nCOPY . .\n\n# Install dependencies\nRUN pip install -e .\n\n# Copy apps directory\nCOPY ./apps /app/apps\n\n# Expose port\nEXPOSE 8000\n\n# Run service\nCMD [\"fastapi\", \"run\", \"main.py\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"guides/app-hosting/#docker-compose","title":"Docker Compose","text":"<p>docker-compose.yml: <pre><code>version: '3.8'\n\nservices:\n  app:\n    build: .\n    ports:\n      - \"8000:8000\"\n    volumes:\n      # Mount apps directory for development\n      - ./apps:/app/apps:ro\n    environment:\n      - LOG_LEVEL=INFO\n</code></pre></p> <p>Run: <pre><code>docker compose up\n</code></pre></p> <p>Access: - App: http://localhost:8000/dashboard - API: http://localhost:8000/api/v1/configs - Docs: http://localhost:8000/docs</p>"},{"location":"guides/app-hosting/#kubernetes-deployment","title":"Kubernetes Deployment","text":""},{"location":"guides/app-hosting/#configmap-for-apps","title":"ConfigMap for Apps","text":"<p>apps-configmap.yaml: <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: dashboard-app\ndata:\n  manifest.json: |\n    {\n      \"name\": \"Dashboard\",\n      \"version\": \"1.0.0\",\n      \"prefix\": \"/dashboard\"\n    }\n  index.html: |\n    &lt;!DOCTYPE html&gt;\n    &lt;html&gt;\n      &lt;head&gt;&lt;title&gt;Dashboard&lt;/title&gt;&lt;/head&gt;\n      &lt;body&gt;\n        &lt;h1&gt;Dashboard&lt;/h1&gt;\n        &lt;div id=\"app\"&gt;&lt;/div&gt;\n      &lt;/body&gt;\n    &lt;/html&gt;\n</code></pre></p>"},{"location":"guides/app-hosting/#deployment","title":"Deployment","text":"<p>deployment.yaml: <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: chapkit-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: chapkit-service\n  template:\n    metadata:\n      labels:\n        app: chapkit-service\n    spec:\n      containers:\n      - name: app\n        image: your-chapkit-app:latest\n        ports:\n        - containerPort: 8000\n        volumeMounts:\n        - name: dashboard-app\n          mountPath: /app/apps/dashboard\n          readOnly: true\n      volumes:\n      - name: dashboard-app\n        configMap:\n          name: dashboard-app\n</code></pre></p> <p>service.yaml: <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: chapkit-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    targetPort: 8000\n  selector:\n    app: chapkit-service\n</code></pre></p>"},{"location":"guides/app-hosting/#security","title":"Security","text":""},{"location":"guides/app-hosting/#path-traversal-protection","title":"Path Traversal Protection","text":"<p>Chapkit validates all paths and rejects path traversal attempts:</p> <pre><code># All rejected with ValueError\n.with_app(\"apps/../../etc\")                          # Prefix traversal\n.with_app((\"mypackage\", \"../../../etc\"))             # Package traversal\n\n# manifest.json with path traversal also rejected:\n{\n  \"prefix\": \"/../../admin\",     # Rejected\n  \"entry\": \"../../../passwd\"    # Rejected\n}\n</code></pre>"},{"location":"guides/app-hosting/#api-protection","title":"API Protection","text":"<p>API endpoints are protected from app conflicts:</p> <ol> <li>Apps cannot mount at <code>/api</code> or <code>/api/**</code></li> <li>Apps are mounted after routes, so API routes take precedence</li> <li>Static files never override API endpoints</li> </ol>"},{"location":"guides/app-hosting/#validation","title":"Validation","text":"<ul> <li>Build-time validation: All errors detected during <code>.build()</code> (fail fast)</li> <li>Manifest validation: Pydantic validates all fields and types</li> <li>File validation: Entry files must exist before mounting</li> <li>Prefix validation: Duplicate prefixes detected and logged</li> </ul>"},{"location":"guides/app-hosting/#best-practices","title":"Best Practices","text":""},{"location":"guides/app-hosting/#recommended-practices","title":"Recommended Practices","text":"<ul> <li>Separate apps directory: Keep apps in <code>./apps</code> outside source code</li> <li>Version apps: Use semantic versioning in manifest.json</li> <li>Test locally: Run <code>fastapi dev</code> before deploying</li> <li>Use package resources: For default/bundled apps in libraries</li> <li>Document prefixes: List all app URLs in README</li> <li>Keep apps small: Under 10MB per app for fast loading</li> <li>Use CDN for assets: For production apps with large assets</li> </ul>"},{"location":"guides/app-hosting/#avoid","title":"Avoid","text":"<ul> <li>Hardcoding paths: Use relative paths, not absolute</li> <li>Path traversal: Never use <code>..</code> in paths or prefixes</li> <li>Large binaries: Don't bundle videos/large files in apps</li> <li>Duplicate prefixes: Causes confusion (service logs warnings)</li> <li>API prefix conflicts: Never mount apps at <code>/api</code></li> <li>Missing manifest: All apps must have manifest.json</li> </ul>"},{"location":"guides/app-hosting/#app-organization","title":"App Organization","text":"<pre><code>apps/\n\u251c\u2500\u2500 dashboard/          # Main dashboard\n\u2502   \u251c\u2500\u2500 manifest.json\n\u2502   \u2514\u2500\u2500 index.html\n\u251c\u2500\u2500 admin/              # Admin panel\n\u2502   \u251c\u2500\u2500 manifest.json\n\u2502   \u2514\u2500\u2500 index.html\n\u2514\u2500\u2500 docs/               # Documentation site\n    \u251c\u2500\u2500 manifest.json\n    \u2514\u2500\u2500 index.html\n</code></pre>"},{"location":"guides/app-hosting/#combining-with-other-features","title":"Combining with Other Features","text":""},{"location":"guides/app-hosting/#with-authentication","title":"With Authentication","text":"<pre><code>app = (\n    BaseServiceBuilder(info=info)\n    .with_auth(\n        unauthenticated_paths=[\n            \"/health\",\n            \"/metrics\",\n            \"/\",           # Landing page (root app)\n            \"/docs\",       # API documentation\n        ]\n    )\n    .with_landing_page()    # Public landing page\n    .with_app(\"apps/admin\") # Admin panel (requires auth)\n    .build()\n)\n</code></pre>"},{"location":"guides/app-hosting/#with-system-endpoint","title":"With System Endpoint","text":"<p>Query installed apps programmatically:</p> <pre><code>app = (\n    BaseServiceBuilder(info=info)\n    .with_system()          # Enables /api/v1/system/apps\n    .with_apps(\"./apps\")\n    .build()\n)\n</code></pre> <p>Test: <pre><code>curl http://localhost:8000/api/v1/system/apps\n</code></pre></p> <p>Response: <pre><code>[\n  {\n    \"name\": \"Dashboard\",\n    \"version\": \"1.0.0\",\n    \"prefix\": \"/dashboard\",\n    \"description\": \"Interactive dashboard\",\n    \"author\": \"Your Name\",\n    \"entry\": \"index.html\",\n    \"is_package\": false\n  }\n]\n</code></pre></p>"},{"location":"guides/app-hosting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/app-hosting/#app-returns-404","title":"App Returns 404","text":"<p>Problem: Accessing <code>/dashboard/</code> returns 404.</p> <p>Solutions: 1. Verify app directory exists: <code>ls ./apps/dashboard</code> 2. Check manifest.json exists: <code>cat ./apps/dashboard/manifest.json</code> 3. Verify prefix matches URL: Check <code>\"prefix\"</code> field in manifest 4. Check service logs for mount messages:    <pre><code>app.mounted name=Dashboard prefix=/dashboard directory=./apps/dashboard\n</code></pre></p>"},{"location":"guides/app-hosting/#assets-not-loading","title":"Assets Not Loading","text":"<p>Problem: HTML loads but CSS/JS return 404.</p> <p>Solutions: 1. Check file paths in HTML are relative: <code>&lt;link href=\"style.css\"&gt;</code> not <code>&lt;link href=\"/style.css\"&gt;</code> 2. Verify assets exist in app directory: <code>ls ./apps/dashboard/</code> 3. Test asset URLs: <code>curl http://localhost:8000/dashboard/style.css</code></p>"},{"location":"guides/app-hosting/#manifest-validation-error","title":"Manifest Validation Error","text":"<p>Problem: Service fails with \"Invalid JSON in manifest.json\".</p> <p>Solutions: 1. Validate JSON syntax: <code>python -m json.tool manifest.json</code> 2. Check required fields: <code>name</code>, <code>version</code>, <code>prefix</code> 3. Check field types: <code>version</code> must be string, not number 4. Remove unknown fields (Pydantic rejects extras)</p>"},{"location":"guides/app-hosting/#app-not-discovered","title":"App Not Discovered","text":"<p>Problem: <code>.with_apps()</code> doesn't find the app.</p> <p>Solutions: 1. Verify directory structure: App must be in subdirectory with manifest.json 2. Check manifest.json is valid JSON 3. Review discovery logs for errors:    <pre><code>app.discovery.failed directory=./apps/broken error=\"Entry file 'index.html' not found\"\n</code></pre></p>"},{"location":"guides/app-hosting/#duplicate-prefix-warning","title":"Duplicate Prefix Warning","text":"<p>Problem: Seeing \"app.prefix.override\" warnings in logs.</p> <p>Solutions: 1. Check for multiple <code>.with_app()</code> calls with same prefix 2. Check multiple manifest.json files with same prefix 3. This is usually intentional (override), but verify it's expected</p>"},{"location":"guides/app-hosting/#api-endpoints-conflict","title":"API Endpoints Conflict","text":"<p>Problem: Cannot mount app because prefix conflicts with API.</p> <p>Solutions: 1. Use different prefix: <code>/admin</code> instead of <code>/api/admin</code> 2. API endpoints always take precedence (by design) 3. Mount apps at unique, non-API prefixes</p>"},{"location":"guides/app-hosting/#examples","title":"Examples","text":""},{"location":"guides/app-hosting/#basic-dashboard","title":"Basic Dashboard","text":"<p>apps/dashboard/manifest.json: <pre><code>{\n  \"name\": \"Dashboard\",\n  \"version\": \"1.0.0\",\n  \"prefix\": \"/dashboard\",\n  \"description\": \"Real-time metrics dashboard\"\n}\n</code></pre></p> <p>apps/dashboard/index.html: <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Dashboard&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"style.css\"&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Dashboard&lt;/h1&gt;\n    &lt;div id=\"metrics\"&gt;&lt;/div&gt;\n    &lt;script src=\"script.js\"&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre></p> <p>apps/dashboard/script.js: <pre><code>// Fetch data from your API\nfetch('/api/v1/configs')\n  .then(response =&gt; response.json())\n  .then(data =&gt; {\n    document.getElementById('metrics').innerHTML =\n      `&lt;pre&gt;${JSON.stringify(data, null, 2)}&lt;/pre&gt;`;\n  });\n</code></pre></p>"},{"location":"guides/app-hosting/#multi-app-service","title":"Multi-App Service","text":"<pre><code>from chapkit.core.api import BaseServiceBuilder, ServiceInfo\n\napp = (\n    BaseServiceBuilder(info=ServiceInfo(display_name=\"Multi-App Service\"))\n    .with_health()\n    .with_system()\n    .with_landing_page()           # Built-in landing at /\n    .with_apps(\"./apps\")           # Dashboard, admin, docs\n    .build()\n)\n</code></pre> <p>URLs: - <code>/</code> - Landing page - <code>/dashboard</code> - Main dashboard - <code>/admin</code> - Admin panel - <code>/docs</code> - API documentation - <code>/api/v1/*</code> - API endpoints</p>"},{"location":"guides/app-hosting/#next-steps","title":"Next Steps","text":"<ul> <li>SPA Support: Apps use <code>html=True</code> mode (serves index.html for directories)</li> <li>Custom Landing Page: Override built-in with <code>.with_app(..., prefix=\"/\")</code></li> <li>Package Apps: Distribute apps via PyPI with your library</li> <li>Authentication: Combine with <code>.with_auth()</code> for protected apps</li> </ul>"},{"location":"guides/app-hosting/#further-reading","title":"Further Reading","text":"<p>For more examples, see: - <code>examples/app_hosting_api.py</code> - Complete app hosting example - <code>examples/apps/sample-dashboard/</code> - Sample dashboard app - <code>designs/app-system.md</code> - Technical design document - <code>CLAUDE.md</code> - Development guide with app system section</p>"},{"location":"guides/authentication/","title":"Authentication","text":"<p>Chapkit provides simple API key authentication for service-to-service communication in Docker Compose and Kubernetes environments.</p>"},{"location":"guides/authentication/#quick-start","title":"Quick Start","text":""},{"location":"guides/authentication/#environment-variables-recommended-for-production","title":"Environment Variables (Recommended for Production)","text":"<p>The simplest and most secure approach for production deployments:</p> <pre><code>from chapkit.api import ServiceBuilder, ServiceInfo\n\napp = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"My Service\"))\n    .with_auth()  # Reads from CHAPKIT_API_KEYS environment variable\n    .with_config(MyConfig)\n    .build()\n)\n</code></pre> <p>Set the environment variable:</p> <pre><code>export CHAPKIT_API_KEYS=\"sk_prod_abc123,sk_prod_xyz789\"\nfastapi run your_file.py\n</code></pre>"},{"location":"guides/authentication/#docker-secrets-most-secure-for-production","title":"Docker Secrets (Most Secure for Production)","text":"<p>For Docker Swarm or Kubernetes deployments:</p> <pre><code>app = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"My Service\"))\n    .with_auth(api_key_file=\"/run/secrets/api_keys\")\n    .build()\n)\n</code></pre> <p>docker-compose.yml: <pre><code>version: '3.8'\n\nservices:\n  app:\n    image: your-app\n    secrets:\n      - api_keys\n\nsecrets:\n  api_keys:\n    file: ./secrets/api_keys.txt\n</code></pre></p> <p>secrets/api_keys.txt: <pre><code>sk_prod_abc123\nsk_prod_xyz789\n</code></pre></p>"},{"location":"guides/authentication/#direct-keys-development-only","title":"Direct Keys (Development Only)","text":"<p>WARNING: Never use this in production!</p> <pre><code>app = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"My Service\"))\n    .with_auth(api_keys=[\"sk_dev_test123\"])  # NOT for production\n    .build()\n)\n</code></pre>"},{"location":"guides/authentication/#configuration-options","title":"Configuration Options","text":"<p>The <code>.with_auth()</code> method accepts these parameters:</p> <pre><code>.with_auth(\n    api_keys=None,                      # Direct list (dev only)\n    api_key_file=None,                  # File path (Docker secrets)\n    env_var=\"CHAPKIT_API_KEYS\",         # Environment variable name\n    header_name=\"X-API-Key\",            # HTTP header for API key\n    unauthenticated_paths=None,         # Paths without auth\n)\n</code></pre>"},{"location":"guides/authentication/#priority","title":"Priority","text":"<p>Chapkit uses the first non-None value in this order: 1. <code>api_keys</code> (direct list) 2. <code>api_key_file</code> (file path) 3. <code>env_var</code> (environment variable, default: <code>CHAPKIT_API_KEYS</code>)</p>"},{"location":"guides/authentication/#parameters","title":"Parameters","text":"<ul> <li>api_keys (<code>List[str] | None</code>): Direct list of API keys. Only for examples and local development.</li> <li>api_key_file (<code>str | None</code>): Path to file containing keys (one per line). For Docker secrets.</li> <li>env_var (<code>str</code>): Environment variable name to read keys from. Default: <code>CHAPKIT_API_KEYS</code>.</li> <li>header_name (<code>str</code>): HTTP header name for API key. Default: <code>X-API-Key</code>.</li> <li>unauthenticated_paths (<code>List[str] | None</code>): Paths that don't require authentication.</li> </ul>"},{"location":"guides/authentication/#key-format-conventions","title":"Key Format Conventions","text":"<p>Recommended format: <code>sk_{environment}_{random}</code></p>"},{"location":"guides/authentication/#examples","title":"Examples","text":"<pre><code>sk_prod_a1b2c3d4e5f6g7h8     # Production\nsk_staging_x1y2z3a4b5c6d7e8  # Staging\nsk_dev_test123               # Development\n</code></pre>"},{"location":"guides/authentication/#why-this-format","title":"Why This Format?","text":"<ul> <li>sk_ prefix: Easily identifiable as a secret key</li> <li>environment: Know which environment the key belongs to</li> <li>random: Unique identifier (16+ characters recommended)</li> </ul> <p>Chapkit logs only the first 7 characters (<code>sk_prod_****</code>) for security.</p>"},{"location":"guides/authentication/#key-rotation","title":"Key Rotation","text":"<p>To rotate API keys without downtime:</p> <ol> <li>Add new key (keep old key active)</li> <li>Update clients to use new key</li> <li>Remove old key after all clients updated</li> </ol>"},{"location":"guides/authentication/#example-rotation","title":"Example Rotation","text":"<pre><code># Step 1: Both keys active\nexport CHAPKIT_API_KEYS=\"sk_prod_old123,sk_prod_new456\"\n\n# Deploy and verify service restarts\nfastapi run your_file.py\n\n# Step 2: Update all clients to use sk_prod_new456\n# Test that clients work with new key\n\n# Step 3: Remove old key (after confirming all clients updated)\nexport CHAPKIT_API_KEYS=\"sk_prod_new456\"\n\n# Restart service\nfastapi run your_file.py\n</code></pre>"},{"location":"guides/authentication/#unauthenticated-paths","title":"Unauthenticated Paths","text":"<p>By default, these paths don't require authentication:</p> <ul> <li><code>/docs</code> - Swagger UI</li> <li><code>/redoc</code> - ReDoc</li> <li><code>/openapi.json</code> - OpenAPI schema</li> <li><code>/health</code> - Health check</li> <li><code>/</code> - Landing page</li> </ul>"},{"location":"guides/authentication/#custom-unauthenticated-paths","title":"Custom Unauthenticated Paths","text":"<pre><code>.with_auth(\n    unauthenticated_paths=[\"/health\", \"/public\", \"/status\"]\n)\n</code></pre> <p>This replaces the default list. To add to the default list:</p> <pre><code>default_paths = [\"/docs\", \"/redoc\", \"/openapi.json\", \"/health\", \"/\"]\ncustom_paths = default_paths + [\"/public\", \"/status\"]\n\n.with_auth(unauthenticated_paths=custom_paths)\n</code></pre>"},{"location":"guides/authentication/#testing-authenticated-apis","title":"Testing Authenticated APIs","text":""},{"location":"guides/authentication/#with-curl","title":"With cURL","text":"<pre><code># Valid request\ncurl -H \"X-API-Key: sk_dev_test123\" http://localhost:8000/api/v1/configs\n\n# Missing key (returns 401)\ncurl http://localhost:8000/api/v1/configs\n\n# Invalid key (returns 401)\ncurl -H \"X-API-Key: invalid_key\" http://localhost:8000/api/v1/configs\n\n# Unauthenticated path (no key needed)\ncurl http://localhost:8000/health\n</code></pre>"},{"location":"guides/authentication/#with-python-requests","title":"With Python requests","text":"<pre><code>import requests\n\nheaders = {\"X-API-Key\": \"sk_dev_test123\"}\n\n# Authenticated request\nresponse = requests.get(\n    \"http://localhost:8000/api/v1/configs\",\n    headers=headers\n)\n\n# Check response\nassert response.status_code == 200\n</code></pre>"},{"location":"guides/authentication/#with-httpx-async","title":"With httpx (async)","text":"<pre><code>import httpx\n\nheaders = {\"X-API-Key\": \"sk_dev_test123\"}\n\nasync with httpx.AsyncClient() as client:\n    response = await client.get(\n        \"http://localhost:8000/api/v1/configs\",\n        headers=headers\n    )\n    assert response.status_code == 200\n</code></pre>"},{"location":"guides/authentication/#docker-deployment","title":"Docker Deployment","text":""},{"location":"guides/authentication/#docker-compose","title":"Docker Compose","text":"<p>docker-compose.yml: <pre><code>version: '3.8'\n\nservices:\n  chapkit-service:\n    image: your-chapkit-app\n    ports:\n      - \"8000:8000\"\n    environment:\n      # Option 1: Environment variable\n      CHAPKIT_API_KEYS: sk_prod_abc123,sk_prod_xyz789\n\n      # Option 2: Point to secrets file\n      # CHAPKIT_API_KEY_FILE: /run/secrets/api_keys\n\n    # Option 2 (continued): Mount secrets\n    # secrets:\n    #   - api_keys\n\n# secrets:\n#   api_keys:\n#     file: ./secrets/api_keys.txt\n</code></pre></p> <p>secrets/api_keys.txt: <pre><code># Production API keys\n# One key per line, comments allowed\nsk_prod_abc123\nsk_prod_xyz789\n</code></pre></p> <p>.gitignore: <pre><code># Never commit secrets!\nsecrets/api_keys.txt\n</code></pre></p> <p>secrets/api_keys.txt.example: <pre><code># Example API keys file\n# Copy to api_keys.txt and replace with real keys\nsk_prod_example1\nsk_prod_example2\n</code></pre></p>"},{"location":"guides/authentication/#docker-swarm","title":"Docker Swarm","text":"<pre><code># Create secret\necho -e \"sk_prod_abc123\\nsk_prod_xyz789\" | \\\n  docker secret create chapkit_api_keys -\n\n# Deploy service\ndocker service create \\\n  --name my-chapkit-service \\\n  --secret chapkit_api_keys \\\n  -e CHAPKIT_API_KEY_FILE=/run/secrets/chapkit_api_keys \\\n  -p 8000:8000 \\\n  your-chapkit-app\n</code></pre>"},{"location":"guides/authentication/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p>secret.yaml: <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: chapkit-api-keys\ntype: Opaque\nstringData:\n  api_keys.txt: |\n    sk_prod_abc123\n    sk_prod_xyz789\n</code></pre></p> <p>deployment.yaml: <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: chapkit-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: chapkit-service\n  template:\n    metadata:\n      labels:\n        app: chapkit-service\n    spec:\n      containers:\n      - name: app\n        image: your-chapkit-app\n        ports:\n        - containerPort: 8000\n        env:\n        - name: CHAPKIT_API_KEY_FILE\n          value: /etc/secrets/api_keys.txt\n        volumeMounts:\n        - name: api-keys\n          mountPath: /etc/secrets\n          readOnly: true\n      volumes:\n      - name: api-keys\n        secret:\n          secretName: chapkit-api-keys\n</code></pre></p>"},{"location":"guides/authentication/#logging","title":"Logging","text":"<p>Chapkit automatically logs authentication events with masked keys for security.</p>"},{"location":"guides/authentication/#successful-authentication","title":"Successful Authentication","text":"<pre><code>{\n  \"event\": \"auth.success\",\n  \"key_prefix\": \"sk_prod\",\n  \"path\": \"/api/v1/configs\"\n}\n</code></pre>"},{"location":"guides/authentication/#failed-authentication","title":"Failed Authentication","text":"<pre><code>{\n  \"event\": \"auth.invalid_key\",\n  \"key_prefix\": \"sk_unkn\",\n  \"path\": \"/api/v1/configs\",\n  \"method\": \"GET\"\n}\n</code></pre>"},{"location":"guides/authentication/#missing-key","title":"Missing Key","text":"<pre><code>{\n  \"event\": \"auth.missing_key\",\n  \"path\": \"/api/v1/configs\",\n  \"method\": \"GET\"\n}\n</code></pre> <p>Only the first 7 characters of keys are logged. Full keys are never logged.</p>"},{"location":"guides/authentication/#security-best-practices","title":"Security Best Practices","text":""},{"location":"guides/authentication/#recommended-practices","title":"Recommended Practices","text":"<ul> <li>Use environment variables or Docker secrets in production</li> <li>Use <code>sk_env_random</code> format for easy identification in logs</li> <li>Rotate keys regularly (quarterly recommended)</li> <li>Use different keys for different services/environments</li> <li>Keep <code>.env</code> files in <code>.gitignore</code></li> <li>Use minimum 16 characters for key randomness</li> <li>Monitor authentication logs for failed attempts</li> </ul>"},{"location":"guides/authentication/#avoid","title":"Avoid","text":"<ul> <li>Committing API keys to git (use <code>.gitignore</code>)</li> <li>Using <code>api_keys=</code> parameter in production (only for examples)</li> <li>Reusing keys across environments (dev/staging/prod)</li> <li>Using weak/short keys (minimum 16 characters)</li> <li>Sharing keys via email/Slack (use secrets management)</li> <li>Hardcoding keys in source code</li> </ul>"},{"location":"guides/authentication/#error-responses","title":"Error Responses","text":"<p>All authentication errors follow RFC 9457 Problem Details format.</p>"},{"location":"guides/authentication/#missing-api-key-401","title":"Missing API Key (401)","text":"<pre><code>{\n  \"type\": \"urn:chapkit:error:unauthorized\",\n  \"title\": \"Unauthorized\",\n  \"status\": 401,\n  \"detail\": \"Missing authentication header: X-API-Key\",\n  \"instance\": \"/api/v1/configs\"\n}\n</code></pre>"},{"location":"guides/authentication/#invalid-api-key-401","title":"Invalid API Key (401)","text":"<pre><code>{\n  \"type\": \"urn:chapkit:error:unauthorized\",\n  \"title\": \"Unauthorized\",\n  \"status\": 401,\n  \"detail\": \"Invalid API key\",\n  \"instance\": \"/api/v1/configs\"\n}\n</code></pre>"},{"location":"guides/authentication/#advanced-usage","title":"Advanced Usage","text":""},{"location":"guides/authentication/#custom-header-name","title":"Custom Header Name","text":"<pre><code>.with_auth(\n    header_name=\"X-Custom-API-Key\"\n)\n</code></pre> <p>Test with: <pre><code>curl -H \"X-Custom-API-Key: sk_dev_test123\" http://localhost:8000/api/v1/configs\n</code></pre></p>"},{"location":"guides/authentication/#multiple-environments","title":"Multiple Environments","text":"<p>Development: <pre><code># dev.py\n.with_auth(api_keys=[\"sk_dev_test123\"])\n</code></pre></p> <p>Production: <pre><code># prod.py\n.with_auth()  # Reads from CHAPKIT_API_KEYS env var\n</code></pre></p>"},{"location":"guides/authentication/#service-to-service-communication","title":"Service-to-Service Communication","text":"<pre><code># Service A (client)\nimport httpx\n\nheaders = {\"X-API-Key\": os.getenv(\"SERVICE_B_API_KEY\")}\nasync with httpx.AsyncClient() as client:\n    response = await client.get(\n        \"http://service-b:8000/api/v1/data\",\n        headers=headers\n    )\n\n# Service B (server)\napp = ServiceBuilder(info=info).with_auth().build()\n</code></pre>"},{"location":"guides/authentication/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/authentication/#no-api-keys-configured-error","title":"\"No API keys configured\" Error","text":"<p>Problem: Service fails to start with error message.</p> <p>Solution: Ensure you've provided keys via one of these methods: <pre><code># Environment variable\nexport CHAPKIT_API_KEYS=\"sk_dev_test123\"\n\n# Or in Python (dev only)\n.with_auth(api_keys=[\"sk_dev_test123\"])\n\n# Or via file\n.with_auth(api_key_file=\"/path/to/keys.txt\")\n</code></pre></p>"},{"location":"guides/authentication/#401-unauthorized-on-health-check","title":"401 Unauthorized on Health Check","text":"<p>Problem: Health check returns 401 instead of 200.</p> <p>Solution: Health checks are unauthenticated by default. If you customized <code>unauthenticated_paths</code>, add <code>/health</code> back:</p> <pre><code>.with_auth(\n    unauthenticated_paths=[\n        \"/docs\", \"/redoc\", \"/openapi.json\",\n        \"/health\",  # Add this\n        \"/\", \"/custom/path\"\n    ]\n)\n</code></pre>"},{"location":"guides/authentication/#keys-not-loading-from-file","title":"Keys Not Loading from File","text":"<p>Problem: <code>FileNotFoundError: API key file not found</code></p> <p>Solution: 1. Verify file path is absolute: <code>/run/secrets/api_keys</code> (not relative) 2. Check file exists: <code>ls -la /run/secrets/api_keys</code> 3. Verify container has access (Docker secrets mount at <code>/run/secrets/</code>)</p>"},{"location":"guides/authentication/#keys-not-loading-from-environment","title":"Keys Not Loading from Environment","text":"<p>Problem: \"No API keys found in CHAPKIT_API_KEYS\"</p> <p>Solution: 1. Verify env var is set: <code>echo $CHAPKIT_API_KEYS</code> 2. Check for typos in variable name 3. Ensure keys are comma-separated: <code>key1,key2,key3</code> 4. No spaces around commas: <code>sk_dev_1,sk_dev_2</code> (not <code>sk_dev_1, sk_dev_2</code>)</p>"},{"location":"guides/authentication/#next-steps","title":"Next Steps","text":"<ul> <li>ML Services: Combine with <code>.with_ml()</code> for authenticated ML endpoints</li> <li>Rate Limiting: See roadmap for per-key rate limiting (P2)</li> <li>Key Scoping: See roadmap for endpoint-specific keys (P2)</li> <li>Monitoring: Track authentication metrics with Prometheus (P1)</li> </ul> <p>For more examples, see: - <code>examples/auth_basic.py</code> - Basic authentication example - <code>CLAUDE.md</code> - Comprehensive development guide</p>"},{"location":"guides/health-checks/","title":"Health Checks and Monitoring","text":"<p>Chapkit provides comprehensive health check capabilities for service monitoring, including one-time health checks and continuous streaming for real-time monitoring.</p>"},{"location":"guides/health-checks/#quick-start","title":"Quick Start","text":"<p>Enable health checks in your service:</p> <pre><code>from chapkit.api import ServiceBuilder, ServiceInfo\n\napp = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"My Service\"))\n    .with_health()  # Enables /health endpoint\n    .build()\n)\n</code></pre> <p>Your service now exposes health endpoints at <code>/health</code> and <code>/health/$stream</code>.</p>"},{"location":"guides/health-checks/#endpoints","title":"Endpoints","text":""},{"location":"guides/health-checks/#one-time-health-check","title":"One-Time Health Check","text":"<p>Endpoint: <code>GET /health</code></p> <p>Returns current health status in a single response:</p> <pre><code>curl http://localhost:8000/health\n</code></pre> <p>Response: <pre><code>{\n  \"status\": \"healthy\"\n}\n</code></pre></p> <p>Use Cases: - Kubernetes liveness/readiness probes - Load balancer health checks - Manual health verification - CI/CD deployment validation</p>"},{"location":"guides/health-checks/#continuous-health-monitoring-sse","title":"Continuous Health Monitoring (SSE)","text":"<p>Endpoint: <code>GET /health/$stream</code></p> <p>Streams health status updates continuously using Server-Sent Events (SSE):</p> <pre><code># Stream with default 1.0s interval\ncurl -N http://localhost:8000/health/\\$stream\n\n# Stream with custom 2.0s interval\ncurl -N \"http://localhost:8000/health/\\$stream?poll_interval=2.0\"\n</code></pre> <p>Response Format (text/event-stream): <pre><code>data: {\"status\":\"healthy\"}\n\ndata: {\"status\":\"healthy\"}\n\ndata: {\"status\":\"healthy\"}\n</code></pre></p> <p>Query Parameters: - <code>poll_interval</code> (float): Seconds between health checks. Default: 1.0</p> <p>Use Cases: - Real-time dashboard monitoring - Continuous integration tests - Service health visualization - Alert detection systems - Development/debugging</p> <p>Note: Stream continues indefinitely until client disconnects. Use Ctrl+C to stop.</p>"},{"location":"guides/health-checks/#custom-health-checks","title":"Custom Health Checks","text":"<p>Add custom health checks to monitor specific subsystems:</p> <pre><code>from chapkit.api import ServiceBuilder, ServiceInfo\nfrom chapkit.core.api.routers.health import HealthState\n\nasync def check_database() -&gt; tuple[HealthState, str | None]:\n    \"\"\"Check database connectivity.\"\"\"\n    try:\n        # Test database connection\n        async with get_session() as session:\n            await session.execute(\"SELECT 1\")\n        return (HealthState.HEALTHY, None)\n    except Exception as e:\n        return (HealthState.UNHEALTHY, f\"Database error: {str(e)}\")\n\nasync def check_redis() -&gt; tuple[HealthState, str | None]:\n    \"\"\"Check Redis connectivity.\"\"\"\n    try:\n        # Test Redis connection\n        await redis_client.ping()\n        return (HealthState.HEALTHY, None)\n    except Exception as e:\n        return (HealthState.DEGRADED, f\"Redis unavailable: {str(e)}\")\n\napp = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"My Service\"))\n    .with_health(checks={\n        \"database\": check_database,\n        \"redis\": check_redis,\n    })\n    .build()\n)\n</code></pre> <p>Response with Custom Checks: <pre><code>{\n  \"status\": \"degraded\",\n  \"checks\": {\n    \"database\": {\n      \"state\": \"healthy\"\n    },\n    \"redis\": {\n      \"state\": \"degraded\",\n      \"message\": \"Redis unavailable: Connection refused\"\n    }\n  }\n}\n</code></pre></p>"},{"location":"guides/health-checks/#health-states","title":"Health States","text":"<ul> <li><code>healthy</code>: All checks passed, service fully operational</li> <li><code>degraded</code>: Some non-critical checks failed, service partially operational</li> <li><code>unhealthy</code>: Critical checks failed, service not operational</li> </ul> <p>Aggregation Logic: - Overall status = worst state among all checks - <code>unhealthy</code> &gt; <code>degraded</code> &gt; <code>healthy</code> - Exception in check = <code>unhealthy</code> with error message</p>"},{"location":"guides/health-checks/#kubernetes-integration","title":"Kubernetes Integration","text":""},{"location":"guides/health-checks/#liveness-and-readiness-probes","title":"Liveness and Readiness Probes","text":"<p>Use health checks for Kubernetes pod lifecycle management:</p> <p>deployment.yaml: <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: chapkit-service\nspec:\n  replicas: 3\n  template:\n    spec:\n      containers:\n      - name: app\n        image: your-chapkit-app\n        ports:\n        - containerPort: 8000\n\n        # Liveness probe - restart if unhealthy\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          failureThreshold: 3\n\n        # Readiness probe - remove from service if not ready\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 10\n          periodSeconds: 5\n          timeoutSeconds: 3\n          failureThreshold: 2\n</code></pre></p> <p>Best Practices: - Liveness: Checks if app is stuck/deadlocked (longer intervals, higher threshold) - Readiness: Checks if app can serve traffic (shorter intervals, lower threshold) - Use <code>/health</code> for both probes (not <code>/health/$stream</code>) - Set appropriate timeouts (3-5 seconds recommended)</p>"},{"location":"guides/health-checks/#service-mesh-integration","title":"Service Mesh Integration","text":"<p>For service meshes like Istio or Linkerd, health checks are used for traffic routing:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: chapkit-service\nspec:\n  host: chapkit-service\n  trafficPolicy:\n    outlierDetection:\n      consecutiveErrors: 5\n      interval: 30s\n      baseEjectionTime: 30s\n      maxEjectionPercent: 50\n      minHealthPercent: 40\n    connectionPool:\n      http:\n        http1MaxPendingRequests: 100\n        http2MaxRequests: 100\n</code></pre>"},{"location":"guides/health-checks/#python-client-examples","title":"Python Client Examples","text":""},{"location":"guides/health-checks/#one-time-health-check_1","title":"One-Time Health Check","text":"<pre><code>import httpx\n\nasync def check_service_health(base_url: str) -&gt; bool:\n    \"\"\"Check if service is healthy.\"\"\"\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"{base_url}/health\")\n        data = response.json()\n        return data[\"status\"] == \"healthy\"\n</code></pre>"},{"location":"guides/health-checks/#continuous-monitoring-with-sse","title":"Continuous Monitoring with SSE","text":"<pre><code>import httpx\nimport json\n\nasync def monitor_service_health(base_url: str, poll_interval: float = 1.0):\n    \"\"\"Monitor service health via SSE stream.\"\"\"\n    url = f\"{base_url}/health/$stream?poll_interval={poll_interval}\"\n\n    async with httpx.AsyncClient() as client:\n        async with client.stream(\"GET\", url) as response:\n            async for line in response.aiter_lines():\n                if line.startswith(\"data: \"):\n                    data = json.loads(line[6:])\n                    status = data[\"status\"]\n                    print(f\"Health: {status}\")\n\n                    if status != \"healthy\":\n                        # Alert or take action\n                        await send_alert(f\"Service unhealthy: {data}\")\n</code></pre>"},{"location":"guides/health-checks/#health-check-with-timeout","title":"Health Check with Timeout","text":"<pre><code>import httpx\nimport asyncio\n\nasync def health_check_with_timeout(base_url: str, timeout: float = 3.0) -&gt; str:\n    \"\"\"Check health with timeout.\"\"\"\n    try:\n        async with httpx.AsyncClient(timeout=timeout) as client:\n            response = await client.get(f\"{base_url}/health\")\n            response.raise_for_status()\n            data = response.json()\n            return data[\"status\"]\n    except httpx.TimeoutException:\n        return \"timeout\"\n    except Exception as e:\n        return f\"error: {str(e)}\"\n</code></pre>"},{"location":"guides/health-checks/#load-balancer-integration","title":"Load Balancer Integration","text":""},{"location":"guides/health-checks/#haproxy-configuration","title":"HAProxy Configuration","text":"<pre><code>backend chapkit_servers\n    balance roundrobin\n    option httpchk GET /health\n    http-check expect status 200\n    http-check expect string healthy\n\n    server app1 10.0.1.10:8000 check inter 5s rise 2 fall 3\n    server app2 10.0.1.11:8000 check inter 5s rise 2 fall 3\n    server app3 10.0.1.12:8000 check inter 5s rise 2 fall 3\n</code></pre>"},{"location":"guides/health-checks/#nginx-configuration","title":"NGINX Configuration","text":"<pre><code>upstream chapkit_backend {\n    server 10.0.1.10:8000 max_fails=3 fail_timeout=30s;\n    server 10.0.1.11:8000 max_fails=3 fail_timeout=30s;\n    server 10.0.1.12:8000 max_fails=3 fail_timeout=30s;\n}\n\nserver {\n    listen 80;\n\n    location /health {\n        proxy_pass http://chapkit_backend;\n        proxy_connect_timeout 2s;\n        proxy_read_timeout 5s;\n    }\n\n    location / {\n        proxy_pass http://chapkit_backend;\n        # Health check performed separately\n    }\n}\n</code></pre>"},{"location":"guides/health-checks/#monitoring-dashboards","title":"Monitoring Dashboards","text":""},{"location":"guides/health-checks/#grafana-dashboard-with-sse","title":"Grafana Dashboard with SSE","text":"<p>Create a custom panel using SSE streaming:</p> <pre><code>// Grafana panel plugin for SSE health monitoring\nconst eventSource = new EventSource('http://localhost:8000/health/$stream');\n\neventSource.onmessage = (event) =&gt; {\n  const data = JSON.parse(event.data);\n  updateHealthStatus(data.status);\n\n  if (data.checks) {\n    updateChecksTable(data.checks);\n  }\n};\n</code></pre>"},{"location":"guides/health-checks/#simple-html-dashboard","title":"Simple HTML Dashboard","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Service Health Monitor&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Service Health&lt;/h1&gt;\n    &lt;div id=\"status\"&gt;Connecting...&lt;/div&gt;\n    &lt;pre id=\"checks\"&gt;&lt;/pre&gt;\n\n    &lt;script&gt;\n        const eventSource = new EventSource('http://localhost:8000/health/$stream?poll_interval=2.0');\n\n        eventSource.onmessage = (event) =&gt; {\n            const data = JSON.parse(event.data);\n            const statusEl = document.getElementById('status');\n            const checksEl = document.getElementById('checks');\n\n            // Update status with color coding\n            statusEl.textContent = `Status: ${data.status}`;\n            statusEl.style.color = data.status === 'healthy' ? 'green' :\n                                   data.status === 'degraded' ? 'orange' : 'red';\n\n            // Show detailed checks\n            if (data.checks) {\n                checksEl.textContent = JSON.stringify(data.checks, null, 2);\n            }\n        };\n\n        eventSource.onerror = () =&gt; {\n            document.getElementById('status').textContent = 'Connection lost';\n            document.getElementById('status').style.color = 'red';\n        };\n    &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"guides/health-checks/#best-practices","title":"Best Practices","text":""},{"location":"guides/health-checks/#recommended-practices","title":"Recommended Practices","text":"<ul> <li>Enable in all services: Health checks are essential for production reliability</li> <li>Use custom checks: Monitor critical dependencies (database, cache, external APIs)</li> <li>Keep checks fast: Health checks should complete in &lt;1 second</li> <li>Avoid expensive operations: Don't run migrations, heavy queries, or external calls</li> <li>Use appropriate states: <code>degraded</code> for non-critical, <code>unhealthy</code> for critical failures</li> <li>SSE for dashboards: Use <code>/health/$stream</code> for real-time monitoring UIs</li> <li>One-time for probes: Use <code>/health</code> for Kubernetes and load balancers</li> <li>Unauthenticated: Keep health endpoints public for infrastructure access</li> </ul>"},{"location":"guides/health-checks/#avoid","title":"Avoid","text":"<ul> <li>Expensive checks: Heavy database queries, full table scans, complex computations</li> <li>External dependencies in liveness: Don't make liveness depend on external services</li> <li>High frequency polling: Don't poll <code>/health</code> more than once per second</li> <li>Authenticated health: Health endpoints should be unauthenticated for infrastructure</li> <li>Incomplete aggregation: Always include all critical subsystems in checks</li> </ul>"},{"location":"guides/health-checks/#combining-with-other-features","title":"Combining with Other Features","text":""},{"location":"guides/health-checks/#with-authentication","title":"With Authentication","text":"<p>Health endpoints should remain unauthenticated:</p> <pre><code>app = (\n    ServiceBuilder(info=info)\n    .with_health()\n    .with_auth(\n        unauthenticated_paths=[\n            \"/health\",        # Health check\n            \"/health/$stream\" # Health monitoring\n        ]\n    )\n    .build()\n)\n</code></pre>"},{"location":"guides/health-checks/#with-monitoring","title":"With Monitoring","text":"<p>Combine health checks with Prometheus metrics:</p> <pre><code>app = (\n    ServiceBuilder(info=info)\n    .with_health(checks={\"database\": check_database})\n    .with_monitoring()  # Prometheus metrics at /metrics\n    .build()\n)\n</code></pre> <p>Operational Endpoints: - <code>/health</code> - Kubernetes liveness/readiness (one-time) - <code>/health/$stream</code> - Real-time monitoring (continuous) - <code>/metrics</code> - Prometheus metrics (scraping)</p> <p>All operational endpoints use root-level paths for easy discovery.</p>"},{"location":"guides/health-checks/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/health-checks/#health-check-times-out","title":"Health Check Times Out","text":"<p>Problem: Health check takes too long or times out.</p> <p>Solution: 1. Review custom health check functions 2. Ensure checks complete in &lt;1 second 3. Remove expensive operations (heavy queries, external calls) 4. Use connection pooling for database checks</p>"},{"location":"guides/health-checks/#health-returns-unhealthy","title":"Health Returns Unhealthy","text":"<p>Problem: Service reports unhealthy but seems functional.</p> <p>Solution: 1. Check logs for health check errors 2. Review custom check implementations 3. Test dependencies manually (database, cache, APIs) 4. Verify network connectivity to dependencies</p>"},{"location":"guides/health-checks/#sse-stream-disconnects","title":"SSE Stream Disconnects","text":"<p>Problem: <code>/health/$stream</code> disconnects frequently.</p> <p>Solution: 1. Check nginx/proxy timeout settings 2. Increase client timeout 3. Verify network stability 4. Check for reverse proxy buffering (should be disabled)</p>"},{"location":"guides/health-checks/#kubernetes-pod-restarts","title":"Kubernetes Pod Restarts","text":"<p>Problem: Pods restart frequently due to liveness probe failures.</p> <p>Solution: 1. Increase <code>initialDelaySeconds</code> for slower startup 2. Increase <code>failureThreshold</code> to allow temporary failures 3. Increase <code>timeoutSeconds</code> for slower responses 4. Review health check performance</p>"},{"location":"guides/health-checks/#examples","title":"Examples","text":"<ul> <li><code>examples/monitoring_api.py</code> - Service with health checks and monitoring</li> <li><code>examples/docs/monitoring_api.postman_collection.json</code> - Postman collection with health endpoints</li> </ul>"},{"location":"guides/health-checks/#next-steps","title":"Next Steps","text":"<ul> <li>Metrics: Add Prometheus monitoring with <code>.with_monitoring()</code></li> <li>Alerting: Set up alerts based on health status</li> <li>Dashboards: Create real-time monitoring dashboards with SSE</li> <li>Custom Checks: Implement checks for your specific dependencies</li> </ul> <p>For related features, see: - Monitoring Guide - Prometheus metrics and OpenTelemetry - Job Scheduler Guide - Background job health monitoring</p>"},{"location":"guides/job-scheduler/","title":"Job Scheduler","text":"<p>Chapkit provides an async job scheduler for managing long-running tasks with real-time status monitoring via Server-Sent Events (SSE).</p>"},{"location":"guides/job-scheduler/#quick-start","title":"Quick Start","text":""},{"location":"guides/job-scheduler/#submit-a-job","title":"Submit a Job","text":"<pre><code># Start the example service\nfastapi dev examples/job_scheduler_sse_api.py\n\n# Submit a 30-second computation job and capture job ID\nJOB_ID=$(curl -s -X POST http://localhost:8000/api/v1/slow-compute \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"steps\": 30}' | jq -r '.job_id')\n\necho \"Job ID: $JOB_ID\"\n</code></pre> <p>Response: <pre><code>{\n  \"job_id\": \"01JQRS7X...\",\n  \"message\": \"Job submitted with 30 steps. Stream real-time status...\",\n  \"stream_url\": \"/api/v1/jobs/01JQRS7X.../$stream\"\n}\n</code></pre></p>"},{"location":"guides/job-scheduler/#monitor-job-status-real-time-sse","title":"Monitor Job Status (Real-Time SSE)","text":"<pre><code># Stream status updates in real-time\ncurl -N http://localhost:8000/api/v1/jobs/$JOB_ID/\\$stream\n</code></pre> <p>Output (streaming): <pre><code>data: {\"id\":\"01JQRS7X...\",\"status\":\"pending\",\"submitted_at\":\"2025-10-12T...\"}\n\ndata: {\"id\":\"01JQRS7X...\",\"status\":\"running\",\"started_at\":\"2025-10-12T...\"}\n\ndata: {\"id\":\"01JQRS7X...\",\"status\":\"completed\",\"finished_at\":\"2025-10-12T...\",\"artifact_id\":null}\n</code></pre></p> <p>Note: Use <code>-N</code> flag to disable cURL buffering for real-time streaming.</p>"},{"location":"guides/job-scheduler/#job-lifecycle","title":"Job Lifecycle","text":"<p>Jobs progress through these states:</p> <ol> <li>pending - Job submitted, waiting to start</li> <li>running - Job is currently executing</li> <li>completed - Job finished successfully</li> <li>failed - Job encountered an error</li> <li>canceled - Job was canceled by user</li> </ol>"},{"location":"guides/job-scheduler/#terminal-states","title":"Terminal States","text":"<p>These states indicate the job is finished: - <code>completed</code> - Success - <code>failed</code> - Error occurred - <code>canceled</code> - User canceled</p> <p>SSE streams automatically close when a terminal state is reached.</p>"},{"location":"guides/job-scheduler/#polling-vs-streaming","title":"Polling vs Streaming","text":""},{"location":"guides/job-scheduler/#traditional-polling","title":"Traditional Polling","text":"<pre><code># Client must repeatedly poll every second\nwhile true; do\n  curl http://localhost:8000/api/v1/jobs/01JQRS7X...\n  sleep 1\ndone\n</code></pre> <p>Problems: - Wastes bandwidth (repeated full HTTP requests) - Polling interval trade-off (fast = expensive, slow = delayed updates) - Client-side polling logic needed</p>"},{"location":"guides/job-scheduler/#sse-streaming","title":"SSE Streaming","text":"<pre><code># Server pushes updates automatically\ncurl -N http://localhost:8000/api/v1/jobs/01JQRS7X.../\\$stream\n</code></pre> <p>Benefits: - Efficient (single HTTP connection, server pushes updates) - Real-time (updates sent immediately when status changes) - Standard (W3C EventSource API built into browsers) - Simple (no client-side polling logic)</p>"},{"location":"guides/job-scheduler/#real-time-streaming-with-sse","title":"Real-Time Streaming with SSE","text":"<p>Server-Sent Events (SSE) provide efficient real-time updates over a single HTTP connection.</p>"},{"location":"guides/job-scheduler/#browser-javascript-eventsource-api","title":"Browser JavaScript (EventSource API)","text":"<pre><code>const jobId = \"01JQRS7X...\";\nconst eventSource = new EventSource(`/api/v1/jobs/${jobId}/$stream`);\n\neventSource.onmessage = (event) =&gt; {\n  const job = JSON.parse(event.data);\n  console.log(`Status: ${job.status}`);\n\n  // Update UI\n  document.getElementById('status').textContent = job.status;\n\n  // Close connection when done\n  if (['completed', 'failed', 'canceled'].includes(job.status)) {\n    console.log('Job finished');\n    eventSource.close();\n  }\n};\n\neventSource.onerror = (error) =&gt; {\n  console.error('SSE connection error:', error);\n  eventSource.close();\n};\n</code></pre>"},{"location":"guides/job-scheduler/#curl-command-line","title":"cURL (Command Line)","text":"<pre><code># Stream job status updates\ncurl -N http://localhost:8000/api/v1/jobs/01JQRS7X.../\\$stream\n\n# Custom poll interval (default: 0.5 seconds)\ncurl -N \"http://localhost:8000/api/v1/jobs/01JQRS7X.../\\$stream?poll_interval=1.0\"\n</code></pre> <p>Important: Use <code>-N</code> / <code>--no-buffer</code> flag to disable buffering and see real-time updates.</p>"},{"location":"guides/job-scheduler/#python-httpx","title":"Python (httpx)","text":"<pre><code>import httpx\nimport json\n\njob_id = \"01JQRS7X...\"\nurl = f\"http://localhost:8000/api/v1/jobs/{job_id}/$stream\"\n\nwith httpx.stream(\"GET\", url) as response:\n    for line in response.iter_lines():\n        if line.startswith(\"data: \"):\n            data = line[6:]  # Remove \"data: \" prefix\n            job = json.loads(data)\n            print(f\"Status: {job['status']}\")\n\n            # Stop when terminal state reached\n            if job['status'] in ['completed', 'failed', 'canceled']:\n                break\n</code></pre>"},{"location":"guides/job-scheduler/#python-requests-not-recommended","title":"Python (requests - Not Recommended)","text":"<p>The <code>requests</code> library buffers responses by default, making it unsuitable for SSE. Use <code>httpx</code> instead.</p>"},{"location":"guides/job-scheduler/#configuration","title":"Configuration","text":""},{"location":"guides/job-scheduler/#servicebuilder-setup","title":"ServiceBuilder Setup","text":"<pre><code>from chapkit.api import ServiceBuilder, ServiceInfo\n\napp = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"My Service\"))\n    .with_jobs(max_concurrency=5)  # Limit concurrent jobs\n    .build()\n)\n</code></pre> <p>Parameters: - <code>max_concurrency</code> (<code>int | None</code>): Maximum concurrent jobs. <code>None</code> = unlimited.</p>"},{"location":"guides/job-scheduler/#sse-poll-interval","title":"SSE Poll Interval","text":"<p>The SSE endpoint polls the scheduler internally at configurable intervals:</p> <pre><code># Default: 0.5 seconds\ncurl -N http://localhost:8000/api/v1/jobs/01JQRS.../\\$stream\n\n# Custom: 1.0 second\ncurl -N \"http://localhost:8000/api/v1/jobs/01JQRS.../\\$stream?poll_interval=1.0\"\n</code></pre> <p>Recommendations: - Development: 0.5s (default) - good balance - Production: 1.0s - reduces server load - High-frequency: 0.1s - near real-time (use sparingly)</p>"},{"location":"guides/job-scheduler/#api-reference","title":"API Reference","text":""},{"location":"guides/job-scheduler/#post-apiv1jobs","title":"POST /api/v1/jobs","text":"<p>Not exposed directly. Submit jobs via custom endpoints (e.g., <code>/api/v1/slow-compute</code>).</p>"},{"location":"guides/job-scheduler/#get-apiv1jobs","title":"GET /api/v1/jobs","text":"<p>List all jobs with optional status filtering.</p> <pre><code># List all jobs\ncurl http://localhost:8000/api/v1/jobs\n\n# Filter by status\ncurl http://localhost:8000/api/v1/jobs?status_filter=completed\n</code></pre>"},{"location":"guides/job-scheduler/#get-apiv1jobsjob_id","title":"GET /api/v1/jobs/{job_id}","text":"<p>Get job status and details (single request).</p> <pre><code>curl http://localhost:8000/api/v1/jobs/01JQRS7X...\n</code></pre> <p>Response: <pre><code>{\n  \"id\": \"01JQRS7X...\",\n  \"status\": \"running\",\n  \"submitted_at\": \"2025-10-12T15:30:00Z\",\n  \"started_at\": \"2025-10-12T15:30:01Z\",\n  \"finished_at\": null,\n  \"error\": null,\n  \"artifact_id\": null\n}\n</code></pre></p>"},{"location":"guides/job-scheduler/#get-apiv1jobsjob_idstream","title":"GET /api/v1/jobs/{job_id}/$stream","text":"<p>Stream real-time job status updates via Server-Sent Events.</p> <p>Query Parameters: - <code>poll_interval</code> (float, default: 0.5): Seconds between status checks</p> <p>Response Format: <pre><code>Content-Type: text/event-stream\nCache-Control: no-cache\nConnection: keep-alive\n\ndata: {\"id\":\"...\",\"status\":\"pending\",...}\n\ndata: {\"id\":\"...\",\"status\":\"running\",...}\n\ndata: {\"id\":\"...\",\"status\":\"completed\",...}\n</code></pre></p> <p>Connection closes automatically when job reaches terminal state.</p>"},{"location":"guides/job-scheduler/#delete-apiv1jobsjob_id","title":"DELETE /api/v1/jobs/{job_id}","text":"<p>Cancel and delete a job.</p> <pre><code>curl -X DELETE http://localhost:8000/api/v1/jobs/01JQRS7X...\n</code></pre> <p>Returns <code>204 No Content</code> on success.</p>"},{"location":"guides/job-scheduler/#error-handling","title":"Error Handling","text":""},{"location":"guides/job-scheduler/#invalid-job-id-400","title":"Invalid Job ID (400)","text":"<pre><code>{\n  \"detail\": \"Invalid job ID format\"\n}\n</code></pre>"},{"location":"guides/job-scheduler/#job-not-found-404","title":"Job Not Found (404)","text":"<pre><code>{\n  \"detail\": \"Job not found\"\n}\n</code></pre>"},{"location":"guides/job-scheduler/#failed-jobs","title":"Failed Jobs","text":"<p>When a job fails, the <code>error</code> field contains the error message:</p> <pre><code>{\n  \"id\": \"01JQRS7X...\",\n  \"status\": \"failed\",\n  \"error\": \"ValueError: Invalid input\",\n  \"error_traceback\": \"Traceback (most recent call last):\\n...\"\n}\n</code></pre>"},{"location":"guides/job-scheduler/#job-deletion-during-streaming","title":"Job Deletion During Streaming","text":"<p>If a job is deleted while being streamed, the SSE connection sends a final event and closes:</p> <pre><code>data: {\"status\": \"deleted\"}\n</code></pre>"},{"location":"guides/job-scheduler/#testing","title":"Testing","text":""},{"location":"guides/job-scheduler/#manual-testing","title":"Manual Testing","text":"<p>Terminal 1: Start service <pre><code>fastapi dev examples/job_scheduler_sse_api.py\n</code></pre></p> <p>Terminal 2: Submit job and stream status <pre><code># Submit job and capture job ID\nJOB_ID=$(curl -s -X POST http://localhost:8000/api/v1/slow-compute \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"steps\": 30}' | jq -r '.job_id')\n\necho \"Job ID: $JOB_ID\"\n\n# Stream status updates in real-time\ncurl -N http://localhost:8000/api/v1/jobs/$JOB_ID/\\$stream\n</code></pre></p>"},{"location":"guides/job-scheduler/#browser-testing","title":"Browser Testing","text":"<ol> <li>Submit job via Swagger UI: http://localhost:8000/docs</li> <li>Open browser console (F12)</li> <li>Run JavaScript:</li> </ol> <pre><code>const jobId = \"01JQRS7X...\";  // From Swagger response\nconst es = new EventSource(`/api/v1/jobs/${jobId}/$stream`);\nes.onmessage = (e) =&gt; console.log(JSON.parse(e.data));\n</code></pre>"},{"location":"guides/job-scheduler/#production-deployment","title":"Production Deployment","text":""},{"location":"guides/job-scheduler/#concurrency-limits","title":"Concurrency Limits","text":"<p>Set <code>max_concurrency</code> to prevent resource exhaustion:</p> <pre><code>.with_jobs(max_concurrency=10)  # Max 10 concurrent jobs\n</code></pre> <p>Recommendations: - CPU-bound jobs: Set to number of CPU cores - I/O-bound jobs: Higher limits OK (10-50) - Memory-intensive: Lower limits to prevent OOM</p>"},{"location":"guides/job-scheduler/#load-balancers-and-proxies","title":"Load Balancers and Proxies","text":"<p>SSE requires special configuration for long-lived connections.</p> <p>nginx: <pre><code>location /api/v1/jobs {\n    proxy_pass http://backend;\n    proxy_buffering off;  # Required for SSE\n    proxy_read_timeout 600s;  # Allow long connections\n    proxy_http_version 1.1;\n}\n</code></pre></p> <p>Apache: <pre><code>&lt;Location /api/v1/jobs&gt;\n    ProxyPass http://backend\n    ProxyPassReverse http://backend\n    ProxyPreserveHost On\n    SetEnv proxy-nokeepalive 1\n&lt;/Location&gt;\n</code></pre></p> <p>AWS ALB: - Enable HTTP/2 (supports SSE) - Set idle timeout \u2265 60 seconds</p>"},{"location":"guides/job-scheduler/#monitoring","title":"Monitoring","text":"<p>Track job metrics:</p> <pre><code># Example: Prometheus metrics\nfrom prometheus_client import Counter, Histogram\n\njob_submissions = Counter('jobs_submitted_total', 'Total jobs submitted')\njob_duration = Histogram('job_duration_seconds', 'Job execution time')\n</code></pre>"},{"location":"guides/job-scheduler/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/job-scheduler/#stream-closes-immediately","title":"Stream Closes Immediately","text":"<p>Problem: SSE connection closes right after opening.</p> <p>Causes: 1. Job already in terminal state 2. Invalid job ID</p> <p>Solution: <pre><code># Check job status first\ncurl http://localhost:8000/api/v1/jobs/01JQRS7X...\n\n# If completed/failed/canceled, stream will close immediately\n</code></pre></p>"},{"location":"guides/job-scheduler/#no-updates-appearing","title":"No Updates Appearing","text":"<p>Problem: Connected but no events streaming.</p> <p>Causes: 1. cURL buffering enabled 2. Proxy buffering responses</p> <p>Solution: <pre><code># Use -N flag with cURL\ncurl -N http://localhost:8000/api/v1/jobs/01JQRS7X.../\\$stream\n\n# Check proxy configuration (see Production Deployment)\n</code></pre></p>"},{"location":"guides/job-scheduler/#eventsource-not-working-in-browser","title":"EventSource Not Working in Browser","text":"<p>Problem: JavaScript EventSource API fails or doesn't connect.</p> <p>Causes: 1. CORS issues 2. HTTPS mixed content (HTTPS page, HTTP EventSource) 3. Ad blockers</p> <p>Solution: <pre><code>// Check for errors\nconst es = new EventSource('/api/v1/jobs/01JQRS.../$stream');\nes.onerror = (e) =&gt; {\n  console.error('EventSource error:', e);\n  console.log('ReadyState:', es.readyState);  // 0=connecting, 1=open, 2=closed\n};\n\n// CORS: Ensure same origin or proper CORS headers\n// HTTPS: Use HTTPS for both page and EventSource\n// Ad blockers: Disable and test\n</code></pre></p>"},{"location":"guides/job-scheduler/#high-cpu-usage","title":"High CPU Usage","text":"<p>Problem: Scheduler consuming excessive CPU.</p> <p>Causes: 1. Too many concurrent jobs 2. Short poll_interval with many streams</p> <p>Solution: <pre><code># Limit concurrent jobs\n.with_jobs(max_concurrency=10)\n</code></pre></p> <pre><code># Increase poll interval\ncurl -N \"http://localhost:8000/api/v1/jobs/01JQRS.../\\$stream?poll_interval=1.0\"\n</code></pre>"},{"location":"guides/job-scheduler/#examples","title":"Examples","text":""},{"location":"guides/job-scheduler/#complete-workflow","title":"Complete Workflow","text":"<pre><code># 1. Submit job and extract job_id\nJOB_ID=$(curl -s -X POST http://localhost:8000/api/v1/slow-compute \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"steps\": 30}' | jq -r '.job_id')\n\necho \"Job ID: $JOB_ID\"\n\n# 2. Stream status updates in real-time\ncurl -N http://localhost:8000/api/v1/jobs/$JOB_ID/\\$stream\n</code></pre>"},{"location":"guides/job-scheduler/#react-component","title":"React Component","text":"<pre><code>import { useEffect, useState } from 'react';\n\nfunction JobStatus({ jobId }) {\n  const [job, setJob] = useState(null);\n\n  useEffect(() =&gt; {\n    const eventSource = new EventSource(`/api/v1/jobs/${jobId}/$stream`);\n\n    eventSource.onmessage = (event) =&gt; {\n      const jobData = JSON.parse(event.data);\n      setJob(jobData);\n\n      // Close when finished\n      if (['completed', 'failed', 'canceled'].includes(jobData.status)) {\n        eventSource.close();\n      }\n    };\n\n    eventSource.onerror = () =&gt; {\n      eventSource.close();\n    };\n\n    return () =&gt; eventSource.close();\n  }, [jobId]);\n\n  return (\n    &lt;div&gt;\n      &lt;h3&gt;Job {jobId}&lt;/h3&gt;\n      &lt;p&gt;Status: {job?.status || 'connecting...'}&lt;/p&gt;\n      {job?.error &amp;&amp; &lt;p className=\"error\"&gt;{job.error}&lt;/p&gt;}\n    &lt;/div&gt;\n  );\n}\n</code></pre>"},{"location":"guides/job-scheduler/#vue-component","title":"Vue Component","text":"<pre><code>&lt;template&gt;\n  &lt;div&gt;\n    &lt;h3&gt;Job {{ jobId }}&lt;/h3&gt;\n    &lt;p&gt;Status: {{ job?.status || 'connecting...' }}&lt;/p&gt;\n    &lt;p v-if=\"job?.error\" class=\"error\"&gt;{{ job.error }}&lt;/p&gt;\n  &lt;/div&gt;\n&lt;/template&gt;\n\n&lt;script setup&gt;\nimport { ref, onMounted, onUnmounted } from 'vue';\n\nconst props = defineProps(['jobId']);\nconst job = ref(null);\nlet eventSource;\n\nonMounted(() =&gt; {\n  eventSource = new EventSource(`/api/v1/jobs/${props.jobId}/$stream`);\n\n  eventSource.onmessage = (event) =&gt; {\n    const jobData = JSON.parse(event.data);\n    job.value = jobData;\n\n    if (['completed', 'failed', 'canceled'].includes(jobData.status)) {\n      eventSource.close();\n    }\n  };\n});\n\nonUnmounted(() =&gt; {\n  eventSource?.close();\n});\n&lt;/script&gt;\n</code></pre>"},{"location":"guides/job-scheduler/#next-steps","title":"Next Steps","text":"<ul> <li>ML Workflows: Combine with <code>.with_ml()</code> for training jobs</li> <li>Task Execution: Use with <code>.with_tasks()</code> for script execution</li> <li>Artifact Storage: Jobs can return ULIDs to link results</li> </ul> <p>For more examples: - <code>examples/job_scheduler_api.py</code> - Basic job scheduler - <code>examples/job_scheduler_sse_api.py</code> - SSE streaming (30s job) - <code>examples/task_execution_api.py</code> - Task execution with jobs</p>"},{"location":"guides/ml-workflows/","title":"ML Workflows","text":"<p>Chapkit provides a complete ML workflow system for training models and making predictions with artifact-based model storage, job scheduling, and hierarchical model lineage tracking.</p>"},{"location":"guides/ml-workflows/#quick-start","title":"Quick Start","text":""},{"location":"guides/ml-workflows/#functional-approach-recommended-for-simple-models","title":"Functional Approach (Recommended for Simple Models)","text":"<pre><code>from chapkit import BaseConfig\nfrom chapkit.api import MLServiceBuilder, MLServiceInfo\nfrom chapkit.modules.artifact import ArtifactHierarchy\nfrom chapkit.modules.ml import FunctionalModelRunner\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\nclass ModelConfig(BaseConfig):\n    pass\n\nasync def on_train(config: ModelConfig, data: pd.DataFrame, geo=None):\n    X = data[[\"feature1\", \"feature2\"]]\n    y = data[\"target\"]\n    model = LinearRegression()\n    model.fit(X, y)\n    return model\n\nasync def on_predict(config: ModelConfig, model, historic, future, geo=None):\n    X = future[[\"feature1\", \"feature2\"]]\n    future[\"sample_0\"] = model.predict(X)\n    return future\n\nrunner = FunctionalModelRunner(on_train=on_train, on_predict=on_predict)\n\napp = (\n    MLServiceBuilder(\n        info=MLServiceInfo(display_name=\"My ML Service\"),\n        config_schema=ModelConfig,\n        hierarchy=ArtifactHierarchy(name=\"ml\", level_labels={0: \"model\", 1: \"predictions\"}),\n        runner=runner,\n    )\n    .build()\n)\n</code></pre> <p>Run: <code>fastapi dev your_file.py</code></p>"},{"location":"guides/ml-workflows/#class-based-approach-recommended-for-complex-models","title":"Class-Based Approach (Recommended for Complex Models)","text":"<pre><code>from chapkit.modules.ml import BaseModelRunner\nfrom sklearn.preprocessing import StandardScaler\n\nclass CustomModelRunner(BaseModelRunner):\n    def __init__(self):\n        self.scaler = StandardScaler()\n\n    async def on_train(self, config, data, geo=None):\n        X = data[[\"feature1\", \"feature2\"]]\n        y = data[\"target\"]\n\n        X_scaled = self.scaler.fit_transform(X)\n        model = LinearRegression()\n        model.fit(X_scaled, y)\n\n        return {\"model\": model, \"scaler\": self.scaler}\n\n    async def on_predict(self, config, model, historic, future, geo=None):\n        X = future[[\"feature1\", \"feature2\"]]\n        X_scaled = model[\"scaler\"].transform(X)\n        future[\"sample_0\"] = model[\"model\"].predict(X_scaled)\n        return future\n\nrunner = CustomModelRunner()\n# Use same MLServiceBuilder setup as above\n</code></pre>"},{"location":"guides/ml-workflows/#shell-based-approach-language-agnostic","title":"Shell-Based Approach (Language-Agnostic)","text":"<pre><code>from chapkit.modules.ml import ShellModelRunner\nimport sys\n\ntrain_command = (\n    f\"{sys.executable} scripts/train.py \"\n    \"--config {config_file} --data {data_file} --model {model_file}\"\n)\n\npredict_command = (\n    f\"{sys.executable} scripts/predict.py \"\n    \"--config {config_file} --model {model_file} \"\n    \"--future {future_file} --output {output_file}\"\n)\n\nrunner = ShellModelRunner(\n    train_command=train_command,\n    predict_command=predict_command,\n    model_format=\"pickle\"\n)\n# Use same MLServiceBuilder setup as above\n</code></pre>"},{"location":"guides/ml-workflows/#architecture","title":"Architecture","text":""},{"location":"guides/ml-workflows/#trainpredict-flow","title":"Train/Predict Flow","text":"<pre><code>1. TRAIN                           2. PREDICT\n   POST /api/v1/ml/$train             POST /api/v1/ml/$predict\n   \u251c\u2500&gt; Submit job                     \u251c\u2500&gt; Load trained model artifact\n   \u251c\u2500&gt; Load config                    \u251c\u2500&gt; Load config\n   \u251c\u2500&gt; Execute runner.on_train()      \u251c\u2500&gt; Execute runner.on_predict()\n   \u2514\u2500&gt; Store model in artifact        \u2514\u2500&gt; Store predictions in artifact\n       (level 0, parent_id=None)           (level 1, parent_id=model_id)\n</code></pre>"},{"location":"guides/ml-workflows/#artifact-hierarchy","title":"Artifact Hierarchy","text":"<pre><code>Config\n  \u2514\u2500&gt; Trained Model (level 0)\n       \u251c\u2500&gt; Predictions 1 (level 1)\n       \u251c\u2500&gt; Predictions 2 (level 1)\n       \u2514\u2500&gt; Predictions 3 (level 1)\n</code></pre> <p>Benefits: - Complete model lineage tracking - Multiple predictions from same model - Config linked to all model artifacts - Immutable model versioning</p>"},{"location":"guides/ml-workflows/#job-scheduling","title":"Job Scheduling","text":"<p>All train/predict operations are asynchronous: - Submit returns immediately with <code>job_id</code> and <code>artifact_id</code> - Monitor progress via Job API or SSE streaming - Results stored in artifacts when complete</p>"},{"location":"guides/ml-workflows/#model-runners","title":"Model Runners","text":""},{"location":"guides/ml-workflows/#basemodelrunner","title":"BaseModelRunner","text":"<p>Abstract base class for custom model runners with lifecycle hooks.</p> <pre><code>from chapkit.modules.ml import BaseModelRunner\n\nclass MyRunner(BaseModelRunner):\n    async def on_init(self):\n        \"\"\"Called before train or predict (optional).\"\"\"\n        pass\n\n    async def on_cleanup(self):\n        \"\"\"Called after train or predict (optional).\"\"\"\n        pass\n\n    async def on_train(self, config, data, geo=None):\n        \"\"\"Train and return model (must be pickleable).\"\"\"\n        # Your training logic\n        return trained_model\n\n    async def on_predict(self, config, model, historic, future, geo=None):\n        \"\"\"Make predictions and return DataFrame.\"\"\"\n        # Your prediction logic\n        return predictions_df\n</code></pre> <p>Key Points: - Model must be pickleable (stored in artifact) - Return value from <code>on_train</code> is passed to <code>on_predict</code> as <code>model</code> parameter - <code>historic</code> parameter is required (must be provided, can be empty DataFrame) - GeoJSON support via <code>geo</code> parameter</p>"},{"location":"guides/ml-workflows/#functionalmodelrunner","title":"FunctionalModelRunner","text":"<p>Wraps train/predict functions for functional-style ML workflows.</p> <pre><code>from chapkit.modules.ml import FunctionalModelRunner\n\nasync def train_fn(config, data, geo=None):\n    # Training logic\n    return model\n\nasync def predict_fn(config, model, historic, future, geo=None):\n    # Prediction logic\n    return predictions\n\nrunner = FunctionalModelRunner(on_train=train_fn, on_predict=predict_fn)\n</code></pre> <p>Use Cases: - Simple models without state - Quick prototypes - Pure function workflows</p>"},{"location":"guides/ml-workflows/#shellmodelrunner","title":"ShellModelRunner","text":"<p>Executes external scripts for language-agnostic ML workflows.</p> <pre><code>from chapkit.modules.ml import ShellModelRunner\n\nrunner = ShellModelRunner(\n    train_command=\"python train.py --config {config_file} --data {data_file} --model {model_file}\",\n    predict_command=\"python predict.py --config {config_file} --model {model_file} --future {future_file} --output {output_file}\",\n    model_format=\"pickle\"  # or \"joblib\", \"json\", etc.\n)\n</code></pre> <p>Variable Substitution: - <code>{config_file}</code> - JSON config file - <code>{data_file}</code> - Training data CSV - <code>{model_file}</code> - Model file (format specified) - <code>{future_file}</code> - Future data CSV - <code>{historic_file}</code> - Historic data CSV (required) - <code>{output_file}</code> - Predictions output CSV - <code>{geo_file}</code> - GeoJSON file (if provided)</p> <p>Script Requirements: - Training script: Read data/config, train model, save model to <code>{model_file}</code> - Prediction script: Read model/data/config, make predictions, save to <code>{output_file}</code> - Exit code 0 on success, non-zero on failure - Use stderr for logging</p> <p>Example Training Script (Python): <pre><code>#!/usr/bin/env python3\nimport argparse, json, pickle\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--config\", required=True)\nparser.add_argument(\"--data\", required=True)\nparser.add_argument(\"--model\", required=True)\nargs = parser.parse_args()\n\n# Load config\nwith open(args.config) as f:\n    config = json.load(f)\n\n# Load data\ndata = pd.read_csv(args.data)\n\n# Train\nX = data[[\"feature1\", \"feature2\"]]\ny = data[\"target\"]\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Save\nwith open(args.model, \"wb\") as f:\n    pickle.dump(model, f)\n</code></pre></p> <p>Use Cases: - Integration with R, Julia, or other languages - Legacy scripts without modification - Containerized ML pipelines - Team collaboration across languages</p>"},{"location":"guides/ml-workflows/#servicebuilder-setup","title":"ServiceBuilder Setup","text":""},{"location":"guides/ml-workflows/#mlservicebuilder-recommended","title":"MLServiceBuilder (Recommended)","text":"<p>Bundles health, config, artifacts, jobs, and ML in one builder.</p> <pre><code>from chapkit.api import MLServiceBuilder, MLServiceInfo, AssessedStatus\nfrom chapkit.modules.artifact import ArtifactHierarchy\n\ninfo = MLServiceInfo(\n    display_name=\"Disease Prediction Service\",\n    version=\"1.0.0\",\n    summary=\"ML service for disease prediction\",\n    description=\"Train and predict disease cases using weather data\",\n    author=\"ML Team\",\n    author_assessed_status=AssessedStatus.green,\n    contact_email=\"ml-team@example.com\",\n)\n\nhierarchy = ArtifactHierarchy(\n    name=\"ml_pipeline\",\n    level_labels={0: \"trained_model\", 1: \"predictions\"},\n)\n\napp = (\n    MLServiceBuilder(\n        info=info,\n        config_schema=ModelConfig,\n        hierarchy=hierarchy,\n        runner=runner,\n    )\n    .with_monitoring()  # Optional: Prometheus metrics\n    .build()\n)\n</code></pre> <p>MLServiceBuilder automatically includes: - Health check (<code>/health</code>) - Config CRUD (<code>/api/v1/configs</code>) - Artifact CRUD (<code>/api/v1/artifacts</code>) - Job scheduler (<code>/api/v1/jobs</code>) with concurrency control - ML endpoints (<code>/api/v1/ml/$train</code>, <code>/api/v1/ml/$predict</code>)</p>"},{"location":"guides/ml-workflows/#servicebuilder-manual-configuration","title":"ServiceBuilder (Manual Configuration)","text":"<p>For fine-grained control:</p> <pre><code>from chapkit.api import ServiceBuilder, ServiceInfo\n\napp = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"Custom ML Service\"))\n    .with_health()\n    .with_config(ModelConfig)\n    .with_artifacts(hierarchy=hierarchy)\n    .with_jobs(max_concurrency=3)\n    .with_ml(runner=runner)\n    .build()\n)\n</code></pre> <p>Requirements: - <code>.with_config()</code> must be called before <code>.with_ml()</code> - <code>.with_artifacts()</code> must be called before <code>.with_ml()</code> - <code>.with_jobs()</code> must be called before <code>.with_ml()</code></p>"},{"location":"guides/ml-workflows/#configuration-options","title":"Configuration Options","text":"<pre><code>MLServiceBuilder(\n    info=info,\n    config_schema=YourConfig,\n    hierarchy=hierarchy,\n    runner=runner,\n    max_concurrency=5,       # Limit concurrent jobs (default: unlimited)\n    database_url=\"ml.db\",    # Persistent storage (default: in-memory)\n)\n</code></pre>"},{"location":"guides/ml-workflows/#api-reference","title":"API Reference","text":""},{"location":"guides/ml-workflows/#post-apiv1mltrain","title":"POST /api/v1/ml/$train","text":"<p>Train a model asynchronously.</p> <p>Request: <pre><code>{\n  \"config_id\": \"01JCONFIG...\",\n  \"data\": {\n    \"columns\": [\"feature1\", \"feature2\", \"target\"],\n    \"data\": [\n      [1.0, 2.0, 10.0],\n      [2.0, 3.0, 15.0],\n      [3.0, 4.0, 20.0]\n    ]\n  },\n  \"geo\": null\n}\n</code></pre></p> <p>Response (202 Accepted): <pre><code>{\n  \"job_id\": \"01JOB123...\",\n  \"model_artifact_id\": \"01MODEL456...\",\n  \"message\": \"Training job submitted. Job ID: 01JOB123...\"\n}\n</code></pre></p> <p>cURL Example: <pre><code># Create config first\nCONFIG_ID=$(curl -s -X POST http://localhost:8000/api/v1/configs \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"my_config\", \"data\": {}}' | jq -r '.id')\n\n# Submit training job\ncurl -X POST http://localhost:8000/api/v1/ml/\\$train \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"config_id\": \"'$CONFIG_ID'\",\n    \"data\": {\n      \"columns\": [\"rainfall\", \"temperature\", \"cases\"],\n      \"data\": [[10.0, 25.0, 5.0], [15.0, 28.0, 8.0]]\n    }\n  }' | jq\n</code></pre></p>"},{"location":"guides/ml-workflows/#post-apiv1mlpredict","title":"POST /api/v1/ml/$predict","text":"<p>Make predictions using a trained model.</p> <p>Request: <pre><code>{\n  \"model_artifact_id\": \"01MODEL456...\",\n  \"historic\": {\n    \"columns\": [\"feature1\", \"feature2\"],\n    \"data\": []\n  },\n  \"future\": {\n    \"columns\": [\"feature1\", \"feature2\"],\n    \"data\": [\n      [1.5, 2.5],\n      [2.5, 3.5]\n    ]\n  },\n  \"geo\": null\n}\n</code></pre></p> <p>Response (202 Accepted): <pre><code>{\n  \"job_id\": \"01JOB789...\",\n  \"prediction_artifact_id\": \"01PRED012...\",\n  \"message\": \"Prediction job submitted. Job ID: 01JOB789...\"\n}\n</code></pre></p> <p>cURL Example: <pre><code># Use model from training\ncurl -X POST http://localhost:8000/api/v1/ml/\\$predict \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model_artifact_id\": \"'$MODEL_ARTIFACT_ID'\",\n    \"historic\": {\n      \"columns\": [\"rainfall\", \"temperature\"],\n      \"data\": []\n    },\n    \"future\": {\n      \"columns\": [\"rainfall\", \"temperature\"],\n      \"data\": [[12.0, 26.0], [18.0, 29.0]]\n    }\n  }' | jq\n</code></pre></p>"},{"location":"guides/ml-workflows/#monitor-job-status","title":"Monitor Job Status","text":"<pre><code># Poll job status\ncurl http://localhost:8000/api/v1/jobs/$JOB_ID | jq\n\n# Stream status updates (SSE)\ncurl -N http://localhost:8000/api/v1/jobs/$JOB_ID/\\$stream\n\n# Get results from artifact\nARTIFACT_ID=$(curl -s http://localhost:8000/api/v1/jobs/$JOB_ID | jq -r '.artifact_id')\ncurl http://localhost:8000/api/v1/artifacts/$ARTIFACT_ID | jq\n</code></pre>"},{"location":"guides/ml-workflows/#data-formats","title":"Data Formats","text":""},{"location":"guides/ml-workflows/#pandasdataframe-schema","title":"PandasDataFrame Schema","text":"<p>All tabular data uses the <code>PandasDataFrame</code> schema:</p> <pre><code>{\n  \"columns\": [\"col1\", \"col2\", \"col3\"],\n  \"data\": [\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0]\n  ],\n  \"index\": null,\n  \"column_types\": null\n}\n</code></pre> <p>Python Usage: <pre><code>from chapkit.modules.artifact.schemas import PandasDataFrame\n\n# Create from DataFrame\ndf = pd.DataFrame({\"a\": [1, 2], \"b\": [3, 4]})\npandas_df = PandasDataFrame.from_dataframe(df)\n\n# Convert to DataFrame\ndf = pandas_df.to_dataframe()\n</code></pre></p>"},{"location":"guides/ml-workflows/#geojson-support","title":"GeoJSON Support","text":"<p>Optional geospatial data via <code>geojson-pydantic</code>:</p> <pre><code>{\n  \"type\": \"FeatureCollection\",\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"geometry\": {\n        \"type\": \"Point\",\n        \"coordinates\": [-122.4194, 37.7749]\n      },\n      \"properties\": {\n        \"name\": \"San Francisco\",\n        \"population\": 883305\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"guides/ml-workflows/#artifact-structure","title":"Artifact Structure","text":""},{"location":"guides/ml-workflows/#trainedmodelartifactdata","title":"TrainedModelArtifactData","text":"<p>Stored at hierarchy level 0:</p> <pre><code>{\n  \"ml_type\": \"trained_model\",\n  \"config_id\": \"01CONFIG...\",\n  \"model\": \"&lt;pickled model object&gt;\",\n  \"model_type\": \"sklearn.linear_model.LinearRegression\",\n  \"model_size_bytes\": 1234,\n  \"started_at\": \"2025-10-14T10:00:00Z\",\n  \"completed_at\": \"2025-10-14T10:00:15Z\",\n  \"duration_seconds\": 15.23\n}\n</code></pre> <p>Fields: - <code>ml_type</code>: Always <code>\"trained_model\"</code> - <code>config_id</code>: Config used for training - <code>model</code>: Pickled model object (any Python object) - <code>model_type</code>: Fully qualified class name (e.g., <code>sklearn.linear_model.LinearRegression</code>) - <code>model_size_bytes</code>: Serialized pickle size - <code>started_at</code>, <code>completed_at</code>: ISO timestamps - <code>duration_seconds</code>: Training duration (rounded to 2 decimals)</p>"},{"location":"guides/ml-workflows/#predictionartifactdata","title":"PredictionArtifactData","text":"<p>Stored at hierarchy level 1 (linked to model):</p> <pre><code>{\n  \"ml_type\": \"prediction\",\n  \"config_id\": \"01CONFIG...\",\n  \"model_artifact_id\": \"01MODEL...\",\n  \"predictions\": {\n    \"columns\": [\"feature1\", \"feature2\", \"sample_0\"],\n    \"data\": [[1.5, 2.5, 12.3], [2.5, 3.5, 17.8]]\n  },\n  \"started_at\": \"2025-10-14T10:05:00Z\",\n  \"completed_at\": \"2025-10-14T10:05:02Z\",\n  \"duration_seconds\": 2.15\n}\n</code></pre> <p>Fields: - <code>ml_type</code>: Always <code>\"prediction\"</code> - <code>config_id</code>: Config used for prediction - <code>model_artifact_id</code>: Parent trained model artifact - <code>predictions</code>: Result DataFrame (PandasDataFrame schema) - <code>started_at</code>, <code>completed_at</code>: ISO timestamps - <code>duration_seconds</code>: Prediction duration (rounded to 2 decimals)</p>"},{"location":"guides/ml-workflows/#complete-workflow-examples","title":"Complete Workflow Examples","text":""},{"location":"guides/ml-workflows/#basic-functional-workflow","title":"Basic Functional Workflow","text":"<pre><code># 1. Start service\nfastapi dev examples/ml_basic.py\n\n# 2. Create config\nCONFIG_ID=$(curl -s -X POST http://localhost:8000/api/v1/configs \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"weather_model\", \"data\": {}}' | jq -r '.id')\n\n# 3. Train model\nTRAIN_RESPONSE=$(curl -s -X POST http://localhost:8000/api/v1/ml/\\$train \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"config_id\": \"'$CONFIG_ID'\",\n    \"data\": {\n      \"columns\": [\"rainfall\", \"mean_temperature\", \"disease_cases\"],\n      \"data\": [\n        [10.0, 25.0, 5.0],\n        [15.0, 28.0, 8.0],\n        [8.0, 22.0, 3.0],\n        [20.0, 30.0, 12.0],\n        [12.0, 26.0, 6.0]\n      ]\n    }\n  }')\n\nJOB_ID=$(echo $TRAIN_RESPONSE | jq -r '.job_id')\nMODEL_ARTIFACT_ID=$(echo $TRAIN_RESPONSE | jq -r '.model_artifact_id')\n\necho \"Training Job ID: $JOB_ID\"\necho \"Model Artifact ID: $MODEL_ARTIFACT_ID\"\n\n# 4. Wait for training completion\ncurl -N http://localhost:8000/api/v1/jobs/$JOB_ID/\\$stream\n\n# 5. View trained model\ncurl http://localhost:8000/api/v1/artifacts/$MODEL_ARTIFACT_ID | jq\n\n# 6. Make predictions\nPREDICT_RESPONSE=$(curl -s -X POST http://localhost:8000/api/v1/ml/\\$predict \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model_artifact_id\": \"'$MODEL_ARTIFACT_ID'\",\n    \"historic\": {\n      \"columns\": [\"rainfall\", \"mean_temperature\"],\n      \"data\": []\n    },\n    \"future\": {\n      \"columns\": [\"rainfall\", \"mean_temperature\"],\n      \"data\": [\n        [11.0, 26.0],\n        [14.0, 27.0],\n        [9.0, 24.0]\n      ]\n    }\n  }')\n\nPRED_JOB_ID=$(echo $PREDICT_RESPONSE | jq -r '.job_id')\nPRED_ARTIFACT_ID=$(echo $PREDICT_RESPONSE | jq -r '.prediction_artifact_id')\n\n# 7. Wait for predictions\ncurl -N http://localhost:8000/api/v1/jobs/$PRED_JOB_ID/\\$stream\n\n# 8. View predictions\ncurl http://localhost:8000/api/v1/artifacts/$PRED_ARTIFACT_ID | jq '.data.predictions'\n</code></pre>"},{"location":"guides/ml-workflows/#class-based-with-preprocessing","title":"Class-Based with Preprocessing","text":"<pre><code># examples/ml_class.py demonstrates:\n# - StandardScaler for feature normalization\n# - State management (scaler shared between train/predict)\n# - Lifecycle hooks (on_init, on_cleanup)\n# - Model artifact containing multiple objects\n\nfrom chapkit.modules.ml import BaseModelRunner\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\n\nclass WeatherModelRunner(BaseModelRunner):\n    def __init__(self):\n        self.feature_names = [\"rainfall\", \"mean_temperature\", \"humidity\"]\n        self.scaler = None\n\n    async def on_train(self, config, data, geo=None):\n        X = data[self.feature_names].fillna(0)\n        y = data[\"disease_cases\"].fillna(0)\n\n        # Normalize features\n        self.scaler = StandardScaler()\n        X_scaled = self.scaler.fit_transform(X)\n\n        # Train model\n        model = LinearRegression()\n        model.fit(X_scaled, y)\n\n        # Return dict with model and preprocessing artifacts\n        return {\n            \"model\": model,\n            \"scaler\": self.scaler,\n            \"feature_names\": self.feature_names,\n        }\n\n    async def on_predict(self, config, model, historic, future, geo=None):\n        # Extract artifacts\n        trained_model = model[\"model\"]\n        scaler = model[\"scaler\"]\n        feature_names = model[\"feature_names\"]\n\n        # Apply same preprocessing\n        X = future[feature_names].fillna(0)\n        X_scaled = scaler.transform(X)\n\n        # Predict\n        future[\"sample_0\"] = trained_model.predict(X_scaled)\n        return future\n</code></pre> <p>Benefits: - Consistent preprocessing between train/predict - Model artifacts include all necessary objects - Type safety and validation - Easy testing and debugging</p>"},{"location":"guides/ml-workflows/#shell-based-language-agnostic","title":"Shell-Based Language-Agnostic","text":"<pre><code># examples/ml_shell.py demonstrates:\n# - External R/Julia/Python scripts\n# - File-based data interchange\n# - No code modification required\n# - Container-friendly workflows\n\nfrom chapkit.modules.ml import ShellModelRunner\nimport sys\n\nrunner = ShellModelRunner(\n    train_command=f\"{sys.executable} scripts/train_model.py --config {{config_file}} --data {{data_file}} --model {{model_file}}\",\n    predict_command=f\"{sys.executable} scripts/predict_model.py --config {{config_file}} --model {{model_file}} --future {{future_file}} --output {{output_file}}\",\n    model_format=\"pickle\"\n)\n</code></pre> <p>External Script Example (R): <pre><code>#!/usr/bin/env Rscript\nlibrary(jsonlite)\n\nargs &lt;- commandArgs(trailingOnly = TRUE)\nconfig_file &lt;- args[which(args == \"--config\") + 1]\ndata_file &lt;- args[which(args == \"--data\") + 1]\nmodel_file &lt;- args[which(args == \"--model\") + 1]\n\n# Load data\nconfig &lt;- fromJSON(config_file)\ndata &lt;- read.csv(data_file)\n\n# Train model\nmodel &lt;- lm(disease_cases ~ rainfall + mean_temperature, data = data)\n\n# Save model\nsaveRDS(model, model_file)\ncat(\"SUCCESS: Model trained\\n\")\n</code></pre></p>"},{"location":"guides/ml-workflows/#testing","title":"Testing","text":""},{"location":"guides/ml-workflows/#manual-testing","title":"Manual Testing","text":"<p>Terminal 1: <pre><code>fastapi dev examples/ml_basic.py\n</code></pre></p> <p>Terminal 2: <pre><code># Complete workflow test\nCONFIG_ID=$(curl -s -X POST http://localhost:8000/api/v1/configs \\\n  -d '{\"name\":\"test\",\"data\":{}}' | jq -r '.id')\n\nTRAIN=$(curl -s -X POST http://localhost:8000/api/v1/ml/\\$train -d '{\n  \"config_id\":\"'$CONFIG_ID'\",\n  \"data\":{\"columns\":[\"a\",\"b\",\"y\"],\"data\":[[1,2,10],[2,3,15],[3,4,20]]}\n}')\n\nMODEL_ID=$(echo $TRAIN | jq -r '.model_artifact_id')\nJOB_ID=$(echo $TRAIN | jq -r '.job_id')\n\n# Wait for completion\nsleep 2\ncurl http://localhost:8000/api/v1/jobs/$JOB_ID | jq '.status'\n\n# Predict\nPRED=$(curl -s -X POST http://localhost:8000/api/v1/ml/\\$predict -d '{\n  \"model_artifact_id\":\"'$MODEL_ID'\",\n  \"historic\":{\"columns\":[\"a\",\"b\"],\"data\":[]},\n  \"future\":{\"columns\":[\"a\",\"b\"],\"data\":[[1.5,2.5],[2.5,3.5]]}\n}')\n\nPRED_ID=$(echo $PRED | jq -r '.prediction_artifact_id')\nsleep 2\n\n# View results\ncurl http://localhost:8000/api/v1/artifacts/$PRED_ID | jq '.data.predictions'\n</code></pre></p>"},{"location":"guides/ml-workflows/#automated-testing","title":"Automated Testing","text":"<pre><code>import time\nfrom fastapi.testclient import TestClient\n\ndef wait_for_job(client: TestClient, job_id: str, timeout: float = 5.0):\n    \"\"\"Poll until job completes.\"\"\"\n    start = time.time()\n    while time.time() - start &lt; timeout:\n        job = client.get(f\"/api/v1/jobs/{job_id}\").json()\n        if job[\"status\"] in [\"completed\", \"failed\", \"canceled\"]:\n            return job\n        time.sleep(0.1)\n    raise TimeoutError(f\"Job {job_id} timeout\")\n\n\ndef test_train_predict_workflow(client: TestClient):\n    \"\"\"Test complete ML workflow.\"\"\"\n    # Create config\n    config_resp = client.post(\"/api/v1/configs\", json={\n        \"name\": \"test_config\",\n        \"data\": {}\n    })\n    config_id = config_resp.json()[\"id\"]\n\n    # Train\n    train_resp = client.post(\"/api/v1/ml/$train\", json={\n        \"config_id\": config_id,\n        \"data\": {\n            \"columns\": [\"x1\", \"x2\", \"y\"],\n            \"data\": [[1, 2, 10], [2, 3, 15], [3, 4, 20]]\n        }\n    })\n    assert train_resp.status_code == 202\n\n    train_data = train_resp.json()\n    job_id = train_data[\"job_id\"]\n    model_id = train_data[\"model_artifact_id\"]\n\n    # Wait for training\n    job = wait_for_job(client, job_id)\n    assert job[\"status\"] == \"completed\"\n\n    # Verify model artifact\n    model_artifact = client.get(f\"/api/v1/artifacts/{model_id}\").json()\n    assert model_artifact[\"data\"][\"ml_type\"] == \"trained_model\"\n    assert model_artifact[\"level\"] == 0\n\n    # Predict\n    pred_resp = client.post(\"/api/v1/ml/$predict\", json={\n        \"model_artifact_id\": model_id,\n        \"historic\": {\n            \"columns\": [\"x1\", \"x2\"],\n            \"data\": []\n        },\n        \"future\": {\n            \"columns\": [\"x1\", \"x2\"],\n            \"data\": [[1.5, 2.5], [2.5, 3.5]]\n        }\n    })\n    assert pred_resp.status_code == 202\n\n    pred_data = pred_resp.json()\n    pred_job_id = pred_data[\"job_id\"]\n    pred_id = pred_data[\"prediction_artifact_id\"]\n\n    # Wait for prediction\n    pred_job = wait_for_job(client, pred_job_id)\n    assert pred_job[\"status\"] == \"completed\"\n\n    # Verify predictions\n    pred_artifact = client.get(f\"/api/v1/artifacts/{pred_id}\").json()\n    assert pred_artifact[\"data\"][\"ml_type\"] == \"prediction\"\n    assert pred_artifact[\"parent_id\"] == model_id\n    assert pred_artifact[\"level\"] == 1\n    assert \"sample_0\" in pred_artifact[\"data\"][\"predictions\"][\"columns\"]\n</code></pre>"},{"location":"guides/ml-workflows/#browser-testing-swagger-ui","title":"Browser Testing (Swagger UI)","text":"<ol> <li>Open http://localhost:8000/docs</li> <li>Create config via POST <code>/api/v1/configs</code></li> <li>Train via POST <code>/api/v1/ml/$train</code></li> <li>Monitor job via GET <code>/api/v1/jobs/{job_id}</code></li> <li>Predict via POST <code>/api/v1/ml/$predict</code></li> <li>View artifacts via GET <code>/api/v1/artifacts/{artifact_id}</code></li> </ol>"},{"location":"guides/ml-workflows/#production-deployment","title":"Production Deployment","text":""},{"location":"guides/ml-workflows/#concurrency-control","title":"Concurrency Control","text":"<pre><code>MLServiceBuilder(\n    info=info,\n    config_schema=config_schema,\n    hierarchy=hierarchy,\n    runner=runner,\n    max_concurrency=3,  # Limit concurrent training jobs\n)\n</code></pre> <p>Recommendations: - CPU-intensive models: Set to CPU core count (4-8) - GPU models: Set to GPU count (1-4) - Memory-intensive: Lower limits (2-3) - I/O-bound: Higher limits OK (10-20)</p>"},{"location":"guides/ml-workflows/#database-configuration","title":"Database Configuration","text":"<pre><code>MLServiceBuilder(\n    info=info,\n    config_schema=config_schema,\n    hierarchy=hierarchy,\n    runner=runner,\n    database_url=\"/data/ml.db\",  # Persistent storage\n)\n</code></pre> <p>Best Practices: - Mount persistent volume for <code>/data</code> - Regular backups (models + artifacts) - Monitor database size growth - Implement artifact retention policies</p>"},{"location":"guides/ml-workflows/#model-versioning","title":"Model Versioning","text":"<pre><code># Use config name for version tracking\nconfig = {\n    \"name\": \"weather_model_v1.2.3\",\n    \"data\": {\n        \"version\": \"1.2.3\",\n        \"features\": [\"rainfall\", \"temperature\"],\n        \"hyperparameters\": {\"alpha\": 0.01}\n    }\n}\n</code></pre> <p>Artifact Hierarchy for Versions: <pre><code>weather_model_v1.0.0 (config)\n  \u2514\u2500&gt; trained_model_1 (artifact level 0)\n       \u2514\u2500&gt; predictions_* (artifact level 1)\n\nweather_model_v1.1.0 (config)\n  \u2514\u2500&gt; trained_model_2 (artifact level 0)\n       \u2514\u2500&gt; predictions_* (artifact level 1)\n</code></pre></p>"},{"location":"guides/ml-workflows/#monitoring","title":"Monitoring","text":"<pre><code>app = (\n    MLServiceBuilder(info=info, config_schema=config, hierarchy=hierarchy, runner=runner)\n    .with_monitoring()  # Prometheus metrics at /metrics\n    .build()\n)\n</code></pre> <p>Available Metrics: - <code>ml_train_jobs_total</code> - Total training jobs submitted - <code>ml_predict_jobs_total</code> - Total prediction jobs submitted - Job scheduler metrics (see Job Scheduler guide)</p> <p>Custom Metrics: <pre><code>from prometheus_client import Histogram\n\nmodel_training_duration = Histogram(\n    'model_training_duration_seconds',\n    'Model training duration'\n)\n\n# Training durations already tracked in artifact metadata\n# Query via artifact API\n</code></pre></p>"},{"location":"guides/ml-workflows/#docker-deployment","title":"Docker Deployment","text":"<p>Dockerfile: <pre><code>FROM python:3.13-slim\n\nWORKDIR /app\nCOPY . /app\n\nRUN pip install --no-cache-dir -e .\n\n# Create non-root user\nRUN useradd -m -u 1000 mluser &amp;&amp; chown -R mluser:mluser /app\nUSER mluser\n\nEXPOSE 8000\n\nCMD [\"fastapi\", \"run\", \"ml_service.py\", \"--host\", \"0.0.0.0\"]\n</code></pre></p> <p>docker-compose.yml: <pre><code>version: '3.8'\n\nservices:\n  ml-service:\n    build: .\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - ml-data:/data\n    environment:\n      - DATABASE_URL=/data/ml.db\n    deploy:\n      resources:\n        limits:\n          cpus: '4.0'\n          memory: 8G\n\nvolumes:\n  ml-data:\n</code></pre></p>"},{"location":"guides/ml-workflows/#gpu-support","title":"GPU Support","text":"<pre><code>FROM nvidia/cuda:12.0-runtime-ubuntu22.04\nFROM python:3.13\n\n# Install ML libraries with GPU support\nRUN pip install torch torchvision --index-url https://download.pytorch.org/whl/cu120\n\n# Your ML code\nCOPY . /app\n</code></pre> <p>docker-compose.yml: <pre><code>services:\n  ml-service:\n    build: .\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: 1\n              capabilities: [gpu]\n</code></pre></p>"},{"location":"guides/ml-workflows/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/ml-workflows/#config-not-found-error","title":"\"Config not found\" Error","text":"<p>Problem: Training fails with \"Config {id} not found\"</p> <p>Cause: Invalid or deleted config ID</p> <p>Solution: <pre><code># List configs\ncurl http://localhost:8000/api/v1/configs | jq\n\n# Verify config exists\ncurl http://localhost:8000/api/v1/configs/$CONFIG_ID\n</code></pre></p>"},{"location":"guides/ml-workflows/#model-artifact-not-found-error","title":"\"Model artifact not found\" Error","text":"<p>Problem: Prediction fails with \"Model artifact {id} not found\"</p> <p>Cause: Invalid model artifact ID or training failed</p> <p>Solution: <pre><code># Check training job status\ncurl http://localhost:8000/api/v1/jobs/$TRAIN_JOB_ID | jq\n\n# If training failed, check error\ncurl http://localhost:8000/api/v1/jobs/$TRAIN_JOB_ID | jq '.error'\n\n# List artifacts\ncurl http://localhost:8000/api/v1/artifacts | jq\n</code></pre></p>"},{"location":"guides/ml-workflows/#training-job-fails-immediately","title":"Training Job Fails Immediately","text":"<p>Problem: Job status shows \"failed\" right after submission</p> <p>Causes: 1. Model not pickleable 2. Missing required columns in data 3. Insufficient training data 4. Config validation errors</p> <p>Solution: <pre><code># Check job error message\ncurl http://localhost:8000/api/v1/jobs/$JOB_ID | jq '.error, .error_traceback'\n\n# Common fixes:\n# - Ensure model is pickleable (no lambda functions, local classes)\n# - Verify DataFrame columns match feature expectations\n# - Check config schema validation\n</code></pre></p>"},{"location":"guides/ml-workflows/#prediction-returns-wrong-shape","title":"Prediction Returns Wrong Shape","text":"<p>Problem: Predictions DataFrame has incorrect columns</p> <p>Cause: <code>on_predict</code> must add prediction columns to input DataFrame</p> <p>Solution: <pre><code>async def on_predict(self, config, model, historic, future, geo=None):\n    X = future[[\"feature1\", \"feature2\"]]\n    predictions = model.predict(X)\n\n    # IMPORTANT: Add predictions to future DataFrame\n    future[\"sample_0\"] = predictions  # Required column name\n\n    return future  # Return modified DataFrame\n</code></pre></p>"},{"location":"guides/ml-workflows/#shell-runner-script-fails","title":"Shell Runner Script Fails","text":"<p>Problem: ShellModelRunner returns \"script failed with exit code 1\"</p> <p>Causes: 1. Script not executable 2. Wrong interpreter 3. Missing dependencies 4. File path issues</p> <p>Solution: <pre><code># Make script executable\nchmod +x scripts/train_model.py\n\n# Test script manually\npython scripts/train_model.py \\\n  --config /tmp/test_config.json \\\n  --data /tmp/test_data.csv \\\n  --model /tmp/test_model.pkl\n\n# Check script stderr output\ncurl http://localhost:8000/api/v1/jobs/$JOB_ID | jq '.error'\n</code></pre></p>"},{"location":"guides/ml-workflows/#high-memory-usage","title":"High Memory Usage","text":"<p>Problem: Service consuming excessive memory</p> <p>Causes: 1. Large models in memory 2. Too many concurrent jobs 3. Artifact accumulation</p> <p>Solution: <pre><code># Limit concurrent jobs\nMLServiceBuilder(..., max_concurrency=2)\n\n# Implement artifact cleanup\nasync def cleanup_old_artifacts(app):\n    # Delete artifacts older than 30 days\n    cutoff = datetime.now() - timedelta(days=30)\n    # Implementation depends on your needs\n\napp.on_startup(cleanup_old_artifacts)\n</code></pre></p>"},{"location":"guides/ml-workflows/#model-size-too-large","title":"Model Size Too Large","text":"<p>Problem: \"Model size exceeds limit\" or slow artifact storage</p> <p>Cause: Large models (&gt;100MB) stored in SQLite</p> <p>Solution: <pre><code># Option 1: External model storage\nasync def on_train(self, config, data, geo=None):\n    model = train_large_model(data)\n\n    # Save to external storage (S3, etc.)\n    model_url = save_to_s3(model)\n\n    # Return metadata instead of model\n    return {\n        \"model_url\": model_url,\n        \"model_metadata\": {...}\n    }\n\n# Option 2: Use PostgreSQL instead of SQLite\nMLServiceBuilder(..., database_url=\"postgresql://...\")\n</code></pre></p>"},{"location":"guides/ml-workflows/#dataframe-validation-errors","title":"DataFrame Validation Errors","text":"<p>Problem: \"Invalid PandasDataFrame schema\" during train/predict</p> <p>Cause: Incorrect data format in request</p> <p>Solution: <pre><code>// Correct format\n{\n  \"columns\": [\"col1\", \"col2\"],\n  \"data\": [\n    [1.0, 2.0],\n    [3.0, 4.0]\n  ]\n}\n\n// Wrong formats:\n// {\"col1\": [1, 3], \"col2\": [2, 4]}  (dict format - not supported)\n// [{\"col1\": 1, \"col2\": 2}]  (records format - not supported)\n</code></pre></p>"},{"location":"guides/ml-workflows/#next-steps","title":"Next Steps","text":"<ul> <li>Job Monitoring: See Job Scheduler guide for SSE streaming</li> <li>Task Execution: Combine with Tasks for preprocessing pipelines</li> <li>Authentication: Secure ML endpoints with API keys</li> <li>Monitoring: Track model performance with Prometheus metrics</li> </ul> <p>For more examples: - <code>examples/ml_basic.py</code> - Functional runner with LinearRegression - <code>examples/ml_class.py</code> - Class-based runner with preprocessing - <code>examples/ml_shell.py</code> - Shell-based runner with external scripts - <code>tests/test_example_ml_basic.py</code> - Complete test suite</p>"},{"location":"guides/monitoring/","title":"Monitoring with OpenTelemetry and Prometheus","text":"<p>Chapkit provides built-in monitoring through OpenTelemetry instrumentation with automatic Prometheus metrics export.</p>"},{"location":"guides/monitoring/#quick-start","title":"Quick Start","text":"<p>Enable monitoring in your service with a single method call:</p> <pre><code>from chapkit.api import ServiceBuilder, ServiceInfo\n\napp = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"My Service\"))\n    .with_monitoring()  # Enables OpenTelemetry + Prometheus endpoint\n    .with_database()\n    .with_health()\n    .build()\n)\n</code></pre> <p>Your service now exposes Prometheus metrics at <code>/metrics</code>.</p>"},{"location":"guides/monitoring/#features","title":"Features","text":""},{"location":"guides/monitoring/#automatic-instrumentation","title":"Automatic Instrumentation","text":"<ul> <li>FastAPI: HTTP request metrics (duration, status codes, paths)</li> <li>SQLAlchemy: Database query metrics (connection pool, query duration)</li> <li>Python Runtime: Garbage collection, memory usage, CPU time</li> </ul>"},{"location":"guides/monitoring/#metrics-endpoint","title":"Metrics Endpoint","text":"<ul> <li>Path: <code>/metrics</code> (operational endpoint, root level)</li> <li>Format: Prometheus text format</li> <li>Content-Type: <code>text/plain; version=0.0.4; charset=utf-8</code></li> </ul>"},{"location":"guides/monitoring/#zero-configuration","title":"Zero Configuration","text":"<p>No manual instrumentation needed - Chapkit automatically:</p> <ul> <li>Instruments all FastAPI routes</li> <li>Tracks SQLAlchemy database operations</li> <li>Exposes Python runtime metrics</li> <li>Handles OpenTelemetry lifecycle</li> </ul>"},{"location":"guides/monitoring/#configuration","title":"Configuration","text":""},{"location":"guides/monitoring/#basic-configuration","title":"Basic Configuration","text":"<pre><code>.with_monitoring()  # Uses defaults\n</code></pre> <p>Defaults: - Metrics endpoint: <code>/metrics</code> - Service name: From <code>ServiceInfo.display_name</code> - Tags: <code>[\"monitoring\"]</code></p>"},{"location":"guides/monitoring/#custom-configuration","title":"Custom Configuration","text":"<pre><code>.with_monitoring(\n    prefix=\"/custom/metrics\",           # Custom endpoint path\n    tags=[\"Observability\", \"Telemetry\"], # Custom OpenAPI tags\n    service_name=\"production-api\",       # Override service name\n)\n</code></pre>"},{"location":"guides/monitoring/#parameters","title":"Parameters","text":"<ul> <li>prefix (<code>str</code>): Metrics endpoint path. Default: <code>/metrics</code></li> <li>tags (<code>List[str]</code>): OpenAPI tags for metrics endpoint. Default: <code>[\"monitoring\"]</code></li> <li>service_name (<code>str | None</code>): Service name in metrics labels. Default: from <code>ServiceInfo</code></li> </ul>"},{"location":"guides/monitoring/#metrics-endpoint_1","title":"Metrics Endpoint","text":""},{"location":"guides/monitoring/#testing-the-endpoint","title":"Testing the Endpoint","text":"<pre><code># Get metrics\ncurl http://localhost:8000/metrics\n\n# Filter specific metrics\ncurl http://localhost:8000/metrics | grep http_request\n\n# Monitor continuously\nwatch -n 1 'curl -s http://localhost:8000/metrics | grep http_request_duration'\n</code></pre>"},{"location":"guides/monitoring/#expected-output","title":"Expected Output","text":"<pre><code># HELP python_gc_objects_collected_total Objects collected during gc\n# TYPE python_gc_objects_collected_total counter\npython_gc_objects_collected_total{generation=\"0\"} 234.0\n\n# HELP http_server_request_duration_seconds HTTP request duration\n# TYPE http_server_request_duration_seconds histogram\nhttp_server_request_duration_seconds_bucket{http_method=\"GET\",http_status_code=\"200\",le=\"0.005\"} 45.0\n\n# HELP db_client_connections_usage Number of connections that are currently in use\n# TYPE db_client_connections_usage gauge\ndb_client_connections_usage{pool_name=\"default\",state=\"used\"} 2.0\n</code></pre>"},{"location":"guides/monitoring/#kubernetes-integration","title":"Kubernetes Integration","text":""},{"location":"guides/monitoring/#deployment-with-service-monitor","title":"Deployment with Service Monitor","text":"<p>deployment.yaml: <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: chapkit-service\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: chapkit-service\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"8000\"\n        prometheus.io/path: \"/metrics\"\n    spec:\n      containers:\n      - name: app\n        image: your-chapkit-app\n        ports:\n        - containerPort: 8000\n          name: http\n</code></pre></p> <p>service.yaml: <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: chapkit-service\n  labels:\n    app: chapkit-service\nspec:\n  ports:\n  - port: 8000\n    targetPort: 8000\n    name: http\n  selector:\n    app: chapkit-service\n</code></pre></p> <p>servicemonitor.yaml (Prometheus Operator): <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: chapkit-service\n  labels:\n    app: chapkit-service\nspec:\n  selector:\n    matchLabels:\n      app: chapkit-service\n  endpoints:\n  - port: http\n    path: /metrics\n    interval: 30s\n</code></pre></p>"},{"location":"guides/monitoring/#prometheus-configuration","title":"Prometheus Configuration","text":""},{"location":"guides/monitoring/#scrape-configuration","title":"Scrape Configuration","text":"<p>Add to <code>prometheus.yml</code>:</p> <pre><code>scrape_configs:\n  - job_name: 'chapkit-services'\n    scrape_interval: 15s\n    static_configs:\n      - targets: ['localhost:8000']\n        labels:\n          service: 'chapkit-api'\n          environment: 'production'\n</code></pre>"},{"location":"guides/monitoring/#docker-compose-setup","title":"Docker Compose Setup","text":"<p>docker-compose.yml: <pre><code>version: '3.8'\n\nservices:\n  chapkit-app:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      - LOG_LEVEL=INFO\n\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml\n      - prometheus-data:/prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n\n  grafana:\n    image: grafana/grafana:latest\n    ports:\n      - \"3000:3000\"\n    volumes:\n      - grafana-data:/var/lib/grafana\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n      - GF_AUTH_ANONYMOUS_ENABLED=true\n\nvolumes:\n  prometheus-data:\n  grafana-data:\n</code></pre></p>"},{"location":"guides/monitoring/#grafana-dashboards","title":"Grafana Dashboards","text":""},{"location":"guides/monitoring/#adding-prometheus-data-source","title":"Adding Prometheus Data Source","text":"<ol> <li>Navigate to Configuration \u2192 Data Sources</li> <li>Click Add data source</li> <li>Select Prometheus</li> <li>Set URL: <code>http://prometheus:9090</code> (Docker) or <code>http://localhost:9090</code> (local)</li> <li>Click Save &amp; Test</li> </ol>"},{"location":"guides/monitoring/#example-queries","title":"Example Queries","text":"<p>HTTP Request Rate: <pre><code>rate(http_server_requests_total{job=\"chapkit-services\"}[5m])\n</code></pre></p> <p>Request Duration (p95): <pre><code>histogram_quantile(0.95,\n  rate(http_server_request_duration_seconds_bucket[5m])\n)\n</code></pre></p> <p>Database Connection Pool Usage: <pre><code>db_client_connections_usage{state=\"used\"} /\ndb_client_connections_limit\n</code></pre></p> <p>Error Rate: <pre><code>rate(http_server_requests_total{http_status_code=~\"5..\"}[5m])\n</code></pre></p> <p>ML Training Job Rate: <pre><code>rate(ml_train_jobs_total{job=\"chapkit-services\"}[5m])\n</code></pre></p> <p>ML Prediction Job Rate: <pre><code>rate(ml_predict_jobs_total{job=\"chapkit-services\"}[5m])\n</code></pre></p> <p>Total ML Jobs (Train + Predict): <pre><code>sum(rate(ml_train_jobs_total{job=\"chapkit-services\"}[5m])) +\nsum(rate(ml_predict_jobs_total{job=\"chapkit-services\"}[5m]))\n</code></pre></p>"},{"location":"guides/monitoring/#available-metrics","title":"Available Metrics","text":""},{"location":"guides/monitoring/#http-metrics-fastapi","title":"HTTP Metrics (FastAPI)","text":"<ul> <li><code>http_server_request_duration_seconds</code> - Request duration histogram</li> <li><code>http_server_requests_total</code> - Total requests counter</li> <li><code>http_server_active_requests</code> - Active requests gauge</li> </ul> <p>Labels: <code>http_method</code>, <code>http_status_code</code>, <code>http_route</code></p>"},{"location":"guides/monitoring/#database-metrics-sqlalchemy","title":"Database Metrics (SQLAlchemy)","text":"<ul> <li><code>db_client_connections_usage</code> - Connection pool usage</li> <li><code>db_client_connections_limit</code> - Connection pool limit</li> <li><code>db_client_operation_duration_seconds</code> - Query duration</li> </ul> <p>Labels: <code>pool_name</code>, <code>state</code>, <code>operation</code></p>"},{"location":"guides/monitoring/#python-runtime-metrics","title":"Python Runtime Metrics","text":"<ul> <li><code>python_gc_objects_collected_total</code> - GC collections</li> <li><code>python_gc_collections_total</code> - GC runs</li> <li><code>python_info</code> - Python version info</li> <li><code>process_cpu_seconds_total</code> - CPU time</li> <li><code>process_resident_memory_bytes</code> - Memory usage</li> </ul>"},{"location":"guides/monitoring/#ml-metrics-when-using-with_ml","title":"ML Metrics (when using <code>.with_ml()</code>)","text":"<ul> <li><code>ml_train_jobs_total</code> - Total number of ML training jobs submitted</li> <li><code>ml_predict_jobs_total</code> - Total number of ML prediction jobs submitted</li> </ul> <p>Labels: <code>service_name</code></p>"},{"location":"guides/monitoring/#best-practices","title":"Best Practices","text":""},{"location":"guides/monitoring/#recommended-practices","title":"Recommended Practices","text":"<ul> <li>Enable monitoring in production for observability</li> <li>Set meaningful service names to identify services in multi-service setups</li> <li>Monitor key metrics: request rate, error rate, duration (RED method)</li> <li>Set up alerts for error rates, high latency, and resource exhaustion</li> <li>Use service labels to tag metrics with environment, version, region</li> <li>Keep <code>/metrics</code> unauthenticated for Prometheus access (use network policies)</li> </ul>"},{"location":"guides/monitoring/#avoid","title":"Avoid","text":"<ul> <li>Exposing metrics publicly (use internal network or auth proxy)</li> <li>Scraping too frequently (15-30s interval is usually sufficient)</li> <li>Ignoring high cardinality (avoid unbounded label values)</li> <li>Skipping resource limits (monitor and limit Prometheus storage growth)</li> </ul>"},{"location":"guides/monitoring/#combining-with-other-features","title":"Combining with Other Features","text":""},{"location":"guides/monitoring/#with-authentication","title":"With Authentication","text":"<pre><code>app = (\n    ServiceBuilder(info=info)\n    .with_monitoring()\n    .with_auth(\n        unauthenticated_paths=[\n            \"/health\",      # Health check\n            \"/metrics\",     # Prometheus scraping\n            \"/docs\"         # API docs\n        ]\n    )\n    .build()\n)\n</code></pre>"},{"location":"guides/monitoring/#with-health-checks","title":"With Health Checks","text":"<pre><code>app = (\n    ServiceBuilder(info=info)\n    .with_health()         # /health - Health check endpoint\n    .with_system()         # /api/v1/system - System metadata\n    .with_monitoring()     # /metrics - Prometheus metrics\n    .build()\n)\n</code></pre> <p>Operational monitoring endpoints (<code>/health</code>, <code>/health/$stream</code>, <code>/metrics</code>) use root-level paths for easy discovery by Kubernetes, monitoring dashboards, and Prometheus. Service metadata endpoints (<code>/api/v1/system</code>, <code>/api/v1/info</code>) use versioned API paths.</p> <p>For detailed health check configuration and usage, see the Health Checks Guide.</p>"},{"location":"guides/monitoring/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/monitoring/#metrics-endpoint-returns-404","title":"Metrics Endpoint Returns 404","text":"<p>Problem: <code>/metrics</code> endpoint not found.</p> <p>Solution: Ensure you called <code>.with_monitoring()</code> in your ServiceBuilder chain.</p>"},{"location":"guides/monitoring/#no-metrics-appear","title":"No Metrics Appear","text":"<p>Problem: Endpoint returns empty or minimal metrics.</p> <p>Solution: 1. Make some requests to your API endpoints 2. Verify FastAPI instrumentation with: <code>curl http://localhost:8000/api/v1/configs</code> 3. Check metrics again: <code>curl http://localhost:8000/metrics | grep http_request</code></p>"},{"location":"guides/monitoring/#prometheus-cannot-scrape","title":"Prometheus Cannot Scrape","text":"<p>Problem: Prometheus shows targets as \"DOWN\".</p> <p>Solution: 1. Verify service is running: <code>curl http://localhost:8000/health</code> 2. Check network connectivity 3. Verify scrape config matches service port and path 4. Check for firewall/network policies blocking access</p>"},{"location":"guides/monitoring/#high-memory-usage","title":"High Memory Usage","text":"<p>Problem: Prometheus uses too much memory.</p> <p>Solution: 1. Reduce retention time: <code>--storage.tsdb.retention.time=15d</code> 2. Increase scrape interval: <code>scrape_interval: 30s</code> 3. Limit metric cardinality (check for unbounded labels)</p>"},{"location":"guides/monitoring/#next-steps","title":"Next Steps","text":"<ul> <li>Health Checks: Add health monitoring with <code>.with_health()</code> - see Health Checks Guide</li> <li>Alerting: Set up Prometheus Alertmanager for notifications</li> <li>Distributed Tracing: Future support for OpenTelemetry traces (see ROADMAP.md)</li> <li>Custom Metrics: Use <code>get_meter()</code> for application-specific metrics</li> <li>SLOs: Define Service Level Objectives based on metrics</li> </ul>"},{"location":"guides/monitoring/#examples","title":"Examples","text":"<ul> <li><code>examples/monitoring_api.py</code> - Complete monitoring example</li> <li><code>examples/docs/monitoring_api.postman_collection.json</code> - Postman collection</li> </ul> <p>For more details, see: - Health Checks Guide - Health check configuration - OpenTelemetry Documentation - Prometheus Documentation - Grafana Documentation</p>"},{"location":"guides/task-execution/","title":"Task Execution","text":"<p>Chapkit provides a task execution system for running shell commands and Python functions asynchronously with artifact-based result storage. Tasks are reusable templates that can be executed multiple times, with each execution creating a Job and storing results in an Artifact.</p>"},{"location":"guides/task-execution/#quick-start","title":"Quick Start","text":""},{"location":"guides/task-execution/#create-and-execute-a-task","title":"Create and Execute a Task","text":"<pre><code># Start the example service\nfastapi dev examples/task_execution_api.py\n\n# Create a task template\nTASK_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"command\": \"echo \\\"Hello World\\\"\"}' | jq -r '.id')\n\necho \"Task ID: $TASK_ID\"\n\n# Execute the task\nJOB_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks/$TASK_ID/\\$execute | jq -r '.job_id')\n\necho \"Job ID: $JOB_ID\"\n\n# Wait for completion and get results\nsleep 1\nARTIFACT_ID=$(curl -s http://localhost:8000/api/v1/jobs/$JOB_ID | jq -r '.artifact_id')\n\n# View execution results\ncurl http://localhost:8000/api/v1/artifacts/$ARTIFACT_ID | jq '.data'\n</code></pre> <p>Output: <pre><code>{\n  \"task\": {\n    \"id\": \"01JCSEED...\",\n    \"command\": \"echo \\\"Hello World\\\"\",\n    \"created_at\": \"2025-10-14T...\",\n    \"updated_at\": \"2025-10-14T...\"\n  },\n  \"stdout\": \"Hello World\\n\",\n  \"stderr\": \"\",\n  \"exit_code\": 0\n}\n</code></pre></p>"},{"location":"guides/task-execution/#architecture","title":"Architecture","text":"<p>The Task execution system uses a clean separation of concerns:</p>"},{"location":"guides/task-execution/#task-templates","title":"Task Templates","text":"<p>Tasks are reusable command templates stored in the database: - Contain only the command to execute - No status or output fields (stateless) - Can be executed multiple times - Immutable history (past executions unaffected by template changes)</p>"},{"location":"guides/task-execution/#job-execution","title":"Job Execution","text":"<p>When a task is executed: 1. Task snapshot is captured (ID, command, timestamps) 2. Job is submitted to the scheduler 3. Command runs asynchronously via <code>asyncio.subprocess</code> 4. stdout, stderr, and exit code are captured</p>"},{"location":"guides/task-execution/#artifact-storage","title":"Artifact Storage","text":"<p>Execution results are stored as Artifacts: - task: Full snapshot of the task template at execution time - stdout: Command standard output - stderr: Command standard error - exit_code: Process exit code</p> <p>The Job record links to the result artifact via <code>Job.artifact_id</code>.</p> <p>Benefits: - Tasks remain reusable templates - Complete execution history preserved - Modifying task doesn't affect past results - Deleting task preserves execution artifacts</p>"},{"location":"guides/task-execution/#python-task-execution","title":"Python Task Execution","text":"<p>In addition to shell commands, Chapkit supports executing registered Python functions as tasks. This provides type-safe, IDE-friendly task execution with parameter validation.</p>"},{"location":"guides/task-execution/#taskregistry","title":"TaskRegistry","text":"<p>Python functions must be registered before they can be executed as tasks. This prevents arbitrary code execution and ensures all callable functions are explicitly defined.</p> <p>Registration Methods:</p> <p>1. Decorator Registration: <pre><code>from chapkit import TaskRegistry\n\n@TaskRegistry.register(\"calculate_sum\")\nasync def calculate_sum(a: int, b: int) -&gt; dict:\n    \"\"\"Calculate sum of two numbers asynchronously.\"\"\"\n    await asyncio.sleep(0.1)  # Simulate async work\n    return {\"result\": a + b, \"operation\": \"sum\"}\n\n@TaskRegistry.register(\"process_data\")\ndef process_data(input_text: str, uppercase: bool = False) -&gt; dict:\n    \"\"\"Process text data synchronously.\"\"\"\n    result = input_text.upper() if uppercase else input_text.lower()\n    return {\"processed\": result, \"original\": input_text}\n</code></pre></p> <p>2. Imperative Registration: <pre><code>def my_function(param: str) -&gt; dict:\n    return {\"result\": f\"Processed {param}\"}\n\nTaskRegistry.register_function(\"my_task\", my_function)\n</code></pre></p>"},{"location":"guides/task-execution/#creating-python-tasks","title":"Creating Python Tasks","text":"<p>Python tasks use <code>task_type=\"python\"</code> and accept a <code>parameters</code> dict:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/tasks \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"command\": \"calculate_sum\",\n    \"task_type\": \"python\",\n    \"parameters\": {\"a\": 10, \"b\": 32}\n  }'\n</code></pre> <p>Field Mapping: - <code>command</code> - Name of registered function (not the function body) - <code>task_type</code> - Must be \"python\" - <code>parameters</code> - Dict passed as kwargs to the function</p>"},{"location":"guides/task-execution/#python-task-artifacts","title":"Python Task Artifacts","text":"<p>Python task results have a different structure than shell tasks:</p> <p>Successful Execution: <pre><code>{\n  \"task\": {\n    \"id\": \"01TASK...\",\n    \"command\": \"calculate_sum\",\n    \"task_type\": \"python\",\n    \"parameters\": {\"a\": 10, \"b\": 32},\n    \"created_at\": \"2025-10-17T...\",\n    \"updated_at\": \"2025-10-17T...\"\n  },\n  \"result\": {\n    \"result\": 42,\n    \"operation\": \"sum\"\n  },\n  \"error\": null\n}\n</code></pre></p> <p>Failed Execution: <pre><code>{\n  \"task\": {...},\n  \"result\": null,\n  \"error\": {\n    \"type\": \"ValueError\",\n    \"message\": \"Invalid parameter value\",\n    \"traceback\": \"Traceback (most recent call last):\\n...\"\n  }\n}\n</code></pre></p> <p>Comparison with Shell Tasks:</p> Feature Shell Tasks Python Tasks Output fields <code>stdout</code>, <code>stderr</code>, <code>exit_code</code> <code>result</code>, <code>error</code> Success indicator <code>exit_code == 0</code> <code>error == null</code> Error info <code>stderr</code> text Full exception with traceback Return value Command output text Any JSON-serializable Python object"},{"location":"guides/task-execution/#sync-vs-async-functions","title":"Sync vs Async Functions","text":"<p>TaskRegistry supports both synchronous and asynchronous functions:</p> <pre><code># Async function - awaited directly\n@TaskRegistry.register(\"async_task\")\nasync def async_task(param: str) -&gt; dict:\n    await asyncio.sleep(1)\n    return {\"result\": param}\n\n# Sync function - executed in thread pool\n@TaskRegistry.register(\"sync_task\")\ndef sync_task(param: str) -&gt; dict:\n    import time\n    time.sleep(1)  # Blocking operation\n    return {\"result\": param}\n</code></pre> <p>Synchronous functions are executed in a thread pool via <code>asyncio.to_thread()</code> to prevent blocking the event loop.</p>"},{"location":"guides/task-execution/#dependency-injection","title":"Dependency Injection","text":"<p>Python task functions support type-based dependency injection for framework services. The framework automatically injects dependencies based on parameter type hints, while user parameters come from <code>task.parameters</code>.</p>"},{"location":"guides/task-execution/#injectable-types-reference","title":"Injectable Types Reference","text":"Type Description Use Case <code>AsyncSession</code> SQLAlchemy async database session Database queries, ORM operations <code>Database</code> chapkit Database instance Creating sessions, database operations <code>ArtifactManager</code> Artifact management service Saving/loading artifacts during execution <code>JobScheduler</code> Job scheduling service Submitting child jobs, job management <p>Location: Defined in <code>src/chapkit/modules/task/manager.py</code> as <code>INJECTABLE_TYPES</code></p>"},{"location":"guides/task-execution/#basic-injection","title":"Basic Injection","text":"<p>Functions request framework services via type hints:</p> <pre><code>from sqlalchemy.ext.asyncio import AsyncSession\nfrom chapkit import TaskRegistry\n\n@TaskRegistry.register(\"query_task_count\")\nasync def query_task_count(session: AsyncSession) -&gt; dict:\n    \"\"\"Task that queries database using injected session.\"\"\"\n    from sqlalchemy import select, func\n    from chapkit.modules.task.models import Task\n\n    # Use injected session\n    stmt = select(func.count()).select_from(Task)\n    result = await session.execute(stmt)\n    count = result.scalar() or 0\n\n    return {\n        \"total_tasks\": count,\n        \"timestamp\": datetime.now(timezone.utc).isoformat(),\n    }\n</code></pre> <p>Execution - No parameters needed: <pre><code>{\n  \"command\": \"query_task_count\",\n  \"task_type\": \"python\",\n  \"parameters\": {}\n}\n</code></pre></p>"},{"location":"guides/task-execution/#mixed-parameters","title":"Mixed Parameters","text":"<p>Combine user parameters with injected dependencies:</p> <pre><code>@TaskRegistry.register(\"process_with_db\")\nasync def process_with_db(\n    input_text: str,        # From task.parameters\n    count: int,             # From task.parameters\n    session: AsyncSession,  # Injected by framework\n) -&gt; dict:\n    \"\"\"Mix user params and framework injection.\"\"\"\n    # Perform database operations using session\n    # Process user-provided input_text and count\n    return {\"processed\": input_text, \"count\": count}\n</code></pre> <p>Execution: <pre><code>{\n  \"command\": \"process_with_db\",\n  \"task_type\": \"python\",\n  \"parameters\": {\n    \"input_text\": \"Hello\",\n    \"count\": 42\n  }\n}\n</code></pre></p> <p>Parameter Sources: - User parameters: Primitives (<code>str</code>, <code>int</code>, <code>dict</code>) and generic types (<code>pd.DataFrame</code>) - Framework parameters: Injectable types from the table above</p>"},{"location":"guides/task-execution/#optional-injection","title":"Optional Injection","text":"<p>Use Optional types for optional dependencies:</p> <pre><code>@TaskRegistry.register(\"optional_db_task\")\nasync def optional_db_task(\n    data: dict,                        # From task.parameters (required)\n    session: AsyncSession | None = None,  # Injected if available (optional)\n) -&gt; dict:\n    \"\"\"Task with optional session injection.\"\"\"\n    if session:\n        # Use database if session available\n        pass\n    return {\"processed\": data}\n</code></pre>"},{"location":"guides/task-execution/#flexible-naming","title":"Flexible Naming","text":"<p>Parameter names don't matter - only types:</p> <pre><code># All of these work - framework matches by type\nasync def task_a(session: AsyncSession) -&gt; dict: ...\nasync def task_b(db_session: AsyncSession) -&gt; dict: ...\nasync def task_c(conn: AsyncSession) -&gt; dict: ...\n</code></pre> <p>This allows natural, readable parameter names in your functions.</p>"},{"location":"guides/task-execution/#multiple-injections","title":"Multiple Injections","text":"<p>Inject multiple framework services:</p> <pre><code>from chapkit import Database, ArtifactManager\n\n@TaskRegistry.register(\"complex_task\")\nasync def complex_task(\n    input_data: dict,                    # From task.parameters\n    database: Database,                  # Injected\n    artifact_manager: ArtifactManager,   # Injected\n    session: AsyncSession,               # Injected\n) -&gt; dict:\n    \"\"\"Task using multiple framework services.\"\"\"\n    # Use all injected services\n    return {\"result\": \"processed\"}\n</code></pre>"},{"location":"guides/task-execution/#error-handling","title":"Error Handling","text":"<p>Missing required user parameters raise clear errors:</p> <pre><code>@TaskRegistry.register(\"needs_param\")\nasync def needs_param(name: str, session: AsyncSession) -&gt; dict:\n    return {\"name\": name}\n\n# Executing without 'name' parameter:\n{\n  \"command\": \"needs_param\",\n  \"task_type\": \"python\",\n  \"parameters\": {}  # Missing 'name'\n}\n\n# Error captured in artifact:\n{\n  \"error\": {\n    \"type\": \"ValueError\",\n    \"message\": \"Missing required parameter 'name' for task function.\n                Parameter is not injectable and not provided in task.parameters.\"\n  }\n}\n</code></pre>"},{"location":"guides/task-execution/#best-practices","title":"Best Practices","text":"<p>DO: - Use type hints for all parameters - Request only needed framework services - Use descriptive parameter names - Combine user parameters with injections naturally</p> <p>DON'T: - Mix user and framework parameter types (primitives vs injectable types are clear) - Forget type hints (injection requires them) - Assume services are always available (use Optional for optional deps)</p>"},{"location":"guides/task-execution/#example-database-query-task","title":"Example: Database Query Task","text":"<p>Complete example combining injection with user parameters:</p> <pre><code>@TaskRegistry.register(\"search_tasks\")\nasync def search_tasks(\n    command_pattern: str,           # User parameter\n    enabled_only: bool = True,      # User parameter with default\n    session: AsyncSession,           # Injected\n) -&gt; dict:\n    \"\"\"Search for tasks matching a pattern.\"\"\"\n    from sqlalchemy import select\n    from chapkit.modules.task.models import Task\n\n    # Build query using injected session\n    stmt = select(Task).where(Task.command.like(f\"%{command_pattern}%\"))\n\n    if enabled_only:\n        stmt = stmt.where(Task.enabled == True)\n\n    result = await session.execute(stmt)\n    tasks = result.scalars().all()\n\n    return {\n        \"matches\": len(tasks),\n        \"tasks\": [{\"id\": str(t.id), \"command\": t.command} for t in tasks],\n    }\n</code></pre> <p>Usage: <pre><code>curl -X POST http://localhost:8000/api/v1/tasks \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"command\": \"search_tasks\",\n    \"task_type\": \"python\",\n    \"parameters\": {\n      \"command_pattern\": \"echo\",\n      \"enabled_only\": true\n    }\n  }'\n</code></pre></p>"},{"location":"guides/task-execution/#complete-example","title":"Complete Example","text":"<p>See <code>examples/python_task_execution_api.py</code> for a complete working example with: - Multiple registered functions (async and sync) - Error handling demonstrations - Mixed shell and Python tasks - Seeded example tasks</p>"},{"location":"guides/task-execution/#task-lifecycle","title":"Task Lifecycle","text":"<pre><code>1. CREATE TEMPLATE          2. EXECUTE              3. RESULTS STORED\n   POST /tasks             POST /tasks/:id/$execute   Artifact created\n   \u2514\u2500&gt; Task stored         \u2514\u2500&gt; Job submitted          \u2514\u2500&gt; Job.artifact_id\n       (reusable)              (async execution)          (immutable result)\n</code></pre>"},{"location":"guides/task-execution/#state-transitions","title":"State Transitions","text":"<p>Task: Stateless template (no execution state)</p> <p>Job: Tracks execution state - <code>pending</code> \u2192 <code>running</code> \u2192 <code>completed</code> (success)                        \u2192 <code>failed</code> (error)                        \u2192 <code>canceled</code> (user canceled)</p> <p>Artifact: Immutable result record containing task snapshot + outputs</p>"},{"location":"guides/task-execution/#servicebuilder-setup","title":"ServiceBuilder Setup","text":""},{"location":"guides/task-execution/#minimal-configuration","title":"Minimal Configuration","text":"<pre><code>from chapkit import ArtifactHierarchy\nfrom chapkit.api import ServiceBuilder, ServiceInfo\n\n# Simple hierarchy for task execution artifacts\nTASK_HIERARCHY = ArtifactHierarchy(\n    name=\"task_executions\",\n    level_labels={0: \"execution\"},\n)\n\napp = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"Task Service\"))\n    .with_health()\n    .with_artifacts(hierarchy=TASK_HIERARCHY)  # Required first\n    .with_jobs(max_concurrency=5)              # Required second\n    .with_tasks()                               # Enables task execution\n    .build()\n)\n</code></pre> <p>Requirements: 1. <code>.with_artifacts()</code> must be called before <code>.with_tasks()</code> 2. <code>.with_jobs()</code> must be called before <code>.with_tasks()</code> 3. Without these, <code>execute_task()</code> will raise <code>ValueError</code></p>"},{"location":"guides/task-execution/#with-database-configuration","title":"With Database Configuration","text":"<pre><code>app = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"Task Service\"))\n    .with_database(\"tasks.db\")  # Persist tasks and artifacts\n    .with_artifacts(hierarchy=TASK_HIERARCHY)\n    .with_jobs(max_concurrency=3)\n    .with_tasks()\n    .build()\n)\n</code></pre>"},{"location":"guides/task-execution/#api-reference","title":"API Reference","text":""},{"location":"guides/task-execution/#post-apiv1tasks","title":"POST /api/v1/tasks","text":"<p>Create a new task template (shell or Python).</p> <p>Request (Shell Task): <pre><code>{\n  \"command\": \"echo 'Hello World'\"\n}\n</code></pre></p> <p>Request (Python Task): <pre><code>{\n  \"command\": \"calculate_sum\",\n  \"task_type\": \"python\",\n  \"parameters\": {\"a\": 10, \"b\": 32}\n}\n</code></pre></p> <p>Fields: - <code>command</code> (required) - Shell command or registered Python function name - <code>task_type</code> (optional) - \"shell\" (default) or \"python\" - <code>parameters</code> (optional) - Dict of parameters for Python tasks (ignored for shell tasks) - <code>enabled</code> (optional) - Boolean to enable/disable task execution (default: true)</p> <p>Response (201): <pre><code>{\n  \"id\": \"01JCSEED0000000000000TASK1\",\n  \"command\": \"calculate_sum\",\n  \"task_type\": \"python\",\n  \"parameters\": {\"a\": 10, \"b\": 32},\n  \"enabled\": true,\n  \"created_at\": \"2025-10-14T10:30:00Z\",\n  \"updated_at\": \"2025-10-14T10:30:00Z\"\n}\n</code></pre></p>"},{"location":"guides/task-execution/#get-apiv1tasks","title":"GET /api/v1/tasks","text":"<p>List all task templates with optional pagination and filtering.</p> <pre><code># List all tasks\ncurl http://localhost:8000/api/v1/tasks\n\n# Filter by enabled status\ncurl http://localhost:8000/api/v1/tasks?enabled=true   # Only enabled tasks\ncurl http://localhost:8000/api/v1/tasks?enabled=false  # Only disabled tasks\n\n# With pagination\ncurl http://localhost:8000/api/v1/tasks?page=1&amp;size=20\n\n# Combine filters\ncurl http://localhost:8000/api/v1/tasks?enabled=true&amp;page=1&amp;size=10\n</code></pre> <p>Response: <pre><code>[\n  {\n    \"id\": \"01JCSEED0000000000000TASK1\",\n    \"command\": \"ls -la /tmp\",\n    \"task_type\": \"shell\",\n    \"parameters\": null,\n    \"enabled\": true,\n    \"created_at\": \"2025-10-14T10:30:00Z\",\n    \"updated_at\": \"2025-10-14T10:30:00Z\"\n  },\n  {\n    \"id\": \"01JCSEED0000000000000TASK2\",\n    \"command\": \"calculate_sum\",\n    \"task_type\": \"python\",\n    \"parameters\": {\"a\": 10, \"b\": 32},\n    \"enabled\": false,\n    \"created_at\": \"2025-10-14T10:30:00Z\",\n    \"updated_at\": \"2025-10-14T10:30:00Z\"\n  }\n]\n</code></pre></p>"},{"location":"guides/task-execution/#get-apiv1taskstask_id","title":"GET /api/v1/tasks/{task_id}","text":"<p>Retrieve a specific task template by ID.</p> <pre><code>curl http://localhost:8000/api/v1/tasks/01JCSEED0000000000000TASK1\n</code></pre>"},{"location":"guides/task-execution/#put-apiv1taskstask_id","title":"PUT /api/v1/tasks/{task_id}","text":"<p>Update a task template.</p> <p>Request: <pre><code>{\n  \"command\": \"echo 'Updated command'\",\n  \"task_type\": \"shell\"\n}\n</code></pre></p> <p>Note: Updating a task does not affect previous execution artifacts. You can change task_type and parameters when updating.</p>"},{"location":"guides/task-execution/#delete-apiv1taskstask_id","title":"DELETE /api/v1/tasks/{task_id}","text":"<p>Delete a task template.</p> <pre><code>curl -X DELETE http://localhost:8000/api/v1/tasks/01JCSEED0000000000000TASK1\n</code></pre> <p>Returns <code>204 No Content</code> on success.</p> <p>Note: Deleting a task preserves all execution artifacts.</p>"},{"location":"guides/task-execution/#post-apiv1taskstask_idexecute","title":"POST /api/v1/tasks/{task_id}/$execute","text":"<p>Execute a task asynchronously.</p> <pre><code>curl -X POST http://localhost:8000/api/v1/tasks/01JCSEED0000000000000TASK1/\\$execute\n</code></pre> <p>Response (202 Accepted): <pre><code>{\n  \"job_id\": \"01JQR7X...\",\n  \"message\": \"Task submitted for execution. Job ID: 01JQR7X...\"\n}\n</code></pre></p> <p>Errors: - <code>400 Bad Request</code> - Task not found, invalid ID, or task is disabled - <code>409 Conflict</code> - Scheduler or artifact manager not configured</p>"},{"location":"guides/task-execution/#task-enabledisable","title":"Task Enable/Disable","text":"<p>Tasks can be enabled or disabled to control execution. Disabled tasks cannot be executed but remain in the database for reference.</p> <p>Creating a Disabled Task: <pre><code>curl -X POST http://localhost:8000/api/v1/tasks \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"command\": \"echo test\",\n    \"enabled\": false\n  }'\n</code></pre></p> <p>Disabling an Existing Task: <pre><code>curl -X PUT http://localhost:8000/api/v1/tasks/{task_id} \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"command\": \"echo test\",\n    \"enabled\": false\n  }'\n</code></pre></p> <p>Attempting to Execute a Disabled Task: <pre><code>curl -X POST http://localhost:8000/api/v1/tasks/{disabled_task_id}/\\$execute\n</code></pre></p> <p>Response (400): <pre><code>{\n  \"detail\": \"Cannot execute disabled task {task_id}\"\n}\n</code></pre></p> <p>Use Cases: - Temporarily pause task execution without deletion - Preserve task history while preventing new executions - Automatically disable orphaned Python tasks (see Orphaned Tasks section) - Soft-delete pattern for auditing and compliance</p>"},{"location":"guides/task-execution/#artifact-integration","title":"Artifact Integration","text":""},{"location":"guides/task-execution/#result-structure","title":"Result Structure","text":"<p>Each execution creates an artifact with this structure:</p> <pre><code>{\n  \"id\": \"01ARTIFACT...\",\n  \"data\": {\n    \"task\": {\n      \"id\": \"01TASK...\",\n      \"command\": \"echo 'test'\",\n      \"created_at\": \"2025-10-14T10:30:00Z\",\n      \"updated_at\": \"2025-10-14T10:30:00Z\"\n    },\n    \"stdout\": \"test\\n\",\n    \"stderr\": \"\",\n    \"exit_code\": 0\n  },\n  \"created_at\": \"2025-10-14T10:31:00Z\",\n  \"updated_at\": \"2025-10-14T10:31:00Z\"\n}\n</code></pre>"},{"location":"guides/task-execution/#task-snapshot-preservation","title":"Task Snapshot Preservation","text":"<p>The artifact contains a complete snapshot of the task at execution time:</p> <pre><code># Create task\ncurl -X POST http://localhost:8000/api/v1/tasks \\\n  -d '{\"command\": \"echo original\"}' &gt; task.json\nTASK_ID=$(jq -r '.id' task.json)\n\n# Execute task\ncurl -X POST http://localhost:8000/api/v1/tasks/$TASK_ID/\\$execute &gt; exec1.json\nJOB1=$(jq -r '.job_id' exec1.json)\n\n# Modify task\ncurl -X PUT http://localhost:8000/api/v1/tasks/$TASK_ID \\\n  -d '{\"command\": \"echo modified\"}'\n\n# Execute again\ncurl -X POST http://localhost:8000/api/v1/tasks/$TASK_ID/\\$execute &gt; exec2.json\nJOB2=$(jq -r '.job_id' exec2.json)\n\n# First execution has original command\ncurl http://localhost:8000/api/v1/jobs/$JOB1 | jq '.artifact_id' | \\\n  xargs -I {} curl http://localhost:8000/api/v1/artifacts/{} | \\\n  jq '.data.task.command'\n# Output: \"echo original\"\n\n# Second execution has modified command\ncurl http://localhost:8000/api/v1/jobs/$JOB2 | jq '.artifact_id' | \\\n  xargs -I {} curl http://localhost:8000/api/v1/artifacts/{} | \\\n  jq '.data.task.command'\n# Output: \"echo modified\"\n</code></pre>"},{"location":"guides/task-execution/#finding-task-executions","title":"Finding Task Executions","text":"<pre><code># Get all artifacts (includes task execution results)\ncurl http://localhost:8000/api/v1/artifacts\n\n# Filter by task ID in application code\nartifacts=$(curl -s http://localhost:8000/api/v1/artifacts)\necho \"$artifacts\" | jq --arg task_id \"$TASK_ID\" \\\n  '[.[] | select(.data.task.id == $task_id)]'\n</code></pre>"},{"location":"guides/task-execution/#examples","title":"Examples","text":""},{"location":"guides/task-execution/#shell-task-examples","title":"Shell Task Examples","text":"<p>Simple Commands:</p> <pre><code># Directory listing\ncurl -X POST http://localhost:8000/api/v1/tasks \\\n  -d '{\"command\": \"ls -la /tmp\"}' | jq -r '.id'\n\n# Date command\ncurl -X POST http://localhost:8000/api/v1/tasks \\\n  -d '{\"command\": \"date\"}' | jq -r '.id'\n\n# Echo with output\ncurl -X POST http://localhost:8000/api/v1/tasks \\\n  -d '{\"command\": \"echo \\\"Task execution works!\\\"\"}' | jq -r '.id'\n</code></pre> <p>Python One-liners (Shell Tasks):</p> <pre><code># Python one-liner as shell command\ncurl -X POST http://localhost:8000/api/v1/tasks -d '{\n  \"command\": \"python3 -c \\\"import sys; print(sys.version); print(2+2)\\\"\"\n}'\n\n# Python script with multiple operations\ncurl -X POST http://localhost:8000/api/v1/tasks -d '{\n  \"command\": \"python3 -c \\\"import json; print(json.dumps({\\\\\\\"result\\\\\\\": 42}))\\\"\"\n}'\n</code></pre>"},{"location":"guides/task-execution/#python-task-examples","title":"Python Task Examples","text":"<p>Async Function Execution:</p> <pre><code># Assuming you have registered this function:\n# @TaskRegistry.register(\"calculate_sum\")\n# async def calculate_sum(a: int, b: int) -&gt; dict:\n#     await asyncio.sleep(0.1)\n#     return {\"result\": a + b, \"operation\": \"sum\"}\n\n# Create Python task\nTASK_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"command\": \"calculate_sum\",\n    \"task_type\": \"python\",\n    \"parameters\": {\"a\": 15, \"b\": 27}\n  }' | jq -r '.id')\n\n# Execute task\nJOB_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks/$TASK_ID/\\$execute | jq -r '.job_id')\n\n# Wait and get result\nsleep 1\nARTIFACT_ID=$(curl -s http://localhost:8000/api/v1/jobs/$JOB_ID | jq -r '.artifact_id')\n\n# View result\ncurl -s http://localhost:8000/api/v1/artifacts/$ARTIFACT_ID | jq '.data.result'\n# Output: {\"result\": 42, \"operation\": \"sum\"}\n</code></pre> <p>Sync Function with Parameters:</p> <pre><code># Assuming you have registered:\n# @TaskRegistry.register(\"process_data\")\n# def process_data(input_text: str, uppercase: bool = False) -&gt; dict:\n#     result = input_text.upper() if uppercase else input_text.lower()\n#     return {\"processed\": result, \"original\": input_text}\n\ncurl -X POST http://localhost:8000/api/v1/tasks \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"command\": \"process_data\",\n    \"task_type\": \"python\",\n    \"parameters\": {\n      \"input_text\": \"Hello World\",\n      \"uppercase\": true\n    }\n  }'\n</code></pre> <p>Error Handling:</p> <pre><code># Assuming you have registered:\n# @TaskRegistry.register(\"failing_task\")\n# async def failing_task(should_fail: bool = True) -&gt; dict:\n#     if should_fail:\n#         raise ValueError(\"This task was designed to fail\")\n#     return {\"success\": True}\n\nTASK_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks \\\n  -d '{\n    \"command\": \"failing_task\",\n    \"task_type\": \"python\",\n    \"parameters\": {\"should_fail\": true}\n  }' | jq -r '.id')\n\n# Execute and check artifact\nJOB_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks/$TASK_ID/\\$execute | jq -r '.job_id')\nsleep 1\n\n# View error details\ncurl -s http://localhost:8000/api/v1/jobs/$JOB_ID | jq '.artifact_id' | \\\n  xargs -I {} curl -s http://localhost:8000/api/v1/artifacts/{} | jq '.data.error'\n\n# Output:\n# {\n#   \"type\": \"ValueError\",\n#   \"message\": \"This task was designed to fail\",\n#   \"traceback\": \"Traceback (most recent call last):\\n...\"\n# }\n</code></pre> <p>Complete Working Example:</p> <p>See <code>examples/python_task_execution_api.py</code> for a full service with: - Multiple registered functions (async and sync) - Error handling demonstrations - Mixed shell and Python tasks - Integration with ServiceBuilder</p>"},{"location":"guides/task-execution/#multi-line-commands","title":"Multi-line Commands","text":"<pre><code># Using printf for multi-line output\ncurl -X POST http://localhost:8000/api/v1/tasks -d '{\n  \"command\": \"printf \\\"Line 1\\\\nLine 2\\\\nLine 3\\\"\"\n}'\n\n# Using bash -c for complex commands\ncurl -X POST http://localhost:8000/api/v1/tasks -d '{\n  \"command\": \"bash -c \\\"for i in {1..5}; do echo Step $i; done\\\"\"\n}'\n</code></pre>"},{"location":"guides/task-execution/#failing-commands","title":"Failing Commands","text":"<pre><code># Command that fails (non-existent path)\ncurl -X POST http://localhost:8000/api/v1/tasks -d '{\n  \"command\": \"ls /nonexistent/directory\"\n}'\n\n# Execute and check results\nTASK_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks \\\n  -d '{\"command\": \"ls /nonexistent/directory\"}' | jq -r '.id')\n\nJOB_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks/$TASK_ID/\\$execute | jq -r '.job_id')\n\n# Wait and check artifact\nsleep 1\ncurl http://localhost:8000/api/v1/jobs/$JOB_ID | jq '.artifact_id' | \\\n  xargs -I {} curl http://localhost:8000/api/v1/artifacts/{} | jq '.data'\n\n# Output shows:\n# - exit_code: non-zero (e.g., 1 or 2)\n# - stderr: error message about missing directory\n# - Job status: \"completed\" (job succeeded even though command failed)\n</code></pre> <p>Note: Job status is <code>completed</code> even if command fails. Check <code>exit_code</code> in artifact to determine command success.</p>"},{"location":"guides/task-execution/#capturing-stderr","title":"Capturing stderr","text":"<pre><code># Write to stderr\ncurl -X POST http://localhost:8000/api/v1/tasks -d '{\n  \"command\": \"&gt;&amp;2 echo \\\"error message\\\"\"\n}'\n\n# Execute and check stderr in artifact\nTASK_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks \\\n  -d '{\"command\": \"&gt;&amp;2 echo \\\"error message\\\"\"}' | jq -r '.id')\nJOB_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks/$TASK_ID/\\$execute | jq -r '.job_id')\n\nsleep 1\ncurl http://localhost:8000/api/v1/jobs/$JOB_ID | jq '.artifact_id' | \\\n  xargs -I {} curl http://localhost:8000/api/v1/artifacts/{} | jq '.data.stderr'\n</code></pre>"},{"location":"guides/task-execution/#concurrent-execution","title":"Concurrent Execution","text":"<pre><code># Create task\nTASK_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks \\\n  -d '{\"command\": \"sleep 2 &amp;&amp; echo done\"}' | jq -r '.id')\n\n# Execute multiple times concurrently\nfor i in {1..5}; do\n  curl -s -X POST http://localhost:8000/api/v1/tasks/$TASK_ID/\\$execute &amp;\ndone\nwait\n\n# List all jobs to see concurrent executions\ncurl http://localhost:8000/api/v1/jobs | jq\n</code></pre>"},{"location":"guides/task-execution/#error-handling_1","title":"Error Handling","text":""},{"location":"guides/task-execution/#task-not-found-400","title":"Task Not Found (400)","text":"<pre><code>curl -X POST http://localhost:8000/api/v1/tasks/01K72P5N5KCRM6MD3BRE4P0999/\\$execute\n</code></pre> <p>Response: <pre><code>{\n  \"detail\": \"Task 01K72P5N5KCRM6MD3BRE4P0999 not found\"\n}\n</code></pre></p>"},{"location":"guides/task-execution/#invalid-ulid-400","title":"Invalid ULID (400)","text":"<pre><code>curl -X POST http://localhost:8000/api/v1/tasks/invalid-id/\\$execute\n</code></pre> <p>Response: <pre><code>{\n  \"type\": \"urn:chapkit:error:invalid-ulid\",\n  \"title\": \"Invalid ULID\",\n  \"status\": 400,\n  \"detail\": \"Invalid ULID format: invalid-id\"\n}\n</code></pre></p>"},{"location":"guides/task-execution/#missing-dependencies-409","title":"Missing Dependencies (409)","text":"<p>If <code>.with_artifacts()</code> or <code>.with_jobs()</code> not configured:</p> <pre><code>{\n  \"detail\": \"Task execution requires artifacts. Use ServiceBuilder.with_artifacts() before with_tasks().\"\n}\n</code></pre>"},{"location":"guides/task-execution/#validation-errors-422","title":"Validation Errors (422)","text":"<pre><code># Missing command field\ncurl -X POST http://localhost:8000/api/v1/tasks -d '{}'\n</code></pre> <p>Response: <pre><code>{\n  \"detail\": [\n    {\n      \"loc\": [\"body\", \"command\"],\n      \"msg\": \"field required\",\n      \"type\": \"value_error.missing\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"guides/task-execution/#testing","title":"Testing","text":""},{"location":"guides/task-execution/#manual-testing","title":"Manual Testing","text":"<p>Terminal 1: Start service <pre><code>fastapi dev examples/task_execution_api.py\n</code></pre></p> <p>Terminal 2: Test workflow <pre><code># Create task\nTASK_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"command\": \"echo \\\"test\\\"\"}' | jq -r '.id')\n\necho \"Task ID: $TASK_ID\"\n\n# Execute task\nJOB_ID=$(curl -s -X POST http://localhost:8000/api/v1/tasks/$TASK_ID/\\$execute | jq -r '.job_id')\n\necho \"Job ID: $JOB_ID\"\n\n# Monitor job status\ncurl -N http://localhost:8000/api/v1/jobs/$JOB_ID/\\$stream\n\n# Get results\nARTIFACT_ID=$(curl -s http://localhost:8000/api/v1/jobs/$JOB_ID | jq -r '.artifact_id')\ncurl http://localhost:8000/api/v1/artifacts/$ARTIFACT_ID | jq '.data'\n</code></pre></p>"},{"location":"guides/task-execution/#automated-testing","title":"Automated Testing","text":"<pre><code>import httpx\nimport time\nfrom collections.abc import Generator\n\ndef wait_for_job_completion(\n    client: httpx.Client,\n    job_id: str,\n    timeout: float = 5.0\n) -&gt; dict:\n    \"\"\"Poll job status until completion or timeout.\"\"\"\n    start_time = time.time()\n    while time.time() - start_time &lt; timeout:\n        response = client.get(f\"/api/v1/jobs/{job_id}\")\n        job = response.json()\n\n        if job[\"status\"] in [\"completed\", \"failed\", \"canceled\"]:\n            return job\n\n        time.sleep(0.1)\n\n    raise TimeoutError(f\"Job {job_id} did not complete within {timeout}s\")\n\n\ndef test_task_execution():\n    \"\"\"Test creating and executing a task.\"\"\"\n    with httpx.Client(base_url=\"http://localhost:8000\") as client:\n        # Create task\n        response = client.post(\n            \"/api/v1/tasks\",\n            json={\"command\": \"echo 'test'\"}\n        )\n        assert response.status_code == 201\n        task = response.json()\n        task_id = task[\"id\"]\n\n        # Execute task\n        response = client.post(f\"/api/v1/tasks/{task_id}/$execute\")\n        assert response.status_code == 202\n        job_id = response.json()[\"job_id\"]\n\n        # Wait for completion\n        job = wait_for_job_completion(client, job_id)\n        assert job[\"status\"] == \"completed\"\n        assert job[\"artifact_id\"] is not None\n\n        # Check artifact\n        response = client.get(f\"/api/v1/artifacts/{job['artifact_id']}\")\n        artifact = response.json()\n\n        assert artifact[\"data\"][\"task\"][\"id\"] == task_id\n        assert \"test\" in artifact[\"data\"][\"stdout\"]\n        assert artifact[\"data\"][\"exit_code\"] == 0\n</code></pre>"},{"location":"guides/task-execution/#pytest-with-testclient","title":"Pytest with TestClient","text":"<pre><code>import pytest\nfrom fastapi.testclient import TestClient\n\n@pytest.fixture(scope=\"module\")\ndef client() -&gt; Generator[TestClient, None, None]:\n    \"\"\"Create FastAPI TestClient with lifespan context.\"\"\"\n    from examples.task_execution_api import app\n\n    with TestClient(app) as test_client:\n        yield test_client\n\n\ndef test_create_task(client: TestClient) -&gt; None:\n    \"\"\"Test creating a new task template.\"\"\"\n    response = client.post(\n        \"/api/v1/tasks\",\n        json={\"command\": \"echo 'test'\"}\n    )\n    assert response.status_code == 201\n    task = response.json()\n\n    assert \"id\" in task\n    assert task[\"command\"] == \"echo 'test'\"\n    assert \"created_at\" in task\n\n\ndef test_execute_task(client: TestClient) -&gt; None:\n    \"\"\"Test executing a task and retrieving results.\"\"\"\n    # Create task\n    response = client.post(\n        \"/api/v1/tasks\",\n        json={\"command\": \"echo 'Hello World'\"}\n    )\n    task_id = response.json()[\"id\"]\n\n    # Execute\n    response = client.post(f\"/api/v1/tasks/{task_id}/$execute\")\n    assert response.status_code == 202\n    job_id = response.json()[\"job_id\"]\n\n    # Wait for completion\n    import time\n    time.sleep(1)\n\n    # Get results\n    job = client.get(f\"/api/v1/jobs/{job_id}\").json()\n    artifact = client.get(f\"/api/v1/artifacts/{job['artifact_id']}\").json()\n\n    assert \"Hello World\" in artifact[\"data\"][\"stdout\"]\n    assert artifact[\"data\"][\"exit_code\"] == 0\n</code></pre>"},{"location":"guides/task-execution/#production-deployment","title":"Production Deployment","text":""},{"location":"guides/task-execution/#concurrency-control","title":"Concurrency Control","text":"<p>Limit concurrent task executions to prevent resource exhaustion:</p> <pre><code>app = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"Task Service\"))\n    .with_artifacts(hierarchy=TASK_HIERARCHY)\n    .with_jobs(max_concurrency=5)  # Max 5 tasks running simultaneously\n    .with_tasks()\n    .build()\n)\n</code></pre> <p>Recommendations: - CPU-bound tasks: Set to number of CPU cores (e.g., 4-8) - I/O-bound tasks: Higher limits OK (10-20) - Memory-intensive: Lower limits to prevent OOM (2-5) - Long-running: Consider lower limits (3-5)</p>"},{"location":"guides/task-execution/#database-configuration","title":"Database Configuration","text":"<p>Use persistent database for production:</p> <pre><code>app = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"Task Service\"))\n    .with_database(\"/data/tasks.db\")  # Persistent storage\n    .with_artifacts(hierarchy=TASK_HIERARCHY)\n    .with_jobs(max_concurrency=5)\n    .with_tasks()\n    .build()\n)\n</code></pre> <p>Best Practices: - Mount <code>/data</code> volume in Docker/Kubernetes - Regular backups of task templates and artifacts - Monitor database size (artifacts can grow)</p>"},{"location":"guides/task-execution/#task-retention","title":"Task Retention","text":"<p>Implement cleanup for old execution artifacts:</p> <pre><code>from datetime import datetime, timedelta\nfrom chapkit.api import ServiceBuilder\n\nasync def cleanup_old_artifacts(app):\n    \"\"\"Remove artifacts older than 30 days.\"\"\"\n    artifact_manager = app.state.artifact_manager\n\n    cutoff_date = datetime.utcnow() - timedelta(days=30)\n\n    # Implementation depends on your retention policy\n    # Consider using artifact metadata or timestamps\n    pass\n\napp = (\n    ServiceBuilder(info=info)\n    .with_artifacts(hierarchy=TASK_HIERARCHY)\n    .with_jobs(max_concurrency=5)\n    .with_tasks()\n    .on_startup(cleanup_old_artifacts)  # Run on startup\n    .build()\n)\n</code></pre>"},{"location":"guides/task-execution/#monitoring","title":"Monitoring","text":"<p>Track task execution metrics:</p> <pre><code>from prometheus_client import Counter, Histogram\n\ntask_executions = Counter(\n    'task_executions_total',\n    'Total task executions',\n    ['status']\n)\n\ntask_duration = Histogram(\n    'task_duration_seconds',\n    'Task execution duration'\n)\n\n# Combine with monitoring feature\napp = (\n    ServiceBuilder(info=info)\n    .with_monitoring()  # Prometheus metrics at /metrics\n    .with_artifacts(hierarchy=TASK_HIERARCHY)\n    .with_jobs(max_concurrency=5)\n    .with_tasks()\n    .build()\n)\n</code></pre>"},{"location":"guides/task-execution/#security-considerations","title":"Security Considerations","text":"<p>Command Injection Prevention:</p> <p>Tasks execute arbitrary shell commands. Implement access controls using CRUD permissions:</p> <pre><code>from chapkit.core.api.crud import CrudPermissions\nfrom chapkit.api import ServiceBuilder, ServiceInfo\n\n# Read-only task API (tasks created only via code)\ntask_permissions = CrudPermissions(\n    allow_create=False,    # Disable runtime task creation\n    allow_read=True,       # Allow reading tasks\n    allow_update=False,    # Disable runtime updates\n    allow_delete=False,    # Disable deletion\n)\n\napp = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"Task Service\"))\n    .with_database(\"tasks.db\")\n    .with_artifacts(hierarchy=TASK_HIERARCHY)\n    .with_jobs(max_concurrency=5)\n    .with_tasks(permissions=task_permissions)  # Apply permissions\n    .build()\n)\n</code></pre> <p>Read-Only API Pattern:</p> <p>With read-only permissions, all tasks are pre-seeded at startup:</p> <pre><code>from chapkit import TaskIn, TaskManager\n\nasync def seed_tasks(app):\n    \"\"\"Pre-seed task templates on startup.\"\"\"\n    task_manager = app.state.task_manager\n\n    # Define tasks programmatically\n    tasks = [\n        TaskIn(command=\"echo 'System health check'\", enabled=True),\n        TaskIn(command=\"python3 /app/backup.py\", enabled=True),\n        TaskIn(command=\"process_data\", task_type=\"python\",\n               parameters={\"batch_size\": 100}, enabled=True),\n    ]\n\n    for task in tasks:\n        await task_manager.save(task)\n\napp = (\n    ServiceBuilder(info=info)\n    .with_database(\"tasks.db\")\n    .with_artifacts(hierarchy=TASK_HIERARCHY)\n    .with_jobs(max_concurrency=5)\n    .with_tasks(permissions=CrudPermissions(\n        allow_create=False,\n        allow_read=True,\n        allow_update=False,\n        allow_delete=False,\n    ))\n    .on_startup(seed_tasks)\n    .build()\n)\n</code></pre> <p>Benefits: - Tasks defined in code (version controlled) - No runtime command injection risk - API users can only execute pre-defined tasks - Tasks can be audited before deployment - Enables GitOps workflow for task management</p> <p>Recommendations: - Use read-only API for production (pre-seed tasks at startup) - Apply authentication (<code>.with_auth()</code>) for execution endpoint - Validate commands in seeding logic - Run service with limited OS user permissions - Use container security (no privileged mode) - Monitor execution logs for suspicious activity - Use <code>validate_and_disable_orphaned_tasks</code> to prevent broken Python tasks</p>"},{"location":"guides/task-execution/#docker-deployment","title":"Docker Deployment","text":"<p>Dockerfile: <pre><code>FROM python:3.13-slim\n\nWORKDIR /app\n\n# Copy application\nCOPY . /app\n\n# Install dependencies\nRUN pip install --no-cache-dir -e .\n\n# Create non-root user\nRUN useradd -m -u 1000 taskuser &amp;&amp; \\\n    chown -R taskuser:taskuser /app\n\nUSER taskuser\n\n# Run service\nCMD [\"fastapi\", \"run\", \"examples/task_execution_api.py\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre></p> <p>docker-compose.yml: <pre><code>version: '3.8'\n\nservices:\n  task-service:\n    build: .\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - task-data:/data\n    environment:\n      - DATABASE_URL=/data/tasks.db\n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 2G\n\nvolumes:\n  task-data:\n</code></pre></p>"},{"location":"guides/task-execution/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/task-execution/#job-status-is-completed-but-command-failed","title":"Job Status is \"completed\" but Command Failed","text":"<p>Problem: Job shows <code>status: completed</code> but command actually failed.</p> <p>Cause: Job execution succeeded (subprocess ran), but command returned non-zero exit code.</p> <p>Solution: Check <code>exit_code</code> in artifact:</p> <pre><code>curl http://localhost:8000/api/v1/jobs/$JOB_ID | jq '.artifact_id' | \\\n  xargs -I {} curl http://localhost:8000/api/v1/artifacts/{} | \\\n  jq '.data.exit_code'\n\n# exit_code == 0: command succeeded\n# exit_code != 0: command failed\n</code></pre>"},{"location":"guides/task-execution/#task-execution-requires-artifacts-error","title":"\"Task execution requires artifacts\" Error","text":"<p>Problem: <code>ValueError: Task execution requires artifacts</code></p> <p>Solution: Call <code>.with_artifacts()</code> before <code>.with_tasks()</code>:</p> <pre><code># Wrong order\n.with_tasks()\n.with_artifacts(hierarchy=TASK_HIERARCHY)  # Too late!\n\n# Correct order\n.with_artifacts(hierarchy=TASK_HIERARCHY)\n.with_tasks()\n</code></pre>"},{"location":"guides/task-execution/#task-execution-requires-a-scheduler-error","title":"\"Task execution requires a scheduler\" Error","text":"<p>Problem: <code>ValueError: Task execution requires a scheduler</code></p> <p>Solution: Call <code>.with_jobs()</code> before <code>.with_tasks()</code>:</p> <pre><code># Wrong order\n.with_tasks()\n.with_jobs()  # Too late!\n\n# Correct order\n.with_jobs(max_concurrency=5)\n.with_tasks()\n</code></pre>"},{"location":"guides/task-execution/#jobs-not-executing-stuck-in-pending","title":"Jobs Not Executing (Stuck in \"pending\")","text":"<p>Problem: Jobs remain in <code>pending</code> state indefinitely.</p> <p>Causes: 1. Reached <code>max_concurrency</code> limit 2. Scheduler not started properly 3. Long-running jobs blocking queue</p> <p>Solution: <pre><code># Check running jobs\ncurl http://localhost:8000/api/v1/jobs?status_filter=running | jq 'length'\n\n# If at max_concurrency, wait for completion or increase limit\n# Restart service to reset scheduler if needed\n</code></pre></p>"},{"location":"guides/task-execution/#artifact-not-created","title":"Artifact Not Created","text":"<p>Problem: <code>Job.artifact_id</code> is <code>null</code> after completion.</p> <p>Cause: Job failed during execution (before artifact creation).</p> <p>Solution: Check job error:</p> <pre><code>curl http://localhost:8000/api/v1/jobs/$JOB_ID | jq '.error'\n</code></pre>"},{"location":"guides/task-execution/#command-not-found-in-container","title":"Command Not Found in Container","text":"<p>Problem: Task works locally but fails in Docker with \"command not found\".</p> <p>Cause: Command not installed in container image.</p> <p>Solution: Install required tools in Dockerfile:</p> <pre><code># Install common utilities\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    curl \\\n    jq \\\n    python3 \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n</code></pre>"},{"location":"guides/task-execution/#orphaned-python-tasks","title":"Orphaned Python Tasks","text":"<p>Problem: Python task references a function that was removed or renamed from the registry.</p> <p>Cause: Function was removed or renamed but task template still references the old name.</p> <p>Automatic Disabling (Recommended):</p> <p>Chapkit provides a startup validation utility that automatically disables orphaned Python tasks:</p> <pre><code>from chapkit import validate_and_disable_orphaned_tasks\nfrom chapkit.api import ServiceBuilder, ServiceInfo\n\napp = (\n    ServiceBuilder(info=ServiceInfo(display_name=\"Task Service\"))\n    .with_database(\"tasks.db\")\n    .with_artifacts(hierarchy=TASK_HIERARCHY)\n    .with_jobs(max_concurrency=5)\n    .with_tasks()\n    .on_startup(validate_and_disable_orphaned_tasks)\n    .build()\n)\n</code></pre> <p>Behavior: - Checks all Python tasks against <code>TaskRegistry</code> on startup - Automatically disables tasks referencing unregistered functions - Logs warnings for each orphaned task with task IDs and function names - Preserves task history (soft-delete via <code>enabled=False</code>) - Returns count of disabled tasks</p> <p>Example Log Output: <pre><code>WARNING Found orphaned Python tasks - disabling them\n  count: 2\n  task_ids: ['01TASK1...', '01TASK2...']\n  commands: ['old_function', 'removed_function']\nINFO Disabling orphaned task 01TASK1...: function 'old_function' not found in registry\nINFO Disabling orphaned task 01TASK2...: function 'removed_function' not found in registry\nWARNING Disabled 2 orphaned Python task(s)\n</code></pre></p> <p>Filtering Disabled Tasks: <pre><code># List all disabled tasks\ncurl http://localhost:8000/api/v1/tasks?enabled=false\n\n# List only enabled tasks\ncurl http://localhost:8000/api/v1/tasks?enabled=true\n</code></pre></p> <p>Re-enabling Tasks: If you re-register the function, you can re-enable the task:</p> <pre><code># Re-register the function\n@TaskRegistry.register(\"old_function\")\ndef old_function(**params) -&gt; dict:\n    return {\"result\": \"restored\"}\n</code></pre> <pre><code># Re-enable the task\ncurl -X PUT http://localhost:8000/api/v1/tasks/{task_id} \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"command\": \"old_function\",\n    \"task_type\": \"python\",\n    \"enabled\": true\n  }'\n</code></pre> <p>Alternative Solutions:</p> <p>Option 1: Keep deprecated functions with errors <pre><code>@TaskRegistry.register(\"old_function\")\ndef old_function(**params) -&gt; dict:\n    \"\"\"Deprecated - use new_function instead.\"\"\"\n    raise NotImplementedError(\"This function has been removed. Use new_function instead.\")\n</code></pre></p> <p>Option 2: Manual deletion <pre><code># Find orphaned tasks\ncurl http://localhost:8000/api/v1/tasks?enabled=false | \\\n  jq '.[] | select(.task_type == \"python\")'\n\n# Delete specific task\ncurl -X DELETE http://localhost:8000/api/v1/tasks/{task_id}\n</code></pre></p> <p>Best Practices: - Always use <code>validate_and_disable_orphaned_tasks</code> on startup (production ready) - Monitor logs for orphaned task warnings - Consider versioning function names (e.g., <code>process_data_v1</code>, <code>process_data_v2</code>) - Document which tasks depend on which functions - Periodically review disabled tasks for cleanup</p>"},{"location":"guides/task-execution/#next-steps","title":"Next Steps","text":"<ul> <li>Job Monitoring: Use <code>.with_jobs()</code> SSE streaming for real-time task progress</li> <li>ML Workflows: Combine with <code>.with_ml()</code> for ML training tasks</li> <li>Authentication: Secure with <code>.with_auth()</code> for production</li> <li>Monitoring: Track execution metrics with <code>.with_monitoring()</code></li> </ul> <p>For more examples: - <code>examples/task_execution_api.py</code> - Shell task execution service - <code>examples/python_task_execution_api.py</code> - Python task execution with TaskRegistry - <code>tests/test_example_task_execution_api.py</code> - Shell task test suite - <code>tests/test_example_python_task_execution_api.py</code> - Python task test suite - <code>docs/guides/job-scheduler.md</code> - Job scheduler and SSE streaming</p>"}]}